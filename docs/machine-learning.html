<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 High-dimensional data | Computational Thinking for Social Scientists</title>
  <meta name="description" content="Chapter 7 High-dimensional data | Computational Thinking for Social Scientists. Online textbook for Teaching Computational Tools and Techniques for Social Scientists." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 High-dimensional data | Computational Thinking for Social Scientists" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Chapter 7 High-dimensional data | Computational Thinking for Social Scientists. Online textbook for Teaching Computational Tools and Techniques for Social Scientists." />
  <meta name="github-repo" content="jaeyk/PS239T" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 High-dimensional data | Computational Thinking for Social Scientists" />
  <meta name="twitter:site" content="@JaeJaeykim2" />
  <meta name="twitter:description" content="Chapter 7 High-dimensional data | Computational Thinking for Social Scientists. Online textbook for Teaching Computational Tools and Techniques for Social Scientists." />
  

<meta name="author" content="Jae Yeon Kim" />


<meta name="date" content="2020-11-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="semi-structured-data.html"/>
<link rel="next" href="big-data.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.0.0/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Thinking for Social Scientists</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Hello World</a>
<ul>
<li class="chapter" data-level="1.0.1" data-path="index.html"><a href="index.html#part-i-fundamentals"><i class="fa fa-check"></i><b>1.0.1</b> Part I Fundamentals</a></li>
<li class="chapter" data-level="1.0.2" data-path="index.html"><a href="index.html#part-ii-applications"><i class="fa fa-check"></i><b>1.0.2</b> Part II Applications</a></li>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#special-thanks"><i class="fa fa-check"></i><b>1.1</b> Special thanks</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#suggestions-questions-or-comments"><i class="fa fa-check"></i><b>1.2</b> Suggestions, questions, or comments</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.3</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i><b>2</b> Computational thinking</a>
<ul>
<li class="chapter" data-level="2.1" data-path="motivation.html"><a href="motivation.html#why-computational-thinking"><i class="fa fa-check"></i><b>2.1</b> Why computational thinking</a></li>
<li class="chapter" data-level="2.2" data-path="motivation.html"><a href="motivation.html#computational-way-of-thinking-about-data"><i class="fa fa-check"></i><b>2.2</b> Computational way of thinking about data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="motivation.html"><a href="motivation.html#structure"><i class="fa fa-check"></i><b>2.2.1</b> Structure</a></li>
<li class="chapter" data-level="2.2.2" data-path="motivation.html"><a href="motivation.html#dimension"><i class="fa fa-check"></i><b>2.2.2</b> Dimension</a></li>
<li class="chapter" data-level="2.2.3" data-path="motivation.html"><a href="motivation.html#size"><i class="fa fa-check"></i><b>2.2.3</b> Size</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="motivation.html"><a href="motivation.html#computational-way-of-thinking-about-research-process"><i class="fa fa-check"></i><b>2.3</b> Computational way of thinking about research process</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="git-bash.html"><a href="git-bash.html"><i class="fa fa-check"></i><b>3</b> Managing data and code</a>
<ul>
<li class="chapter" data-level="3.1" data-path="git-bash.html"><a href="git-bash.html#getting-started-in-r"><i class="fa fa-check"></i><b>3.1</b> Getting started in R</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="git-bash.html"><a href="git-bash.html#rstudio"><i class="fa fa-check"></i><b>3.1.1</b> RStudio</a></li>
<li class="chapter" data-level="3.1.2" data-path="git-bash.html"><a href="git-bash.html#basic-syntax"><i class="fa fa-check"></i><b>3.1.2</b> Basic Syntax</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="git-bash.html"><a href="git-bash.html#environment"><i class="fa fa-check"></i><b>3.2</b> Environment</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="git-bash.html"><a href="git-bash.html#objects"><i class="fa fa-check"></i><b>3.2.1</b> Objects</a></li>
<li class="chapter" data-level="3.2.2" data-path="git-bash.html"><a href="git-bash.html#packages"><i class="fa fa-check"></i><b>3.2.2</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="git-bash.html"><a href="git-bash.html#project-oriented-research"><i class="fa fa-check"></i><b>3.3</b> Project-oriented research</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="git-bash.html"><a href="git-bash.html#computational-reproducibility"><i class="fa fa-check"></i><b>3.3.1</b> Computational reproducibility</a></li>
<li class="chapter" data-level="3.3.2" data-path="git-bash.html"><a href="git-bash.html#version-control-git-and-bash"><i class="fa fa-check"></i><b>3.3.2</b> Version control (Git and Bash)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="git-bash.html"><a href="git-bash.html#writing-code-how-to-code-like-a-professional"><i class="fa fa-check"></i><b>3.4</b> Writing code: How to code like a professional</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="git-bash.html"><a href="git-bash.html#write-readable-code"><i class="fa fa-check"></i><b>3.4.1</b> Write readable code</a></li>
<li class="chapter" data-level="3.4.2" data-path="git-bash.html"><a href="git-bash.html#write-reusable-code"><i class="fa fa-check"></i><b>3.4.2</b> Write reusable code</a></li>
<li class="chapter" data-level="3.4.3" data-path="git-bash.html"><a href="git-bash.html#test-your-code-systematically"><i class="fa fa-check"></i><b>3.4.3</b> Test your code systematically</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="git-bash.html"><a href="git-bash.html#asking-questions-minimal-reproducible-example"><i class="fa fa-check"></i><b>3.5</b> Asking questions: Minimal reproducible example</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="git-bash.html"><a href="git-bash.html#how-to-create-a-minimal-reproducible-example"><i class="fa fa-check"></i><b>3.5.1</b> How to create a minimal reproducible example</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="git-bash.html"><a href="git-bash.html#references"><i class="fa fa-check"></i><b>3.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tidy-data.html"><a href="tidy-data.html"><i class="fa fa-check"></i><b>4</b> Tidy data and its friends</a>
<ul>
<li class="chapter" data-level="4.1" data-path="tidy-data.html"><a href="tidy-data.html#setup-2"><i class="fa fa-check"></i><b>4.1</b> Setup</a></li>
<li class="chapter" data-level="4.2" data-path="tidy-data.html"><a href="tidy-data.html#r-data-structures"><i class="fa fa-check"></i><b>4.2</b> R Data structures</a></li>
<li class="chapter" data-level="4.3" data-path="tidy-data.html"><a href="tidy-data.html#d-data-vectors"><i class="fa fa-check"></i><b>4.3</b> 1D data: Vectors</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="tidy-data.html"><a href="tidy-data.html#atomic-classes"><i class="fa fa-check"></i><b>4.3.1</b> Atomic classes</a></li>
<li class="chapter" data-level="4.3.2" data-path="tidy-data.html"><a href="tidy-data.html#data-structures"><i class="fa fa-check"></i><b>4.3.2</b> Data structures</a></li>
<li class="chapter" data-level="4.3.3" data-path="tidy-data.html"><a href="tidy-data.html#attributes"><i class="fa fa-check"></i><b>4.3.3</b> Attributes</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tidy-data.html"><a href="tidy-data.html#d-data-matrices-and-dataframes"><i class="fa fa-check"></i><b>4.4</b> 2D data: matrices and dataframes</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="tidy-data.html"><a href="tidy-data.html#matrices"><i class="fa fa-check"></i><b>4.4.1</b> Matrices</a></li>
<li class="chapter" data-level="4.4.2" data-path="tidy-data.html"><a href="tidy-data.html#dataframes"><i class="fa fa-check"></i><b>4.4.2</b> Dataframes</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tidy-data.html"><a href="tidy-data.html#subset"><i class="fa fa-check"></i><b>4.5</b> Subset</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="tidy-data.html"><a href="tidy-data.html#atomic-vectors"><i class="fa fa-check"></i><b>4.5.1</b> Atomic vectors</a></li>
<li class="chapter" data-level="4.5.2" data-path="tidy-data.html"><a href="tidy-data.html#lists-1"><i class="fa fa-check"></i><b>4.5.2</b> Lists</a></li>
<li class="chapter" data-level="4.5.3" data-path="tidy-data.html"><a href="tidy-data.html#matrices-1"><i class="fa fa-check"></i><b>4.5.3</b> Matrices</a></li>
<li class="chapter" data-level="4.5.4" data-path="tidy-data.html"><a href="tidy-data.html#data-frames"><i class="fa fa-check"></i><b>4.5.4</b> Data frames</a></li>
<li class="chapter" data-level="4.5.5" data-path="tidy-data.html"><a href="tidy-data.html#subsetting-operators"><i class="fa fa-check"></i><b>4.5.5</b> Subsetting operators</a></li>
<li class="chapter" data-level="4.5.6" data-path="tidy-data.html"><a href="tidy-data.html#subassignment"><i class="fa fa-check"></i><b>4.5.6</b> Subassignment</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="tidy-data.html"><a href="tidy-data.html#tidyverse"><i class="fa fa-check"></i><b>4.6</b> Tidyverse</a></li>
<li class="chapter" data-level="4.7" data-path="tidy-data.html"><a href="tidy-data.html#tidy-data"><i class="fa fa-check"></i><b>4.7</b> Tidy data</a></li>
<li class="chapter" data-level="4.8" data-path="tidy-data.html"><a href="tidy-data.html#tidying-tidyr"><i class="fa fa-check"></i><b>4.8</b> Tidying (tidyr)</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="tidy-data.html"><a href="tidy-data.html#reshaping"><i class="fa fa-check"></i><b>4.8.1</b> Reshaping</a></li>
<li class="chapter" data-level="4.8.2" data-path="tidy-data.html"><a href="tidy-data.html#filling-tbd"><i class="fa fa-check"></i><b>4.8.2</b> Filling (TBD)</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="tidy-data.html"><a href="tidy-data.html#manipulating-dplyr"><i class="fa fa-check"></i><b>4.9</b> Manipulating (dplyr)</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="tidy-data.html"><a href="tidy-data.html#rearranging"><i class="fa fa-check"></i><b>4.9.1</b> Rearranging</a></li>
<li class="chapter" data-level="4.9.2" data-path="tidy-data.html"><a href="tidy-data.html#subset-observations-rows"><i class="fa fa-check"></i><b>4.9.2</b> Subset observations (rows)</a></li>
<li class="chapter" data-level="4.9.3" data-path="tidy-data.html"><a href="tidy-data.html#subset-variables-columns"><i class="fa fa-check"></i><b>4.9.3</b> Subset variables (columns)</a></li>
<li class="chapter" data-level="4.9.4" data-path="tidy-data.html"><a href="tidy-data.html#create-variables-tbd"><i class="fa fa-check"></i><b>4.9.4</b> Create variables (TBD)</a></li>
<li class="chapter" data-level="4.9.5" data-path="tidy-data.html"><a href="tidy-data.html#rename-variables-tbd"><i class="fa fa-check"></i><b>4.9.5</b> Rename variables (TBD)</a></li>
<li class="chapter" data-level="4.9.6" data-path="tidy-data.html"><a href="tidy-data.html#recode-values-tbd"><i class="fa fa-check"></i><b>4.9.6</b> Recode values (TBD)</a></li>
<li class="chapter" data-level="4.9.7" data-path="tidy-data.html"><a href="tidy-data.html#counting"><i class="fa fa-check"></i><b>4.9.7</b> Counting</a></li>
<li class="chapter" data-level="4.9.8" data-path="tidy-data.html"><a href="tidy-data.html#summarizing"><i class="fa fa-check"></i><b>4.9.8</b> Summarizing</a></li>
<li class="chapter" data-level="4.9.9" data-path="tidy-data.html"><a href="tidy-data.html#grouping"><i class="fa fa-check"></i><b>4.9.9</b> Grouping</a></li>
<li class="chapter" data-level="4.9.10" data-path="tidy-data.html"><a href="tidy-data.html#joining"><i class="fa fa-check"></i><b>4.9.10</b> Joining</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="tidy-data.html"><a href="tidy-data.html#modeling-broom"><i class="fa fa-check"></i><b>4.10</b> Modeling (broom)</a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="tidy-data.html"><a href="tidy-data.html#nesting"><i class="fa fa-check"></i><b>4.10.1</b> Nesting</a></li>
<li class="chapter" data-level="4.10.2" data-path="tidy-data.html"><a href="tidy-data.html#mapping"><i class="fa fa-check"></i><b>4.10.2</b> Mapping</a></li>
<li class="chapter" data-level="4.10.3" data-path="tidy-data.html"><a href="tidy-data.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.10.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="4.10.4" data-path="tidy-data.html"><a href="tidy-data.html#mixed-models"><i class="fa fa-check"></i><b>4.10.4</b> Mixed models</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="tidy-data.html"><a href="tidy-data.html#visualizing-ggplot2"><i class="fa fa-check"></i><b>4.11</b> Visualizing (ggplot2)</a>
<ul>
<li class="chapter" data-level="4.11.1" data-path="tidy-data.html"><a href="tidy-data.html#motivation-2"><i class="fa fa-check"></i><b>4.11.1</b> Motivation</a></li>
<li class="chapter" data-level="4.11.2" data-path="tidy-data.html"><a href="tidy-data.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>4.11.2</b> The grammar of graphics</a></li>
<li class="chapter" data-level="4.11.3" data-path="tidy-data.html"><a href="tidy-data.html#mapping-and-geom"><i class="fa fa-check"></i><b>4.11.3</b> mapping and geom</a></li>
<li class="chapter" data-level="4.11.4" data-path="tidy-data.html"><a href="tidy-data.html#basic-aes-x-y"><i class="fa fa-check"></i><b>4.11.4</b> basic aes (x , y)</a></li>
<li class="chapter" data-level="4.11.5" data-path="tidy-data.html"><a href="tidy-data.html#univariate-distribution"><i class="fa fa-check"></i><b>4.11.5</b> Univariate distribution</a></li>
<li class="chapter" data-level="4.11.6" data-path="tidy-data.html"><a href="tidy-data.html#advanced-aes-size-color"><i class="fa fa-check"></i><b>4.11.6</b> Advanced aes (size, color)</a></li>
<li class="chapter" data-level="4.11.7" data-path="tidy-data.html"><a href="tidy-data.html#co-ordinates-and-scales"><i class="fa fa-check"></i><b>4.11.7</b> Co-ordinates and scales</a></li>
<li class="chapter" data-level="4.11.8" data-path="tidy-data.html"><a href="tidy-data.html#labels-and-guides"><i class="fa fa-check"></i><b>4.11.8</b> Labels and guides</a></li>
<li class="chapter" data-level="4.11.9" data-path="tidy-data.html"><a href="tidy-data.html#ggsave"><i class="fa fa-check"></i><b>4.11.9</b> ggsave</a></li>
<li class="chapter" data-level="4.11.10" data-path="tidy-data.html"><a href="tidy-data.html#many-plots"><i class="fa fa-check"></i><b>4.11.10</b> Many plots</a></li>
<li class="chapter" data-level="4.11.11" data-path="tidy-data.html"><a href="tidy-data.html#transforming"><i class="fa fa-check"></i><b>4.11.11</b> Transforming</a></li>
<li class="chapter" data-level="4.11.12" data-path="tidy-data.html"><a href="tidy-data.html#ploting-models"><i class="fa fa-check"></i><b>4.11.12</b> Ploting models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="functional-programming.html"><a href="functional-programming.html"><i class="fa fa-check"></i><b>5</b> Automating repeated things</a>
<ul>
<li class="chapter" data-level="5.1" data-path="functional-programming.html"><a href="functional-programming.html#flow-control"><i class="fa fa-check"></i><b>5.1</b> Flow control</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="functional-programming.html"><a href="functional-programming.html#functions"><i class="fa fa-check"></i><b>5.1.1</b> Functions</a></li>
<li class="chapter" data-level="5.1.2" data-path="functional-programming.html"><a href="functional-programming.html#for-loop"><i class="fa fa-check"></i><b>5.1.2</b> for loop</a></li>
<li class="chapter" data-level="5.1.3" data-path="functional-programming.html"><a href="functional-programming.html#apply-family"><i class="fa fa-check"></i><b>5.1.3</b> apply family</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="functional-programming.html"><a href="functional-programming.html#purrr"><i class="fa fa-check"></i><b>5.2</b> purrr</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="functional-programming.html"><a href="functional-programming.html#why-map"><i class="fa fa-check"></i><b>5.2.1</b> Why map?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="functional-programming.html"><a href="functional-programming.html#automote-2-or-2-tasks"><i class="fa fa-check"></i><b>5.3</b> Automote 2 or 2+ tasks</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="functional-programming.html"><a href="functional-programming.html#objectives-1"><i class="fa fa-check"></i><b>5.3.1</b> Objectives</a></li>
<li class="chapter" data-level="5.3.2" data-path="functional-programming.html"><a href="functional-programming.html#problem"><i class="fa fa-check"></i><b>5.3.2</b> Problem</a></li>
<li class="chapter" data-level="5.3.3" data-path="functional-programming.html"><a href="functional-programming.html#for-loop-1"><i class="fa fa-check"></i><b>5.3.3</b> For loop</a></li>
<li class="chapter" data-level="5.3.4" data-path="functional-programming.html"><a href="functional-programming.html#map2-pmap"><i class="fa fa-check"></i><b>5.3.4</b> map2 &amp; pmap</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="functional-programming.html"><a href="functional-programming.html#automate-plotting"><i class="fa fa-check"></i><b>5.4</b> Automate plotting</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="functional-programming.html"><a href="functional-programming.html#objective"><i class="fa fa-check"></i><b>5.4.1</b> Objective</a></li>
<li class="chapter" data-level="5.4.2" data-path="functional-programming.html"><a href="functional-programming.html#problem-1"><i class="fa fa-check"></i><b>5.4.2</b> Problem</a></li>
<li class="chapter" data-level="5.4.3" data-path="functional-programming.html"><a href="functional-programming.html#solution"><i class="fa fa-check"></i><b>5.4.3</b> Solution</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="functional-programming.html"><a href="functional-programming.html#automate-joining"><i class="fa fa-check"></i><b>5.5</b> Automate joining</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="functional-programming.html"><a href="functional-programming.html#objective-1"><i class="fa fa-check"></i><b>5.5.1</b> Objective</a></li>
<li class="chapter" data-level="5.5.2" data-path="functional-programming.html"><a href="functional-programming.html#problem-2"><i class="fa fa-check"></i><b>5.5.2</b> Problem</a></li>
<li class="chapter" data-level="5.5.3" data-path="functional-programming.html"><a href="functional-programming.html#copy-and-paste"><i class="fa fa-check"></i><b>5.5.3</b> Copy and paste</a></li>
<li class="chapter" data-level="5.5.4" data-path="functional-programming.html"><a href="functional-programming.html#reduce"><i class="fa fa-check"></i><b>5.5.4</b> reduce</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="functional-programming.html"><a href="functional-programming.html#make-automation-slower-or-faster"><i class="fa fa-check"></i><b>5.6</b> Make automation slower or faster</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="functional-programming.html"><a href="functional-programming.html#objectives-2"><i class="fa fa-check"></i><b>5.6.1</b> Objectives</a></li>
<li class="chapter" data-level="5.6.2" data-path="functional-programming.html"><a href="functional-programming.html#how-to-make-automation-slower"><i class="fa fa-check"></i><b>5.6.2</b> How to make automation slower</a></li>
<li class="chapter" data-level="5.6.3" data-path="functional-programming.html"><a href="functional-programming.html#for-loop-2"><i class="fa fa-check"></i><b>5.6.3</b> For loop</a></li>
<li class="chapter" data-level="5.6.4" data-path="functional-programming.html"><a href="functional-programming.html#map"><i class="fa fa-check"></i><b>5.6.4</b> Map</a></li>
<li class="chapter" data-level="5.6.5" data-path="functional-programming.html"><a href="functional-programming.html#how-to-make-automation-faster"><i class="fa fa-check"></i><b>5.6.5</b> How to make automation Faster</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="functional-programming.html"><a href="functional-programming.html#make-error-handling-easier"><i class="fa fa-check"></i><b>5.7</b> Make error handling easier</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="functional-programming.html"><a href="functional-programming.html#learning-objective"><i class="fa fa-check"></i><b>5.7.1</b> Learning objective</a></li>
<li class="chapter" data-level="5.7.2" data-path="functional-programming.html"><a href="functional-programming.html#solution-1"><i class="fa fa-check"></i><b>5.7.2</b> Solution</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="functional-programming.html"><a href="functional-programming.html#developing-your-own-data-products"><i class="fa fa-check"></i><b>5.8</b> Developing your own data products</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="functional-programming.html"><a href="functional-programming.html#developing-r-packages"><i class="fa fa-check"></i><b>5.8.1</b> Developing R packages</a></li>
<li class="chapter" data-level="5.8.2" data-path="functional-programming.html"><a href="functional-programming.html#developing-shiny-apps"><i class="fa fa-check"></i><b>5.8.2</b> Developing Shiny apps</a></li>
<li class="chapter" data-level="5.8.3" data-path="functional-programming.html"><a href="functional-programming.html#other-useful-data-products"><i class="fa fa-check"></i><b>5.8.3</b> Other useful data products</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="semi-structured-data.html"><a href="semi-structured-data.html"><i class="fa fa-check"></i><b>6</b> Semi-structured data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="semi-structured-data.html"><a href="semi-structured-data.html#objectives-3"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="semi-structured-data.html"><a href="semi-structured-data.html#what-is-semi-structured-data"><i class="fa fa-check"></i><b>6.2</b> What is semi-structured data?</a></li>
<li class="chapter" data-level="6.3" data-path="semi-structured-data.html"><a href="semi-structured-data.html#workflow-2"><i class="fa fa-check"></i><b>6.3</b> Workflow</a></li>
<li class="chapter" data-level="6.4" data-path="semi-structured-data.html"><a href="semi-structured-data.html#htmlcss-web-scraping"><i class="fa fa-check"></i><b>6.4</b> HTML/CSS: web scraping</a></li>
<li class="chapter" data-level="6.5" data-path="semi-structured-data.html"><a href="semi-structured-data.html#xmljson-social-media-scraping"><i class="fa fa-check"></i><b>6.5</b> XML/JSON: social media scraping</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="semi-structured-data.html"><a href="semi-structured-data.html#api"><i class="fa fa-check"></i><b>6.5.1</b> API</a></li>
<li class="chapter" data-level="6.5.2" data-path="semi-structured-data.html"><a href="semi-structured-data.html#hydrating"><i class="fa fa-check"></i><b>6.5.2</b> Hydrating</a></li>
<li class="chapter" data-level="6.5.3" data-path="semi-structured-data.html"><a href="semi-structured-data.html#parsing-json"><i class="fa fa-check"></i><b>6.5.3</b> Parsing JSON</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>7</b> High-dimensional data</a>
<ul>
<li class="chapter" data-level="7.1" data-path="machine-learning.html"><a href="machine-learning.html#overview"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="machine-learning.html"><a href="machine-learning.html#dataset"><i class="fa fa-check"></i><b>7.2</b> Dataset</a></li>
<li class="chapter" data-level="7.3" data-path="machine-learning.html"><a href="machine-learning.html#workflow-3"><i class="fa fa-check"></i><b>7.3</b> Workflow</a></li>
<li class="chapter" data-level="7.4" data-path="machine-learning.html"><a href="machine-learning.html#tidymodels"><i class="fa fa-check"></i><b>7.4</b> tidymodels</a></li>
<li class="chapter" data-level="7.5" data-path="machine-learning.html"><a href="machine-learning.html#pre-processing"><i class="fa fa-check"></i><b>7.5</b> Pre-processing</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="machine-learning.html"><a href="machine-learning.html#regression-setup"><i class="fa fa-check"></i><b>7.5.1</b> Regression setup</a></li>
<li class="chapter" data-level="7.5.2" data-path="machine-learning.html"><a href="machine-learning.html#classification-setup"><i class="fa fa-check"></i><b>7.5.2</b> Classification setup</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="machine-learning.html"><a href="machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>7.6</b> Supervised learning</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="machine-learning.html"><a href="machine-learning.html#ols-and-lasso"><i class="fa fa-check"></i><b>7.6.1</b> OLS and Lasso</a></li>
<li class="chapter" data-level="7.6.2" data-path="machine-learning.html"><a href="machine-learning.html#decision-tree"><i class="fa fa-check"></i><b>7.6.2</b> Decision tree</a></li>
<li class="chapter" data-level="7.6.3" data-path="machine-learning.html"><a href="machine-learning.html#bagging-random-forest"><i class="fa fa-check"></i><b>7.6.3</b> Bagging (Random forest)</a></li>
<li class="chapter" data-level="7.6.4" data-path="machine-learning.html"><a href="machine-learning.html#boosting-xgboost"><i class="fa fa-check"></i><b>7.6.4</b> Boosting (XGboost)</a></li>
<li class="chapter" data-level="7.6.5" data-path="machine-learning.html"><a href="machine-learning.html#stacking-superlearner"><i class="fa fa-check"></i><b>7.6.5</b> Stacking (SuperLearner)</a></li>
<li class="chapter" data-level="7.6.6" data-path="machine-learning.html"><a href="machine-learning.html#applications-2"><i class="fa fa-check"></i><b>7.6.6</b> Applications</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="machine-learning.html"><a href="machine-learning.html#unsupervised-learning"><i class="fa fa-check"></i><b>7.7</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="machine-learning.html"><a href="machine-learning.html#dimension-reduction"><i class="fa fa-check"></i><b>7.7.1</b> Dimension reduction</a></li>
<li class="chapter" data-level="7.7.2" data-path="machine-learning.html"><a href="machine-learning.html#topic-modeling"><i class="fa fa-check"></i><b>7.7.2</b> Topic modeling</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="machine-learning.html"><a href="machine-learning.html#bias-and-fairness-in-machine-learning"><i class="fa fa-check"></i><b>7.8</b> Bias and fairness in machine learning</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="machine-learning.html"><a href="machine-learning.html#bias-in-the-data-risk-of-recidivism-analysis"><i class="fa fa-check"></i><b>7.8.1</b> Bias in the Data (Risk of Recidivism Analysis)</a></li>
<li class="chapter" data-level="7.8.2" data-path="machine-learning.html"><a href="machine-learning.html#bias-in-the-data-risk-of-violent-recidivism-analysis"><i class="fa fa-check"></i><b>7.8.2</b> Bias in the Data (Risk of Violent Recidivism Analysis)</a></li>
<li class="chapter" data-level="7.8.3" data-path="machine-learning.html"><a href="machine-learning.html#bias-in-the-algorithm"><i class="fa fa-check"></i><b>7.8.3</b> Bias in the algorithm</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="machine-learning.html"><a href="machine-learning.html#references-2"><i class="fa fa-check"></i><b>7.9</b> References</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="machine-learning.html"><a href="machine-learning.html#books"><i class="fa fa-check"></i><b>7.9.1</b> Books</a></li>
<li class="chapter" data-level="7.9.2" data-path="machine-learning.html"><a href="machine-learning.html#lecture-slides"><i class="fa fa-check"></i><b>7.9.2</b> Lecture slides</a></li>
<li class="chapter" data-level="7.9.3" data-path="machine-learning.html"><a href="machine-learning.html#blog-posts"><i class="fa fa-check"></i><b>7.9.3</b> Blog posts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="big-data.html"><a href="big-data.html"><i class="fa fa-check"></i><b>8</b> Big data</a>
<ul>
<li class="chapter" data-level="8.1" data-path="big-data.html"><a href="big-data.html#overview-2"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="big-data.html"><a href="big-data.html#sql"><i class="fa fa-check"></i><b>8.2</b> SQL</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="big-data.html"><a href="big-data.html#learning-objectives"><i class="fa fa-check"></i><b>8.2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2.2" data-path="big-data.html"><a href="big-data.html#sql-and-r"><i class="fa fa-check"></i><b>8.2.2</b> SQL and R</a></li>
<li class="chapter" data-level="8.2.3" data-path="big-data.html"><a href="big-data.html#setup-7"><i class="fa fa-check"></i><b>8.2.3</b> Setup</a></li>
<li class="chapter" data-level="8.2.4" data-path="big-data.html"><a href="big-data.html#packages-1"><i class="fa fa-check"></i><b>8.2.4</b> Packages</a></li>
<li class="chapter" data-level="8.2.5" data-path="big-data.html"><a href="big-data.html#nyc-flights-data"><i class="fa fa-check"></i><b>8.2.5</b> NYC flights data</a></li>
<li class="chapter" data-level="8.2.6" data-path="big-data.html"><a href="big-data.html#workflow-4"><i class="fa fa-check"></i><b>8.2.6</b> Workflow</a></li>
<li class="chapter" data-level="8.2.7" data-path="big-data.html"><a href="big-data.html#things-we-didnt-cover"><i class="fa fa-check"></i><b>8.2.7</b> Things we didn’t cover</a></li>
<li class="chapter" data-level="8.2.8" data-path="big-data.html"><a href="big-data.html#references-3"><i class="fa fa-check"></i><b>8.2.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="big-data.html"><a href="big-data.html#spark"><i class="fa fa-check"></i><b>8.3</b> Spark</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="big-data.html"><a href="big-data.html#setup-8"><i class="fa fa-check"></i><b>8.3.1</b> Setup</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/jaeyk/PS239T/" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Thinking for Social Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine_learning" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> High-dimensional data</h1>
<div id="overview" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Overview</h2>
<ul>
<li><p>The rise of high-dimensional data. The new data frontiers in social sciences—text (<a href="https://web.stanford.edu/~gentzkow/research/text-as-data.pdf">Gentzkow et al. 2019</a>; <a href="https://www.jstor.org/stable/pdf/24572662.pdf?casa_token=SQdSI4R_VdwAAAAA:4QiVLhCXqr9f0qNMM9U75EL5JbDxxnXxUxyIfDf0U8ZzQx9szc0xVqaU6DXG4nHyZiNkvcwGlgD6H0Lxj3y0ULHwgkf1MZt8-9TPVtkEH9I4AHgbTg">Grimmer and Stewart 2013</a>) and and image (<a href="https://arxiv.org/pdf/1810.01544">Joo and Steinert-Threlkeld 2018</a>)—are all high-dimensional data.</p>
<ul>
<li><p>1000 common English words for 30-word tweets: <span class="math inline">\(1000^{30}\)</span> similar to N of atoms in the universe (<a href="https://web.stanford.edu/~gentzkow/research/text-as-data.pdf">Gentzkow et al. 2019</a>)</p></li>
<li><p>Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. <a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.28.2.29">“High-dimensional methods and inference on structural and treatment effects.”</a> <em>Journal of Economic Perspectives 28</em>, no. 2 (2014): 29-50.</p></li>
</ul></li>
<li><p>The rise of new approach: statistics + computer science = machine learning</p></li>
<li><p>Statistical inference</p>
<ul>
<li><p><span class="math inline">\(y\)</span> &lt;- some probability models (e.g., linear regression, logistic regression) &lt;- <span class="math inline">\(x\)</span></p></li>
<li><p><span class="math inline">\(y\)</span> = <span class="math inline">\(X\beta\)</span> + <span class="math inline">\(\epsilon\)</span></p></li>
<li><p>The goal is to estimate <span class="math inline">\(\beta\)</span></p></li>
</ul></li>
<li><p>Machine learning</p>
<ul>
<li><p><span class="math inline">\(y\)</span> &lt;- unknown &lt;- <span class="math inline">\(x\)</span></p></li>
<li><p><span class="math inline">\(y\)</span> &lt;-&gt; decision trees, neutral nets &lt;-&gt; <span class="math inline">\(x\)</span></p></li>
<li><p>For the main idea behind prediction modeling, see Breiman, Leo (Berkeley stat faculty who passed away in 2005). <a href="https://projecteuclid.org/euclid.ss/1009213726">“Statistical modeling: The two cultures (with comments and a rejoinder by the author).”</a> <em>Statistical science</em> 16, no. 3 (2001): 199-231.</p></li>
<li><p>“The problem is to find an algorithm <span class="math inline">\(f(x)\)</span> such that for future <span class="math inline">\(x\)</span> in a test set, <span class="math inline">\(f(x)\)</span> will be a good predictor of <span class="math inline">\(y\)</span>.”</p></li>
<li><p>“There are <strong>two cultures</strong> in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a <strong>given</strong> <strong>stochastic data model</strong>. The other uses <strong>algorithmic models</strong> and treats the data mechanism as <strong>unknown</strong>.”</p></li>
</ul></li>
<li><p>How ML differs from econometrics?</p></li>
<li><p>A review by Athey, Susan, and Guido W. Imbens. <a href="https://www.annualreviews.org/doi/full/10.1146/annurev-economics-080217-053433">“Machine learning methods that economists should know about.”</a> <em>Annual Review of Economics</em> 11 (2019): 685-725.</p></li>
<li><p>Stat:</p>
<ul>
<li><p>Specifying a target (i.e., an estimand)</p></li>
<li><p>Fitting a model to data using an objective function (e.g., the sum of squared errors)</p></li>
<li><p>Reporting point estimates (effect size) and standard errors (uncertainty)</p></li>
<li><p>Validation by yes-no using goodness-of-fit tests and residual examination</p></li>
</ul></li>
<li><p>ML:</p>
<ul>
<li><p>Developing algorithms (estimating <em>f(x)</em>)</p></li>
<li><p>Prediction power not structural/causal parameters</p></li>
<li><p>Basically, high-dimensional data statistics (N &lt; P)</p></li>
<li><p>The major problem is to avoid <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">“the curse of dimensionality”</a> (<a href="https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e">too many features - &gt; overfitting</a>)</p></li>
<li><p>Validation: out-of-sample comparisons (cross-validation) not in-sample goodness-of-fit measures</p></li>
<li><p>So, it’s curve-fitting but the primary focus is unseen (test data) not seen data (training data)</p></li>
</ul></li>
<li><p>A quick review on ML lingos for those trained in econometrics</p>
<ul>
<li><p>Sample to estimate parameters = Training sample</p></li>
<li><p>Estimating the model = Being trained</p></li>
<li><p>Regressors, covariates, or predictors = Features</p></li>
<li><p>Regression parameters = weights</p></li>
<li><p>Prediction problems = Supervised (some <span class="math inline">\(y\)</span> are known) + Unsupervised (<span class="math inline">\(y\)</span> unknown)</p></li>
</ul></li>
</ul>
<div class="figure">
<img src="https://i.vas3k.ru/7w9.jpg" alt="" />
<p class="caption">How to teach machines. Based on <a href="https://vas3k.com/blog/machine_learning/">vas3k blog</a>. Many images in this chapter come from vas3k blog.</p>
</div>
<div class="figure">
<img src="https://i.vas3k.ru/7vz.jpg" alt="" />
<p class="caption">The main types of machine learning. Based on <a href="https://vas3k.com/blog/machine_learning/">vas3k blog</a></p>
</div>
<div class="figure">
<img src="https://i.vas3k.ru/7vx.jpg" alt="" />
<p class="caption">The map of the machine learning universe. Based on <a href="https://vas3k.com/blog/machine_learning/">vas3k blog</a></p>
</div>
<div class="figure">
<img src="https://i.vas3k.ru/7w1.jpg" alt="" />
<p class="caption">Classical machine learning. Based on <a href="https://vas3k.com/blog/machine_learning/">vas3k blog</a></p>
</div>
</div>
<div id="dataset" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Dataset</h2>
<ul>
<li><p><a href="https://archive.ics.uci.edu/ml/datasets/heart+Disease">Heart disease data from UCI</a></p></li>
<li><p>One of the popular datasets used in machine learning competitions</p></li>
</ul>
<div class="sourceCode" id="cb1025"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1025-1"><a href="machine-learning.html#cb1025-1"></a><span class="co"># Load packages </span></span>
<span id="cb1025-2"><a href="machine-learning.html#cb1025-2"></a></span>
<span id="cb1025-3"><a href="machine-learning.html#cb1025-3"></a><span class="co">## CRAN packages </span></span>
<span id="cb1025-4"><a href="machine-learning.html#cb1025-4"></a>pacman<span class="op">::</span><span class="kw">p_load</span>(here,</span>
<span id="cb1025-5"><a href="machine-learning.html#cb1025-5"></a>               tidyverse, </span>
<span id="cb1025-6"><a href="machine-learning.html#cb1025-6"></a>               tidymodels,</span>
<span id="cb1025-7"><a href="machine-learning.html#cb1025-7"></a>               doParallel, <span class="co"># parallel processing </span></span>
<span id="cb1025-8"><a href="machine-learning.html#cb1025-8"></a>               patchwork, <span class="co"># arranging ggplots</span></span>
<span id="cb1025-9"><a href="machine-learning.html#cb1025-9"></a>               ck37r, </span>
<span id="cb1025-10"><a href="machine-learning.html#cb1025-10"></a>               SuperLearner, </span>
<span id="cb1025-11"><a href="machine-learning.html#cb1025-11"></a>               vip, </span>
<span id="cb1025-12"><a href="machine-learning.html#cb1025-12"></a>               tidymodels)</span>
<span id="cb1025-13"><a href="machine-learning.html#cb1025-13"></a></span>
<span id="cb1025-14"><a href="machine-learning.html#cb1025-14"></a><span class="co">## Jae&#39;s custom functions </span></span>
<span id="cb1025-15"><a href="machine-learning.html#cb1025-15"></a><span class="kw">source</span>(<span class="kw">here</span>(<span class="st">&quot;functions&quot;</span>, <span class="st">&quot;ml_utils.r&quot;</span>))</span>
<span id="cb1025-16"><a href="machine-learning.html#cb1025-16"></a></span>
<span id="cb1025-17"><a href="machine-learning.html#cb1025-17"></a><span class="co"># Import the dataset </span></span>
<span id="cb1025-18"><a href="machine-learning.html#cb1025-18"></a></span>
<span id="cb1025-19"><a href="machine-learning.html#cb1025-19"></a>data_original &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;heart.csv&quot;</span>))</span></code></pre></div>
<pre><code>## 
## ── Column specification ───────────────────────────────────────────────────────────────
## cols(
##   age = col_double(),
##   sex = col_double(),
##   cp = col_double(),
##   trestbps = col_double(),
##   chol = col_double(),
##   fbs = col_double(),
##   restecg = col_double(),
##   thalach = col_double(),
##   exang = col_double(),
##   oldpeak = col_double(),
##   slope = col_double(),
##   ca = col_double(),
##   thal = col_double(),
##   target = col_double()
## )</code></pre>
<div class="sourceCode" id="cb1027"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1027-1"><a href="machine-learning.html#cb1027-1"></a><span class="kw">glimpse</span>(data_original)</span></code></pre></div>
<pre><code>## Rows: 303
## Columns: 14
## $ age      &lt;dbl&gt; 63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, 48, 49, 64, 58, …
## $ sex      &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, …
## $ cp       &lt;dbl&gt; 3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3, 2, 2, 3, 0, 3, …
## $ trestbps &lt;dbl&gt; 145, 130, 130, 120, 120, 140, 140, 120, 172, 150, 140, 130, …
## $ chol     &lt;dbl&gt; 233, 250, 204, 236, 354, 192, 294, 263, 199, 168, 239, 275, …
## $ fbs      &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …
## $ restecg  &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …
## $ thalach  &lt;dbl&gt; 150, 187, 172, 178, 163, 148, 153, 173, 162, 174, 160, 139, …
## $ exang    &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …
## $ oldpeak  &lt;dbl&gt; 2.3, 3.5, 1.4, 0.8, 0.6, 0.4, 1.3, 0.0, 0.5, 1.6, 1.2, 0.2, …
## $ slope    &lt;dbl&gt; 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, …
## $ ca       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, …
## $ thal     &lt;dbl&gt; 1, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …
## $ target   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</code></pre>
<div class="sourceCode" id="cb1029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1029-1"><a href="machine-learning.html#cb1029-1"></a><span class="co"># Createa a copy </span></span>
<span id="cb1029-2"><a href="machine-learning.html#cb1029-2"></a>data &lt;-<span class="st"> </span>data_original</span>
<span id="cb1029-3"><a href="machine-learning.html#cb1029-3"></a></span>
<span id="cb1029-4"><a href="machine-learning.html#cb1029-4"></a><span class="kw">theme_set</span>(<span class="kw">theme_minimal</span>())</span></code></pre></div>
<ul>
<li>For more information on the Iowa housing data, read <a href="http://jse.amstat.org/v19n3/decock.pdf">Cook (2011)</a>. This is one of the famous datastets used in many prediction modeling competitions.</li>
</ul>
</div>
<div id="workflow-3" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Workflow</h2>
<ul>
<li><ol style="list-style-type: decimal">
<li>Preprocessing</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Model building</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Model fitting</li>
</ol></li>
<li><ol start="4" style="list-style-type: decimal">
<li>Model evaluation</li>
</ol></li>
<li><ol start="5" style="list-style-type: decimal">
<li>Model tuning</li>
</ol></li>
<li><ol start="6" style="list-style-type: decimal">
<li>Prediction</li>
</ol></li>
</ul>
</div>
<div id="tidymodels" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> tidymodels</h2>
<ul>
<li><p>Like <code>tidyverse</code>, <code>tidymodels</code> is a collection of packages.</p>
<ul>
<li><p><a href="https://rsample.tidymodels.org/"><code>rsample</code></a>: for data splitting</p></li>
<li><p><a href="https://recipes.tidymodels.org/index.html"><code>recipes</code></a>: for pre-processing</p></li>
<li><p><a href="https://www.tidyverse.org/blog/2018/11/parsnip-0-0-1/"><code>parsnip</code></a>: for model building</p>
<ul>
<li><a href="https://github.com/tidymodels/tune"><code>tune</code></a>: hyperparameter tuning</li>
</ul></li>
<li><p><a href="https://github.com/tidymodels/yardstick"><code>yardstick</code></a>: for model evaluations</p></li>
<li><p><a href="https://github.com/tidymodels/workflows"><code>workflows</code></a>: for bundling a pieplne that bundles together pre-processing, modeling, and post-processing requests</p></li>
</ul></li>
<li><p>Why taking a tidyverse approach to machine learning?</p></li>
<li><p>Benefits</p>
<ul>
<li><p>Readable code</p></li>
<li><p>Reusable data structures</p></li>
<li><p>Extendable code</p></li>
</ul></li>
</ul>
<div class="figure">
<img src="https://rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/ds.png" alt="" />
<p class="caption">Tidymodels. From RStudio.</p>
</div>
<blockquote>
<p>tidymodels are an <strong>integrated, modular, extensible</strong> set of packages that implement a framework that facilitates creating predicative stochastic models. - Joseph <a href="mailto:Rickert@RStudio" class="email">Rickert@RStudio</a></p>
</blockquote>
<ul>
<li><p>Currently, 238 models are <a href="https://topepo.github.io/caret/available-models.html">available</a></p></li>
<li><p>The following materials are based on <a href="https://github.com/dlab-berkeley/Machine-Learning-with-tidymodels">the machine learning with tidymodels workshop</a> I developed for D-Lab. <a href="https://github.com/dlab-berkeley/Machine-Learning-in-R">The original workshop</a> was designed by <a href="https://ck37.com/">Chris Kennedy</a> and [Evan Muzzall](<a href="https://dlab.berkeley.edu/people/evan-muzzall" class="uri">https://dlab.berkeley.edu/people/evan-muzzall</a>.</p></li>
</ul>
</div>
<div id="pre-processing" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Pre-processing</h2>
<ul>
<li><p><a href="https://recipes.tidymodels.org/index.html"><code>recipes</code></a>: for pre-processing</p></li>
<li><p><a href="https://github.com/tidymodels/textrecipes"><code>textrecipes</code></a> for text pre-processing</p></li>
<li><p>Step 1: <code>recipe()</code> defines target and predictor variables (ingredients).</p></li>
<li><p>Step 2: <code>step_*()</code> defines preprocessing steps to be taken (recipe).</p>
<p>The list of the preprocessing steps draws on the vignette of the <a href="https://www.tidymodels.org/find/parsnip/"><code>parsnip</code></a> package.</p>
<ul>
<li><p>dummy: Also called one-hot encoding</p></li>
<li><p>zero variance: Removing columns (or features) with a single unique value</p></li>
<li><p>impute: Imputing missing values</p></li>
<li><p>decorrelate: Mitigating correlated predictors (e.g., principal component analysis)</p></li>
<li><p>normalize: Centering and/or scaling predictors (e.g., log scaling). Scaling matters because many algorithms (e.g., lasso) are scale-variant (except tree-based algorithms). Remind you that normalization (sensitive to outliers) = <span class="math inline">\(\frac{X - X_{min}}{X_{max} - X_{min}}\)</span> and standardization (not sensitive to outliers) = <span class="math inline">\(\frac{X - \mu}{\sigma}\)</span></p></li>
<li><p>transform: Making predictors symmetric</p></li>
</ul></li>
<li><p>Step 3: <code>prep()</code> prepares a dataset to base each step on.</p></li>
<li><p>Step 4: <code>bake()</code> applies the pre-processing steps to your datasets.</p></li>
</ul>
<p>In this course, we focus on two preprocessing tasks.</p>
<ul>
<li>One-hot encoding (creating dummy/indicator variables)</li>
</ul>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1030-1"><a href="machine-learning.html#cb1030-1"></a><span class="co"># Turn selected numeric variables into factor variables </span></span>
<span id="cb1030-2"><a href="machine-learning.html#cb1030-2"></a>data &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span></span>
<span id="cb1030-3"><a href="machine-learning.html#cb1030-3"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="kw">across</span>(<span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ca&quot;</span>, <span class="st">&quot;cp&quot;</span>, <span class="st">&quot;slope&quot;</span>, <span class="st">&quot;thal&quot;</span>), as.factor)) </span>
<span id="cb1030-4"><a href="machine-learning.html#cb1030-4"></a></span>
<span id="cb1030-5"><a href="machine-learning.html#cb1030-5"></a><span class="kw">glimpse</span>(data) </span></code></pre></div>
<pre><code>## Rows: 303
## Columns: 14
## $ age      &lt;dbl&gt; 63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, 48, 49, 64, 58, …
## $ sex      &lt;fct&gt; 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, …
## $ cp       &lt;fct&gt; 3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3, 2, 2, 3, 0, 3, …
## $ trestbps &lt;dbl&gt; 145, 130, 130, 120, 120, 140, 140, 120, 172, 150, 140, 130, …
## $ chol     &lt;dbl&gt; 233, 250, 204, 236, 354, 192, 294, 263, 199, 168, 239, 275, …
## $ fbs      &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …
## $ restecg  &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …
## $ thalach  &lt;dbl&gt; 150, 187, 172, 178, 163, 148, 153, 173, 162, 174, 160, 139, …
## $ exang    &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …
## $ oldpeak  &lt;dbl&gt; 2.3, 3.5, 1.4, 0.8, 0.6, 0.4, 1.3, 0.0, 0.5, 1.6, 1.2, 0.2, …
## $ slope    &lt;fct&gt; 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, …
## $ ca       &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, …
## $ thal     &lt;fct&gt; 1, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …
## $ target   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</code></pre>
<ul>
<li>Imputation</li>
</ul>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="machine-learning.html#cb1032-1"></a><span class="co"># Check missing values </span></span>
<span id="cb1032-2"><a href="machine-learning.html#cb1032-2"></a></span>
<span id="cb1032-3"><a href="machine-learning.html#cb1032-3"></a><span class="kw">map_df</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">is.na</span>(.) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>())</span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;
## 1     0     0     0        0     0     0       0       0     0       0     0
## # … with 3 more variables: ca &lt;int&gt;, thal &lt;int&gt;, target &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="machine-learning.html#cb1034-1"></a><span class="co"># Add missing values </span></span>
<span id="cb1034-2"><a href="machine-learning.html#cb1034-2"></a></span>
<span id="cb1034-3"><a href="machine-learning.html#cb1034-3"></a>data<span class="op">$</span>oldpeak[<span class="kw">sample</span>(<span class="kw">seq</span>(data), <span class="dt">size =</span> <span class="dv">10</span>)] &lt;-<span class="st"> </span><span class="ot">NA</span></span>
<span id="cb1034-4"><a href="machine-learning.html#cb1034-4"></a></span>
<span id="cb1034-5"><a href="machine-learning.html#cb1034-5"></a><span class="co"># Check missing values </span></span>
<span id="cb1034-6"><a href="machine-learning.html#cb1034-6"></a></span>
<span id="cb1034-7"><a href="machine-learning.html#cb1034-7"></a><span class="co"># Check the number of missing values </span></span>
<span id="cb1034-8"><a href="machine-learning.html#cb1034-8"></a>data <span class="op">%&gt;%</span></span>
<span id="cb1034-9"><a href="machine-learning.html#cb1034-9"></a><span class="st">  </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">is.na</span>(.) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>())</span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;
## 1     0     0     0        0     0     0       0       0     0      10     0
## # … with 3 more variables: ca &lt;int&gt;, thal &lt;int&gt;, target &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb1036"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1036-1"><a href="machine-learning.html#cb1036-1"></a><span class="co"># Check the rate of missing values</span></span>
<span id="cb1036-2"><a href="machine-learning.html#cb1036-2"></a>data <span class="op">%&gt;%</span></span>
<span id="cb1036-3"><a href="machine-learning.html#cb1036-3"></a><span class="st">  </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">is.na</span>(.) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mean</span>())</span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1     0     0     0        0     0     0       0       0     0  0.0330     0
## # … with 3 more variables: ca &lt;dbl&gt;, thal &lt;dbl&gt;, target &lt;dbl&gt;</code></pre>
<div id="regression-setup" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Regression setup</h3>
<div id="outcome-variable" class="section level4" number="7.5.1.1">
<h4><span class="header-section-number">7.5.1.1</span> Outcome variable</h4>
<div class="sourceCode" id="cb1038"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1038-1"><a href="machine-learning.html#cb1038-1"></a><span class="co"># Continuous variable </span></span>
<span id="cb1038-2"><a href="machine-learning.html#cb1038-2"></a>data<span class="op">$</span>age <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">class</span>()</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
</div>
<div id="data-splitting-using-random-sampling" class="section level4" number="7.5.1.2">
<h4><span class="header-section-number">7.5.1.2</span> Data splitting using random sampling</h4>
<div class="sourceCode" id="cb1040"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1040-1"><a href="machine-learning.html#cb1040-1"></a><span class="co"># for reproducibility </span></span>
<span id="cb1040-2"><a href="machine-learning.html#cb1040-2"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) </span>
<span id="cb1040-3"><a href="machine-learning.html#cb1040-3"></a></span>
<span id="cb1040-4"><a href="machine-learning.html#cb1040-4"></a><span class="co"># split </span></span>
<span id="cb1040-5"><a href="machine-learning.html#cb1040-5"></a>split_reg &lt;-<span class="st"> </span><span class="kw">initial_split</span>(data, <span class="dt">prop =</span> <span class="fl">0.7</span>)</span>
<span id="cb1040-6"><a href="machine-learning.html#cb1040-6"></a></span>
<span id="cb1040-7"><a href="machine-learning.html#cb1040-7"></a><span class="co"># training set </span></span>
<span id="cb1040-8"><a href="machine-learning.html#cb1040-8"></a>raw_train_x_reg &lt;-<span class="st"> </span><span class="kw">training</span>(split_reg)</span>
<span id="cb1040-9"><a href="machine-learning.html#cb1040-9"></a></span>
<span id="cb1040-10"><a href="machine-learning.html#cb1040-10"></a><span class="co"># test set </span></span>
<span id="cb1040-11"><a href="machine-learning.html#cb1040-11"></a>raw_test_x_reg &lt;-<span class="st"> </span><span class="kw">testing</span>(split_reg)</span></code></pre></div>
</div>
<div id="recipe" class="section level4" number="7.5.1.3">
<h4><span class="header-section-number">7.5.1.3</span> recipe</h4>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1041-1"><a href="machine-learning.html#cb1041-1"></a><span class="co"># Regression recipe </span></span>
<span id="cb1041-2"><a href="machine-learning.html#cb1041-2"></a>rec_reg &lt;-<span class="st"> </span>raw_train_x_reg <span class="op">%&gt;%</span></span>
<span id="cb1041-3"><a href="machine-learning.html#cb1041-3"></a><span class="st">  </span><span class="co"># Define the outcome variable </span></span>
<span id="cb1041-4"><a href="machine-learning.html#cb1041-4"></a><span class="st">  </span><span class="kw">recipe</span>(age <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span></span>
<span id="cb1041-5"><a href="machine-learning.html#cb1041-5"></a><span class="st">  </span><span class="co"># Median impute oldpeak column </span></span>
<span id="cb1041-6"><a href="machine-learning.html#cb1041-6"></a><span class="st">  </span><span class="kw">step_medianimpute</span>(oldpeak) <span class="op">%&gt;%</span></span>
<span id="cb1041-7"><a href="machine-learning.html#cb1041-7"></a><span class="st">  </span><span class="co"># Expand &quot;sex&quot;, &quot;ca&quot;, &quot;cp&quot;, &quot;slope&quot;, and &quot;thal&quot; features out into dummy variables (indicators). </span></span>
<span id="cb1041-8"><a href="machine-learning.html#cb1041-8"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ca&quot;</span>, <span class="st">&quot;cp&quot;</span>, <span class="st">&quot;slope&quot;</span>, <span class="st">&quot;thal&quot;</span>))</span>
<span id="cb1041-9"><a href="machine-learning.html#cb1041-9"></a></span>
<span id="cb1041-10"><a href="machine-learning.html#cb1041-10"></a><span class="co"># Prepare a dataset to base each step on</span></span>
<span id="cb1041-11"><a href="machine-learning.html#cb1041-11"></a>prep_reg &lt;-<span class="st"> </span>rec_reg <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prep</span>(<span class="dt">retain =</span> <span class="ot">TRUE</span>) </span></code></pre></div>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1042-1"><a href="machine-learning.html#cb1042-1"></a><span class="co"># x features </span></span>
<span id="cb1042-2"><a href="machine-learning.html#cb1042-2"></a>train_x_reg &lt;-<span class="st"> </span><span class="kw">juice</span>(prep_reg, <span class="kw">all_predictors</span>())</span>
<span id="cb1042-3"><a href="machine-learning.html#cb1042-3"></a></span>
<span id="cb1042-4"><a href="machine-learning.html#cb1042-4"></a>test_x_reg &lt;-<span class="st"> </span><span class="kw">bake</span>(<span class="dt">object =</span> prep_reg, </span>
<span id="cb1042-5"><a href="machine-learning.html#cb1042-5"></a>                   <span class="dt">new_data =</span> raw_test_x_reg, <span class="kw">all_predictors</span>())</span>
<span id="cb1042-6"><a href="machine-learning.html#cb1042-6"></a></span>
<span id="cb1042-7"><a href="machine-learning.html#cb1042-7"></a><span class="co"># y variables </span></span>
<span id="cb1042-8"><a href="machine-learning.html#cb1042-8"></a>train_y_reg &lt;-<span class="st"> </span><span class="kw">juice</span>(prep_reg, <span class="kw">all_outcomes</span>())<span class="op">$</span>age <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>()</span>
<span id="cb1042-9"><a href="machine-learning.html#cb1042-9"></a>test_y_reg &lt;-<span class="st"> </span><span class="kw">bake</span>(prep_reg, raw_test_x_reg, <span class="kw">all_outcomes</span>())<span class="op">$</span>age <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>()</span>
<span id="cb1042-10"><a href="machine-learning.html#cb1042-10"></a></span>
<span id="cb1042-11"><a href="machine-learning.html#cb1042-11"></a><span class="co"># Checks</span></span>
<span id="cb1042-12"><a href="machine-learning.html#cb1042-12"></a><span class="kw">names</span>(train_x_reg) <span class="co"># Make sure there&#39;s no age variable!</span></span></code></pre></div>
<pre><code>##  [1] &quot;trestbps&quot; &quot;chol&quot;     &quot;fbs&quot;      &quot;restecg&quot;  &quot;thalach&quot;  &quot;exang&quot;   
##  [7] &quot;oldpeak&quot;  &quot;target&quot;   &quot;sex_X1&quot;   &quot;ca_X1&quot;    &quot;ca_X2&quot;    &quot;ca_X3&quot;   
## [13] &quot;ca_X4&quot;    &quot;cp_X1&quot;    &quot;cp_X2&quot;    &quot;cp_X3&quot;    &quot;slope_X1&quot; &quot;slope_X2&quot;
## [19] &quot;thal_X1&quot;  &quot;thal_X2&quot;  &quot;thal_X3&quot;</code></pre>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="machine-learning.html#cb1044-1"></a><span class="kw">class</span>(train_y_reg) <span class="co"># Make sure this is a continuous variable!</span></span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<ul>
<li>Note that other imputation methods are also available.</li>
</ul>
<div class="sourceCode" id="cb1046"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1046-1"><a href="machine-learning.html#cb1046-1"></a><span class="kw">grep</span>(<span class="st">&quot;impute&quot;</span>, <span class="kw">ls</span>(<span class="st">&quot;package:recipes&quot;</span>), <span class="dt">value =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] &quot;step_bagimpute&quot;     &quot;step_impute_linear&quot; &quot;step_knnimpute&quot;    
## [4] &quot;step_lowerimpute&quot;   &quot;step_meanimpute&quot;    &quot;step_medianimpute&quot; 
## [7] &quot;step_modeimpute&quot;    &quot;step_rollimpute&quot;</code></pre>
<ul>
<li>You can also create your own <code>step_</code> functions. For more information, see <a href="https://www.tidymodels.org/learn/develop/recipes/">tidymodels.org</a>.</li>
</ul>
</div>
</div>
<div id="classification-setup" class="section level3" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Classification setup</h3>
<div id="outcome-variable-1" class="section level4" number="7.5.2.1">
<h4><span class="header-section-number">7.5.2.1</span> Outcome variable</h4>
<div class="sourceCode" id="cb1048"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1048-1"><a href="machine-learning.html#cb1048-1"></a>data<span class="op">$</span>target <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">class</span>() </span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1050-1"><a href="machine-learning.html#cb1050-1"></a>data<span class="op">$</span>target &lt;-<span class="st"> </span><span class="kw">as.factor</span>(data<span class="op">$</span>target)</span>
<span id="cb1050-2"><a href="machine-learning.html#cb1050-2"></a></span>
<span id="cb1050-3"><a href="machine-learning.html#cb1050-3"></a>data<span class="op">$</span>target <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">class</span>()</span></code></pre></div>
<pre><code>## [1] &quot;factor&quot;</code></pre>
</div>
<div id="data-splitting-using-stratified-random-sampling" class="section level4" number="7.5.2.2">
<h4><span class="header-section-number">7.5.2.2</span> Data splitting using stratified random sampling</h4>
<div class="sourceCode" id="cb1052"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1052-1"><a href="machine-learning.html#cb1052-1"></a><span class="co"># split </span></span>
<span id="cb1052-2"><a href="machine-learning.html#cb1052-2"></a>split_class &lt;-<span class="st"> </span><span class="kw">initial_split</span>(data <span class="op">%&gt;%</span></span>
<span id="cb1052-3"><a href="machine-learning.html#cb1052-3"></a><span class="st">                             </span><span class="kw">mutate</span>(<span class="dt">target =</span> <span class="kw">as.factor</span>(target)), </span>
<span id="cb1052-4"><a href="machine-learning.html#cb1052-4"></a>                             <span class="dt">prop =</span> <span class="fl">0.7</span>, </span>
<span id="cb1052-5"><a href="machine-learning.html#cb1052-5"></a>                             <span class="dt">strata =</span> target)</span>
<span id="cb1052-6"><a href="machine-learning.html#cb1052-6"></a></span>
<span id="cb1052-7"><a href="machine-learning.html#cb1052-7"></a><span class="co"># training set </span></span>
<span id="cb1052-8"><a href="machine-learning.html#cb1052-8"></a>raw_train_x_class &lt;-<span class="st"> </span><span class="kw">training</span>(split_class)</span>
<span id="cb1052-9"><a href="machine-learning.html#cb1052-9"></a></span>
<span id="cb1052-10"><a href="machine-learning.html#cb1052-10"></a><span class="co"># testing set </span></span>
<span id="cb1052-11"><a href="machine-learning.html#cb1052-11"></a>raw_test_x_class &lt;-<span class="st"> </span><span class="kw">testing</span>(split_class)</span></code></pre></div>
</div>
<div id="recipe-1" class="section level4" number="7.5.2.3">
<h4><span class="header-section-number">7.5.2.3</span> recipe</h4>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="machine-learning.html#cb1053-1"></a><span class="co"># Classification recipe </span></span>
<span id="cb1053-2"><a href="machine-learning.html#cb1053-2"></a>rec_class &lt;-<span class="st"> </span>raw_train_x_class <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1053-3"><a href="machine-learning.html#cb1053-3"></a><span class="st">  </span><span class="co"># Define the outcome variable </span></span>
<span id="cb1053-4"><a href="machine-learning.html#cb1053-4"></a><span class="st">  </span><span class="kw">recipe</span>(target <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span></span>
<span id="cb1053-5"><a href="machine-learning.html#cb1053-5"></a><span class="st">  </span><span class="co"># Median impute oldpeak column </span></span>
<span id="cb1053-6"><a href="machine-learning.html#cb1053-6"></a><span class="st">  </span><span class="kw">step_medianimpute</span>(oldpeak) <span class="op">%&gt;%</span></span>
<span id="cb1053-7"><a href="machine-learning.html#cb1053-7"></a><span class="st">  </span><span class="co"># Expand &quot;sex&quot;, &quot;ca&quot;, &quot;cp&quot;, &quot;slope&quot;, and &quot;thal&quot; features out into dummy variables (indicators).</span></span>
<span id="cb1053-8"><a href="machine-learning.html#cb1053-8"></a><span class="st">  </span><span class="kw">step_normalize</span>(age) <span class="op">%&gt;%</span></span>
<span id="cb1053-9"><a href="machine-learning.html#cb1053-9"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ca&quot;</span>, <span class="st">&quot;cp&quot;</span>, <span class="st">&quot;slope&quot;</span>, <span class="st">&quot;thal&quot;</span>)) </span>
<span id="cb1053-10"><a href="machine-learning.html#cb1053-10"></a></span>
<span id="cb1053-11"><a href="machine-learning.html#cb1053-11"></a><span class="co"># Prepare a dataset to base each step on</span></span>
<span id="cb1053-12"><a href="machine-learning.html#cb1053-12"></a>prep_class &lt;-<span class="st"> </span>rec_class <span class="op">%&gt;%</span><span class="kw">prep</span>(<span class="dt">retain =</span> <span class="ot">TRUE</span>) </span></code></pre></div>
<div class="sourceCode" id="cb1054"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1054-1"><a href="machine-learning.html#cb1054-1"></a><span class="co"># x features </span></span>
<span id="cb1054-2"><a href="machine-learning.html#cb1054-2"></a>train_x_class &lt;-<span class="st"> </span><span class="kw">juice</span>(prep_class, <span class="kw">all_predictors</span>()) </span>
<span id="cb1054-3"><a href="machine-learning.html#cb1054-3"></a>test_x_class &lt;-<span class="st"> </span><span class="kw">bake</span>(prep_class, raw_test_x_class, <span class="kw">all_predictors</span>())</span>
<span id="cb1054-4"><a href="machine-learning.html#cb1054-4"></a></span>
<span id="cb1054-5"><a href="machine-learning.html#cb1054-5"></a><span class="co"># y variables </span></span>
<span id="cb1054-6"><a href="machine-learning.html#cb1054-6"></a>train_y_class &lt;-<span class="st"> </span><span class="kw">juice</span>(prep_class, <span class="kw">all_outcomes</span>())<span class="op">$</span>target <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</span>
<span id="cb1054-7"><a href="machine-learning.html#cb1054-7"></a>test_y_class &lt;-<span class="st"> </span><span class="kw">bake</span>(prep_class, raw_test_x_class, <span class="kw">all_outcomes</span>())<span class="op">$</span>target <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</span>
<span id="cb1054-8"><a href="machine-learning.html#cb1054-8"></a></span>
<span id="cb1054-9"><a href="machine-learning.html#cb1054-9"></a><span class="co"># Checks </span></span>
<span id="cb1054-10"><a href="machine-learning.html#cb1054-10"></a><span class="kw">names</span>(train_x_class) <span class="co"># Make sure there&#39;s no target variable!</span></span></code></pre></div>
<pre><code>##  [1] &quot;age&quot;      &quot;trestbps&quot; &quot;chol&quot;     &quot;fbs&quot;      &quot;restecg&quot;  &quot;thalach&quot; 
##  [7] &quot;exang&quot;    &quot;oldpeak&quot;  &quot;sex_X1&quot;   &quot;ca_X1&quot;    &quot;ca_X2&quot;    &quot;ca_X3&quot;   
## [13] &quot;ca_X4&quot;    &quot;cp_X1&quot;    &quot;cp_X2&quot;    &quot;cp_X3&quot;    &quot;slope_X1&quot; &quot;slope_X2&quot;
## [19] &quot;thal_X1&quot;  &quot;thal_X2&quot;  &quot;thal_X3&quot;</code></pre>
<div class="sourceCode" id="cb1056"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1056-1"><a href="machine-learning.html#cb1056-1"></a><span class="kw">class</span>(train_y_class) <span class="co"># Make sure this is a factor variable!</span></span></code></pre></div>
<pre><code>## [1] &quot;factor&quot;</code></pre>
</div>
</div>
</div>
<div id="supervised-learning" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Supervised learning</h2>
<p>x -&gt; f - &gt; y (defined)</p>
<div id="ols-and-lasso" class="section level3" number="7.6.1">
<h3><span class="header-section-number">7.6.1</span> OLS and Lasso</h3>
<div id="parsnip" class="section level4" number="7.6.1.1">
<h4><span class="header-section-number">7.6.1.1</span> parsnip</h4>
<ul>
<li>Build models (<code>parsnip</code>)</li>
</ul>
<ol style="list-style-type: decimal">
<li>Specify a model</li>
<li>Specify an engine</li>
<li>Specify a mode</li>
</ol>
<div class="sourceCode" id="cb1058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1058-1"><a href="machine-learning.html#cb1058-1"></a><span class="co"># OLS spec </span></span>
<span id="cb1058-2"><a href="machine-learning.html#cb1058-2"></a>ols_spec &lt;-<span class="st"> </span><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Specify a model </span></span>
<span id="cb1058-3"><a href="machine-learning.html#cb1058-3"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Specify an engine: lm, glmnet, stan, keras, spark </span></span>
<span id="cb1058-4"><a href="machine-learning.html#cb1058-4"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="co"># Declare a mode: regression or classification </span></span>
<span id="cb1058-5"><a href="machine-learning.html#cb1058-5"></a></span>
<span id="cb1058-6"><a href="machine-learning.html#cb1058-6"></a><span class="co"># Lasso spec </span></span>
<span id="cb1058-7"><a href="machine-learning.html#cb1058-7"></a>lasso_spec &lt;-<span class="st"> </span><span class="kw">linear_reg</span>(<span class="dt">penalty =</span> <span class="fl">0.1</span>, <span class="co"># tuning hyperparameter </span></span>
<span id="cb1058-8"><a href="machine-learning.html#cb1058-8"></a>                         <span class="dt">mixture =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># 1 = lasso, 0 = ridge </span></span>
<span id="cb1058-9"><a href="machine-learning.html#cb1058-9"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1058-10"><a href="machine-learning.html#cb1058-10"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">&quot;regression&quot;</span>) </span>
<span id="cb1058-11"><a href="machine-learning.html#cb1058-11"></a></span>
<span id="cb1058-12"><a href="machine-learning.html#cb1058-12"></a><span class="co"># If you don&#39;t understand parsnip arguments </span></span>
<span id="cb1058-13"><a href="machine-learning.html#cb1058-13"></a>lasso_spec <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">translate</span>() <span class="co"># See the documentation</span></span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 0.1
##   mixture = 1
## 
## Computational engine: glmnet 
## 
## Model fit template:
## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
##     alpha = 1, family = &quot;gaussian&quot;)</code></pre>
<ul>
<li>Fit models</li>
</ul>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="machine-learning.html#cb1060-1"></a>ols_fit &lt;-<span class="st"> </span>ols_spec <span class="op">%&gt;%</span></span>
<span id="cb1060-2"><a href="machine-learning.html#cb1060-2"></a><span class="st">  </span><span class="kw">fit_xy</span>(<span class="dt">x =</span> train_x_reg, <span class="dt">y=</span> train_y_reg) </span>
<span id="cb1060-3"><a href="machine-learning.html#cb1060-3"></a>  <span class="co"># fit(train_y_reg ~ ., train_x_reg) # When you data are not preprocessed </span></span>
<span id="cb1060-4"><a href="machine-learning.html#cb1060-4"></a></span>
<span id="cb1060-5"><a href="machine-learning.html#cb1060-5"></a>lasso_fit &lt;-<span class="st"> </span>lasso_spec <span class="op">%&gt;%</span></span>
<span id="cb1060-6"><a href="machine-learning.html#cb1060-6"></a><span class="st">  </span><span class="kw">fit_xy</span>(<span class="dt">x =</span> train_x_reg, <span class="dt">y=</span> train_y_reg) </span></code></pre></div>
</div>
<div id="yardstick" class="section level4" number="7.6.1.2">
<h4><span class="header-section-number">7.6.1.2</span> yardstick</h4>
<ul>
<li>Visualize model fits</li>
</ul>
<div class="sourceCode" id="cb1061"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1061-1"><a href="machine-learning.html#cb1061-1"></a><span class="kw">map2</span>(<span class="kw">list</span>(ols_fit, lasso_fit), <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;Lasso&quot;</span>), visualize_fit) </span></code></pre></div>
<pre><code>## [[1]]</code></pre>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<pre><code>## 
## [[2]]</code></pre>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-16-2.png" width="672" /></p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="machine-learning.html#cb1064-1"></a><span class="co"># Define performance metrics </span></span>
<span id="cb1064-2"><a href="machine-learning.html#cb1064-2"></a>metrics &lt;-<span class="st"> </span>yardstick<span class="op">::</span><span class="kw">metric_set</span>(rmse, mae, rsq)</span>
<span id="cb1064-3"><a href="machine-learning.html#cb1064-3"></a></span>
<span id="cb1064-4"><a href="machine-learning.html#cb1064-4"></a><span class="co"># Evaluate many models </span></span>
<span id="cb1064-5"><a href="machine-learning.html#cb1064-5"></a>evals &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="kw">list</span>(ols_fit, lasso_fit), evaluate_reg) <span class="op">%&gt;%</span></span>
<span id="cb1064-6"><a href="machine-learning.html#cb1064-6"></a><span class="st">  </span><span class="kw">reduce</span>(bind_rows) <span class="op">%&gt;%</span></span>
<span id="cb1064-7"><a href="machine-learning.html#cb1064-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">type =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;Lasso&quot;</span>), <span class="dt">each =</span> <span class="dv">3</span>))</span>
<span id="cb1064-8"><a href="machine-learning.html#cb1064-8"></a></span>
<span id="cb1064-9"><a href="machine-learning.html#cb1064-9"></a><span class="co"># Visualize the test results </span></span>
<span id="cb1064-10"><a href="machine-learning.html#cb1064-10"></a>evals <span class="op">%&gt;%</span></span>
<span id="cb1064-11"><a href="machine-learning.html#cb1064-11"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(type, .estimate), <span class="dt">y =</span> .estimate)) <span class="op">+</span></span>
<span id="cb1064-12"><a href="machine-learning.html#cb1064-12"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb1064-13"><a href="machine-learning.html#cb1064-13"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Model&quot;</span>,</span>
<span id="cb1064-14"><a href="machine-learning.html#cb1064-14"></a>         <span class="dt">y =</span> <span class="st">&quot;Estimate&quot;</span>) <span class="op">+</span></span>
<span id="cb1064-15"><a href="machine-learning.html#cb1064-15"></a><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="kw">glue</span>(<span class="st">&quot;{toupper(.metric)}&quot;</span>), <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) </span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-17-1.png" width="672" />
- For more information, read <a href="https://www.tmwr.org/">Tidy Modeling with R</a> by Max Kuhn and Julia Silge.</p>
</div>
<div id="tune" class="section level4" number="7.6.1.3">
<h4><span class="header-section-number">7.6.1.3</span> tune</h4>
<p><strong>Hyper</strong>parameters are parameters which control the learning process.</p>
<div id="tune-ingredients" class="section level5" number="7.6.1.3.1">
<h5><span class="header-section-number">7.6.1.3.1</span> tune ingredients</h5>
<div class="sourceCode" id="cb1065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1065-1"><a href="machine-learning.html#cb1065-1"></a><span class="co"># tune() = placeholder </span></span>
<span id="cb1065-2"><a href="machine-learning.html#cb1065-2"></a></span>
<span id="cb1065-3"><a href="machine-learning.html#cb1065-3"></a>tune_spec &lt;-<span class="st"> </span><span class="kw">linear_reg</span>(<span class="dt">penalty =</span> <span class="kw">tune</span>(), <span class="co"># tuning hyperparameter </span></span>
<span id="cb1065-4"><a href="machine-learning.html#cb1065-4"></a>                        <span class="dt">mixture =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># 1 = lasso, 0 = ridge </span></span>
<span id="cb1065-5"><a href="machine-learning.html#cb1065-5"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1065-6"><a href="machine-learning.html#cb1065-6"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">&quot;regression&quot;</span>) </span>
<span id="cb1065-7"><a href="machine-learning.html#cb1065-7"></a></span>
<span id="cb1065-8"><a href="machine-learning.html#cb1065-8"></a>tune_spec</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet</code></pre>
<div class="sourceCode" id="cb1067"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1067-1"><a href="machine-learning.html#cb1067-1"></a><span class="co"># penalty() searches 50 possible combinations </span></span>
<span id="cb1067-2"><a href="machine-learning.html#cb1067-2"></a></span>
<span id="cb1067-3"><a href="machine-learning.html#cb1067-3"></a>lambda_grid &lt;-<span class="st"> </span><span class="kw">grid_regular</span>(<span class="kw">penalty</span>(), <span class="dt">levels =</span> <span class="dv">50</span>)</span>
<span id="cb1067-4"><a href="machine-learning.html#cb1067-4"></a></span>
<span id="cb1067-5"><a href="machine-learning.html#cb1067-5"></a><span class="co"># 10-fold cross-validation</span></span>
<span id="cb1067-6"><a href="machine-learning.html#cb1067-6"></a></span>
<span id="cb1067-7"><a href="machine-learning.html#cb1067-7"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co"># for reproducibility </span></span>
<span id="cb1067-8"><a href="machine-learning.html#cb1067-8"></a></span>
<span id="cb1067-9"><a href="machine-learning.html#cb1067-9"></a>rec_folds &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(train_x_reg <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">age =</span> train_y_reg)))</span></code></pre></div>
</div>
<div id="add-these-elements-to-a-workflow" class="section level5" number="7.6.1.3.2">
<h5><span class="header-section-number">7.6.1.3.2</span> Add these elements to a workflow</h5>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1068-1"><a href="machine-learning.html#cb1068-1"></a><span class="co"># Workflow </span></span>
<span id="cb1068-2"><a href="machine-learning.html#cb1068-2"></a>rec_wf &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span></span>
<span id="cb1068-3"><a href="machine-learning.html#cb1068-3"></a><span class="st">  </span><span class="kw">add_model</span>(tune_spec) <span class="op">%&gt;%</span></span>
<span id="cb1068-4"><a href="machine-learning.html#cb1068-4"></a><span class="st">  </span><span class="kw">add_formula</span>(age<span class="op">~</span>.)</span></code></pre></div>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1069-1"><a href="machine-learning.html#cb1069-1"></a><span class="co"># Tuning results </span></span>
<span id="cb1069-2"><a href="machine-learning.html#cb1069-2"></a>rec_res &lt;-<span class="st"> </span>rec_wf <span class="op">%&gt;%</span></span>
<span id="cb1069-3"><a href="machine-learning.html#cb1069-3"></a><span class="st">  </span><span class="kw">tune_grid</span>(</span>
<span id="cb1069-4"><a href="machine-learning.html#cb1069-4"></a>    <span class="dt">resamples =</span> rec_folds, </span>
<span id="cb1069-5"><a href="machine-learning.html#cb1069-5"></a>    <span class="dt">grid =</span> lambda_grid</span>
<span id="cb1069-6"><a href="machine-learning.html#cb1069-6"></a>  )</span></code></pre></div>
</div>
<div id="visualize" class="section level5" number="7.6.1.3.3">
<h5><span class="header-section-number">7.6.1.3.3</span> Visualize</h5>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1070-1"><a href="machine-learning.html#cb1070-1"></a><span class="co"># Visualize</span></span>
<span id="cb1070-2"><a href="machine-learning.html#cb1070-2"></a></span>
<span id="cb1070-3"><a href="machine-learning.html#cb1070-3"></a>rec_res <span class="op">%&gt;%</span></span>
<span id="cb1070-4"><a href="machine-learning.html#cb1070-4"></a><span class="st">  </span><span class="kw">collect_metrics</span>() <span class="op">%&gt;%</span></span>
<span id="cb1070-5"><a href="machine-learning.html#cb1070-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(penalty, mean, <span class="dt">col =</span> .metric)) <span class="op">+</span></span>
<span id="cb1070-6"><a href="machine-learning.html#cb1070-6"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(</span>
<span id="cb1070-7"><a href="machine-learning.html#cb1070-7"></a>    <span class="dt">ymin =</span> mean <span class="op">-</span><span class="st"> </span>std_err,</span>
<span id="cb1070-8"><a href="machine-learning.html#cb1070-8"></a>    <span class="dt">ymax =</span> mean <span class="op">+</span><span class="st"> </span>std_err</span>
<span id="cb1070-9"><a href="machine-learning.html#cb1070-9"></a>  ),</span>
<span id="cb1070-10"><a href="machine-learning.html#cb1070-10"></a>  <span class="dt">alpha =</span> <span class="fl">0.3</span></span>
<span id="cb1070-11"><a href="machine-learning.html#cb1070-11"></a>  ) <span class="op">+</span></span>
<span id="cb1070-12"><a href="machine-learning.html#cb1070-12"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1070-13"><a href="machine-learning.html#cb1070-13"></a><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span></span>
<span id="cb1070-14"><a href="machine-learning.html#cb1070-14"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log(lambda)&quot;</span>) <span class="op">+</span></span>
<span id="cb1070-15"><a href="machine-learning.html#cb1070-15"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="kw">glue</span>(<span class="st">&quot;{toupper(.metric)}&quot;</span>), </span>
<span id="cb1070-16"><a href="machine-learning.html#cb1070-16"></a>             <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>,</span>
<span id="cb1070-17"><a href="machine-learning.html#cb1070-17"></a>             <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1070-18"><a href="machine-learning.html#cb1070-18"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
<div id="select" class="section level5" number="7.6.1.3.4">
<h5><span class="header-section-number">7.6.1.3.4</span> Select</h5>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1071-1"><a href="machine-learning.html#cb1071-1"></a>top_rmse &lt;-<span class="st"> </span><span class="kw">show_best</span>(rec_res, <span class="dt">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb1071-2"><a href="machine-learning.html#cb1071-2"></a></span>
<span id="cb1071-3"><a href="machine-learning.html#cb1071-3"></a>best_rmse &lt;-<span class="st"> </span><span class="kw">select_best</span>(rec_res, <span class="dt">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb1071-4"><a href="machine-learning.html#cb1071-4"></a></span>
<span id="cb1071-5"><a href="machine-learning.html#cb1071-5"></a>best_rmse </span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   penalty .config
##     &lt;dbl&gt; &lt;chr&gt;  
## 1   0.153 Model46</code></pre>
<div class="sourceCode" id="cb1073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1073-1"><a href="machine-learning.html#cb1073-1"></a><span class="kw">glue</span>(<span class="st">&#39;The RMSE of the intiail model is </span></span>
<span id="cb1073-2"><a href="machine-learning.html#cb1073-2"></a><span class="st">     {evals %&gt;%</span></span>
<span id="cb1073-3"><a href="machine-learning.html#cb1073-3"></a><span class="st">  filter(type == &quot;Lasso&quot;, .metric == &quot;rmse&quot;) %&gt;%</span></span>
<span id="cb1073-4"><a href="machine-learning.html#cb1073-4"></a><span class="st">  select(.estimate) %&gt;%</span></span>
<span id="cb1073-5"><a href="machine-learning.html#cb1073-5"></a><span class="st">  round(2)}&#39;</span>)</span></code></pre></div>
<pre><code>## The RMSE of the intiail model is 
##    7.88</code></pre>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="machine-learning.html#cb1075-1"></a><span class="kw">glue</span>(<span class="st">&#39;The RMSE of the tuned model is {rec_res %&gt;%</span></span>
<span id="cb1075-2"><a href="machine-learning.html#cb1075-2"></a><span class="st">  collect_metrics() %&gt;%</span></span>
<span id="cb1075-3"><a href="machine-learning.html#cb1075-3"></a><span class="st">  filter(.metric == &quot;rmse&quot;) %&gt;%</span></span>
<span id="cb1075-4"><a href="machine-learning.html#cb1075-4"></a><span class="st">  arrange(mean) %&gt;%</span></span>
<span id="cb1075-5"><a href="machine-learning.html#cb1075-5"></a><span class="st">  dplyr::slice(1) %&gt;%</span></span>
<span id="cb1075-6"><a href="machine-learning.html#cb1075-6"></a><span class="st">  select(mean) %&gt;%</span></span>
<span id="cb1075-7"><a href="machine-learning.html#cb1075-7"></a><span class="st">  round(2)}&#39;</span>)</span></code></pre></div>
<pre><code>## The RMSE of the tuned model is 7.71</code></pre>
<ul>
<li>Finalize your workflow and visualize <a href="https://koalaverse.github.io/vip/articles/vip.html">variable importance</a></li>
</ul>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="machine-learning.html#cb1077-1"></a>finalize_lasso &lt;-<span class="st"> </span>rec_wf <span class="op">%&gt;%</span></span>
<span id="cb1077-2"><a href="machine-learning.html#cb1077-2"></a><span class="st">  </span><span class="kw">finalize_workflow</span>(best_rmse)</span>
<span id="cb1077-3"><a href="machine-learning.html#cb1077-3"></a></span>
<span id="cb1077-4"><a href="machine-learning.html#cb1077-4"></a>finalize_lasso <span class="op">%&gt;%</span></span>
<span id="cb1077-5"><a href="machine-learning.html#cb1077-5"></a><span class="st">  </span><span class="kw">fit</span>(train_x_reg <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">age =</span> train_y_reg))) <span class="op">%&gt;%</span></span>
<span id="cb1077-6"><a href="machine-learning.html#cb1077-6"></a><span class="st">  </span><span class="kw">pull_workflow_fit</span>() <span class="op">%&gt;%</span></span>
<span id="cb1077-7"><a href="machine-learning.html#cb1077-7"></a><span class="st">  </span>vip<span class="op">::</span><span class="kw">vip</span>()</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
</div>
<div id="test-fit" class="section level5" number="7.6.1.3.5">
<h5><span class="header-section-number">7.6.1.3.5</span> Test fit</h5>
<ul>
<li>Apply the tuned model to the test dataset</li>
</ul>
<div class="sourceCode" id="cb1078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1078-1"><a href="machine-learning.html#cb1078-1"></a>test_fit &lt;-<span class="st"> </span>finalize_lasso <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1078-2"><a href="machine-learning.html#cb1078-2"></a><span class="st">  </span><span class="kw">fit</span>(test_x_reg <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">age =</span> test_y_reg)))</span>
<span id="cb1078-3"><a href="machine-learning.html#cb1078-3"></a></span>
<span id="cb1078-4"><a href="machine-learning.html#cb1078-4"></a><span class="kw">evaluate_reg</span>(test_fit)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       7.09 
## 2 mae     standard       5.84 
## 3 rsq     standard       0.414</code></pre>
</div>
</div>
</div>
<div id="decision-tree" class="section level3" number="7.6.2">
<h3><span class="header-section-number">7.6.2</span> Decision tree</h3>
<div id="parsnip-1" class="section level4" number="7.6.2.1">
<h4><span class="header-section-number">7.6.2.1</span> parsnip</h4>
<ul>
<li>Build a model</li>
</ul>
<ol style="list-style-type: decimal">
<li>Specify a model</li>
<li>Specify an engine</li>
<li>Specify a mode</li>
</ol>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="machine-learning.html#cb1080-1"></a><span class="co"># workflow </span></span>
<span id="cb1080-2"><a href="machine-learning.html#cb1080-2"></a>tree_wf &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">add_formula</span>(target<span class="op">~</span>.)</span>
<span id="cb1080-3"><a href="machine-learning.html#cb1080-3"></a></span>
<span id="cb1080-4"><a href="machine-learning.html#cb1080-4"></a><span class="co"># spec </span></span>
<span id="cb1080-5"><a href="machine-learning.html#cb1080-5"></a>tree_spec &lt;-<span class="st"> </span><span class="kw">decision_tree</span>(</span>
<span id="cb1080-6"><a href="machine-learning.html#cb1080-6"></a>  </span>
<span id="cb1080-7"><a href="machine-learning.html#cb1080-7"></a>           <span class="co"># Mode </span></span>
<span id="cb1080-8"><a href="machine-learning.html#cb1080-8"></a>           <span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb1080-9"><a href="machine-learning.html#cb1080-9"></a>           </span>
<span id="cb1080-10"><a href="machine-learning.html#cb1080-10"></a>           <span class="co"># Tuning hyperparameters</span></span>
<span id="cb1080-11"><a href="machine-learning.html#cb1080-11"></a>           <span class="dt">cost_complexity =</span> <span class="ot">NULL</span>, </span>
<span id="cb1080-12"><a href="machine-learning.html#cb1080-12"></a>           <span class="dt">tree_depth =</span> <span class="ot">NULL</span>) <span class="op">%&gt;%</span></span>
<span id="cb1080-13"><a href="machine-learning.html#cb1080-13"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;rpart&quot;</span>) <span class="co"># rpart, c5.0, spark</span></span>
<span id="cb1080-14"><a href="machine-learning.html#cb1080-14"></a></span>
<span id="cb1080-15"><a href="machine-learning.html#cb1080-15"></a>tree_wf &lt;-<span class="st"> </span>tree_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">add_model</span>(tree_spec)</span></code></pre></div>
<ul>
<li>Fit a model</li>
</ul>
<div class="sourceCode" id="cb1081"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1081-1"><a href="machine-learning.html#cb1081-1"></a>tree_fit &lt;-<span class="st"> </span>tree_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)))</span></code></pre></div>
</div>
<div id="yardstick-1" class="section level4" number="7.6.2.2">
<h4><span class="header-section-number">7.6.2.2</span> yardstick</h4>
<ul>
<li>Let’s formally test prediction performance.</li>
</ul>
<p><strong>Metrics</strong></p>
<ul>
<li><p><code>accuracy</code>: The proportion of the data predicted correctly</p></li>
<li><p><code>precision</code>: Positive predictive value</p></li>
<li><p><code>recall</code> (specificity): True positive rate (e.g., healthy people really healthy)</p></li>
</ul>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png" alt="" />
<p class="caption">From wikipedia</p>
</div>
<ul>
<li>To learn more about other metrics, check out the yardstick package <a href="https://yardstick.tidymodels.org/reference/index.html">references</a>.</li>
</ul>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="machine-learning.html#cb1082-1"></a><span class="co"># Define performance metrics </span></span>
<span id="cb1082-2"><a href="machine-learning.html#cb1082-2"></a></span>
<span id="cb1082-3"><a href="machine-learning.html#cb1082-3"></a>metrics &lt;-<span class="st"> </span>yardstick<span class="op">::</span><span class="kw">metric_set</span>(accuracy, precision, recall)</span>
<span id="cb1082-4"><a href="machine-learning.html#cb1082-4"></a></span>
<span id="cb1082-5"><a href="machine-learning.html#cb1082-5"></a><span class="co"># Visualize</span></span>
<span id="cb1082-6"><a href="machine-learning.html#cb1082-6"></a></span>
<span id="cb1082-7"><a href="machine-learning.html#cb1082-7"></a>tree_fit_viz_metr &lt;-<span class="st"> </span><span class="kw">visualize_class_eval</span>(tree_fit)</span>
<span id="cb1082-8"><a href="machine-learning.html#cb1082-8"></a></span>
<span id="cb1082-9"><a href="machine-learning.html#cb1082-9"></a>tree_fit_viz_metr</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<div class="sourceCode" id="cb1083"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1083-1"><a href="machine-learning.html#cb1083-1"></a>tree_fit_viz_mat &lt;-<span class="st"> </span><span class="kw">visualize_class_conf</span>(tree_fit)</span>
<span id="cb1083-2"><a href="machine-learning.html#cb1083-2"></a></span>
<span id="cb1083-3"><a href="machine-learning.html#cb1083-3"></a>tree_fit_viz_mat</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-27-2.png" width="672" /></p>
</div>
<div id="tune-1" class="section level4" number="7.6.2.3">
<h4><span class="header-section-number">7.6.2.3</span> tune</h4>
<div id="tune-ingredients-1" class="section level5" number="7.6.2.3.1">
<h5><span class="header-section-number">7.6.2.3.1</span> tune ingredients</h5>
<p>Decisions trees tend to overfit. Broadly speaking, there are two things we need to consider to reduce this problem: how to split and when to stop a tree.</p>
<ul>
<li><p><strong>complexity parameter</strong>: a high CP means a simple decision tree with few splits.</p></li>
<li><p><strong>tree_depth</strong></p></li>
</ul>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="machine-learning.html#cb1084-1"></a>tune_spec &lt;-<span class="st"> </span></span>
<span id="cb1084-2"><a href="machine-learning.html#cb1084-2"></a><span class="st">  </span><span class="kw">decision_tree</span>(</span>
<span id="cb1084-3"><a href="machine-learning.html#cb1084-3"></a>    <span class="dt">cost_complexity =</span> <span class="kw">tune</span>(), <span class="co"># how to split </span></span>
<span id="cb1084-4"><a href="machine-learning.html#cb1084-4"></a>    <span class="dt">tree_depth =</span> <span class="kw">tune</span>(), <span class="co"># when to stop </span></span>
<span id="cb1084-5"><a href="machine-learning.html#cb1084-5"></a>    <span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span></span>
<span id="cb1084-6"><a href="machine-learning.html#cb1084-6"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb1084-7"><a href="machine-learning.html#cb1084-7"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;rpart&quot;</span>)</span>
<span id="cb1084-8"><a href="machine-learning.html#cb1084-8"></a></span>
<span id="cb1084-9"><a href="machine-learning.html#cb1084-9"></a>tree_grid &lt;-<span class="st"> </span><span class="kw">grid_regular</span>(<span class="kw">cost_complexity</span>(),</span>
<span id="cb1084-10"><a href="machine-learning.html#cb1084-10"></a>                          <span class="kw">tree_depth</span>(),</span>
<span id="cb1084-11"><a href="machine-learning.html#cb1084-11"></a>                          <span class="dt">levels =</span> <span class="dv">5</span>) <span class="co"># 2 hyperparameters -&gt; 5*5 = 25 combinations </span></span>
<span id="cb1084-12"><a href="machine-learning.html#cb1084-12"></a></span>
<span id="cb1084-13"><a href="machine-learning.html#cb1084-13"></a>tree_grid <span class="op">%&gt;%</span></span>
<span id="cb1084-14"><a href="machine-learning.html#cb1084-14"></a><span class="st">  </span><span class="kw">count</span>(tree_depth)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   tree_depth     n
##        &lt;int&gt; &lt;int&gt;
## 1          1     5
## 2          4     5
## 3          8     5
## 4         11     5
## 5         15     5</code></pre>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="machine-learning.html#cb1086-1"></a><span class="co"># 10-fold cross-validation</span></span>
<span id="cb1086-2"><a href="machine-learning.html#cb1086-2"></a></span>
<span id="cb1086-3"><a href="machine-learning.html#cb1086-3"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co"># for reproducibility </span></span>
<span id="cb1086-4"><a href="machine-learning.html#cb1086-4"></a></span>
<span id="cb1086-5"><a href="machine-learning.html#cb1086-5"></a>tree_folds &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)),</span>
<span id="cb1086-6"><a href="machine-learning.html#cb1086-6"></a>                       <span class="dt">strata =</span> target)</span></code></pre></div>
</div>
<div id="add-these-elements-to-a-workflow-1" class="section level5" number="7.6.2.3.2">
<h5><span class="header-section-number">7.6.2.3.2</span> Add these elements to a workflow</h5>
<div class="sourceCode" id="cb1087"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1087-1"><a href="machine-learning.html#cb1087-1"></a><span class="co"># Update workflow </span></span>
<span id="cb1087-2"><a href="machine-learning.html#cb1087-2"></a>tree_wf &lt;-<span class="st"> </span>tree_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">update_model</span>(tune_spec)</span>
<span id="cb1087-3"><a href="machine-learning.html#cb1087-3"></a></span>
<span id="cb1087-4"><a href="machine-learning.html#cb1087-4"></a><span class="co"># Determine the number of cores</span></span>
<span id="cb1087-5"><a href="machine-learning.html#cb1087-5"></a>no_cores &lt;-<span class="st"> </span><span class="kw">detectCores</span>() <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb1087-6"><a href="machine-learning.html#cb1087-6"></a></span>
<span id="cb1087-7"><a href="machine-learning.html#cb1087-7"></a><span class="co"># Initiate</span></span>
<span id="cb1087-8"><a href="machine-learning.html#cb1087-8"></a>cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(no_cores)</span>
<span id="cb1087-9"><a href="machine-learning.html#cb1087-9"></a></span>
<span id="cb1087-10"><a href="machine-learning.html#cb1087-10"></a><span class="kw">registerDoParallel</span>(cl)</span>
<span id="cb1087-11"><a href="machine-learning.html#cb1087-11"></a></span>
<span id="cb1087-12"><a href="machine-learning.html#cb1087-12"></a><span class="co"># Tuning results </span></span>
<span id="cb1087-13"><a href="machine-learning.html#cb1087-13"></a>tree_res &lt;-<span class="st"> </span>tree_wf <span class="op">%&gt;%</span></span>
<span id="cb1087-14"><a href="machine-learning.html#cb1087-14"></a><span class="st">  </span><span class="kw">tune_grid</span>(</span>
<span id="cb1087-15"><a href="machine-learning.html#cb1087-15"></a>    <span class="dt">resamples =</span> tree_folds, </span>
<span id="cb1087-16"><a href="machine-learning.html#cb1087-16"></a>    <span class="dt">grid =</span> tree_grid,</span>
<span id="cb1087-17"><a href="machine-learning.html#cb1087-17"></a>    <span class="dt">metrics =</span> metrics</span>
<span id="cb1087-18"><a href="machine-learning.html#cb1087-18"></a>  )</span></code></pre></div>
</div>
<div id="visualize-1" class="section level5" number="7.6.2.3.3">
<h5><span class="header-section-number">7.6.2.3.3</span> Visualize</h5>
<ul>
<li>The following plot draws on the <a href="https://www.tidymodels.org/start/tuning/">vignette</a> of the tidymodels package.</li>
</ul>
<div class="sourceCode" id="cb1088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1088-1"><a href="machine-learning.html#cb1088-1"></a>tree_res <span class="op">%&gt;%</span></span>
<span id="cb1088-2"><a href="machine-learning.html#cb1088-2"></a><span class="st">  </span><span class="kw">collect_metrics</span>() <span class="op">%&gt;%</span></span>
<span id="cb1088-3"><a href="machine-learning.html#cb1088-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">tree_depth =</span> <span class="kw">factor</span>(tree_depth)) <span class="op">%&gt;%</span></span>
<span id="cb1088-4"><a href="machine-learning.html#cb1088-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(cost_complexity, mean, <span class="dt">col =</span> .metric)) <span class="op">+</span></span>
<span id="cb1088-5"><a href="machine-learning.html#cb1088-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb1088-6"><a href="machine-learning.html#cb1088-6"></a><span class="st">  </span><span class="co"># Subplots </span></span>
<span id="cb1088-7"><a href="machine-learning.html#cb1088-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>tree_depth, </span>
<span id="cb1088-8"><a href="machine-learning.html#cb1088-8"></a>             <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>, </span>
<span id="cb1088-9"><a href="machine-learning.html#cb1088-9"></a>             <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1088-10"><a href="machine-learning.html#cb1088-10"></a><span class="st">  </span><span class="co"># Log scale x </span></span>
<span id="cb1088-11"><a href="machine-learning.html#cb1088-11"></a><span class="st">  </span><span class="kw">scale_x_log10</span>(<span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">label_number</span>()) <span class="op">+</span></span>
<span id="cb1088-12"><a href="machine-learning.html#cb1088-12"></a><span class="st">  </span><span class="co"># Discrete color scale </span></span>
<span id="cb1088-13"><a href="machine-learning.html#cb1088-13"></a><span class="st">  </span><span class="kw">scale_color_viridis_d</span>(<span class="dt">option =</span> <span class="st">&quot;plasma&quot;</span>, <span class="dt">begin =</span> <span class="fl">.9</span>, <span class="dt">end =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb1088-14"><a href="machine-learning.html#cb1088-14"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cost complexity&quot;</span>,</span>
<span id="cb1088-15"><a href="machine-learning.html#cb1088-15"></a>       <span class="dt">col =</span> <span class="st">&quot;Tree depth&quot;</span>,</span>
<span id="cb1088-16"><a href="machine-learning.html#cb1088-16"></a>       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb1088-17"><a href="machine-learning.html#cb1088-17"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
<div id="select-1" class="section level5" number="7.6.2.3.4">
<h5><span class="header-section-number">7.6.2.3.4</span> Select</h5>
<div class="sourceCode" id="cb1089"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1089-1"><a href="machine-learning.html#cb1089-1"></a><span class="co"># Optimal hyperparameter</span></span>
<span id="cb1089-2"><a href="machine-learning.html#cb1089-2"></a>best_tree &lt;-<span class="st"> </span><span class="kw">select_best</span>(tree_res, <span class="st">&quot;recall&quot;</span>)</span>
<span id="cb1089-3"><a href="machine-learning.html#cb1089-3"></a></span>
<span id="cb1089-4"><a href="machine-learning.html#cb1089-4"></a><span class="co"># Add the hyperparameter to the workflow </span></span>
<span id="cb1089-5"><a href="machine-learning.html#cb1089-5"></a>finalize_tree &lt;-<span class="st"> </span>tree_wf <span class="op">%&gt;%</span></span>
<span id="cb1089-6"><a href="machine-learning.html#cb1089-6"></a><span class="st">  </span><span class="kw">finalize_workflow</span>(best_tree)</span></code></pre></div>
<div class="sourceCode" id="cb1090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1090-1"><a href="machine-learning.html#cb1090-1"></a>tree_fit_tuned &lt;-<span class="st"> </span>finalize_tree <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1090-2"><a href="machine-learning.html#cb1090-2"></a><span class="st">  </span><span class="kw">fit</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)))</span>
<span id="cb1090-3"><a href="machine-learning.html#cb1090-3"></a></span>
<span id="cb1090-4"><a href="machine-learning.html#cb1090-4"></a><span class="co"># Metrics </span></span>
<span id="cb1090-5"><a href="machine-learning.html#cb1090-5"></a>(tree_fit_viz_metr <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Non-tuned&quot;</span>)) <span class="op">/</span><span class="st"> </span>(<span class="kw">visualize_class_eval</span>(tree_fit_tuned) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tuned&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<div class="sourceCode" id="cb1091"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1091-1"><a href="machine-learning.html#cb1091-1"></a><span class="co"># Confusion matrix </span></span>
<span id="cb1091-2"><a href="machine-learning.html#cb1091-2"></a>(tree_fit_viz_mat <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Non-tuned&quot;</span>)) <span class="op">/</span><span class="st"> </span>(<span class="kw">visualize_class_conf</span>(tree_fit_tuned) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tuned&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-32-2.png" width="672" /></p>
<ul>
<li>Visualize variable importance</li>
</ul>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1092-1"><a href="machine-learning.html#cb1092-1"></a>tree_fit_tuned <span class="op">%&gt;%</span></span>
<span id="cb1092-2"><a href="machine-learning.html#cb1092-2"></a><span class="st">  </span><span class="kw">pull_workflow_fit</span>() <span class="op">%&gt;%</span></span>
<span id="cb1092-3"><a href="machine-learning.html#cb1092-3"></a><span class="st">  </span>vip<span class="op">::</span><span class="kw">vip</span>()</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
</div>
<div id="test-fit-1" class="section level5" number="7.6.2.3.5">
<h5><span class="header-section-number">7.6.2.3.5</span> Test fit</h5>
<ul>
<li>Apply the tuned model to the test dataset</li>
</ul>
<div class="sourceCode" id="cb1093"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1093-1"><a href="machine-learning.html#cb1093-1"></a>test_fit &lt;-<span class="st"> </span>finalize_tree <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1093-2"><a href="machine-learning.html#cb1093-2"></a><span class="st">  </span><span class="kw">fit</span>(test_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> test_y_class)))</span>
<span id="cb1093-3"><a href="machine-learning.html#cb1093-3"></a></span>
<span id="cb1093-4"><a href="machine-learning.html#cb1093-4"></a><span class="kw">evaluate_class</span>(test_fit)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy  binary         0.756
## 2 precision binary         0.721
## 3 recall    binary         0.756</code></pre>
<p>In the next subsection, we will learn variants of ensemble models that improve decision tree model by putting models together.</p>
</div>
</div>
</div>
<div id="bagging-random-forest" class="section level3" number="7.6.3">
<h3><span class="header-section-number">7.6.3</span> Bagging (Random forest)</h3>
<p>Key idea applied across all ensemble models (bagging, boosting, and stacking):
single learner -&gt; N learners (N &gt; 1)</p>
<p>Many learners could perform better than a single learner as this approach reduces the <strong>variance</strong> of a single estimate and provides more stability.</p>
<p>Here we focus on the difference between bagging and boosting. In short, boosting may reduce bias while increasing variance. Bagging may reduce variance but has nothing to do with bias. For more information, please check out <a href="https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/">What is the difference between Bagging and Boosting?</a> by aporras.</p>
<p><strong>bagging</strong></p>
<ul>
<li><p>Data: Training data will be random sampled with replacement (bootstrapping samples + drawing random <strong>subsets</strong> of features for training individual trees)</p></li>
<li><p>Learning: Building models in parallel (independently)</p></li>
<li><p>Prediction: Simple average of the estimated responses (majority vote system)</p></li>
</ul>
<div class="figure">
<img src="https://sebastianraschka.com/images/faq/bagging-boosting-rf/bagging.png" alt="" />
<p class="caption">From Sebastian Raschka’s blog</p>
</div>
<p><strong>boosting</strong></p>
<ul>
<li><p>Data: Weighted training data will be random sampled</p></li>
<li><p>Learning: Building models sequentially (mispredicted cases would receive more weights)</p></li>
<li><p>Prediction: Weighted average of the estimated responses</p></li>
</ul>
<div class="figure">
<img src="https://sebastianraschka.com/images/faq/bagging-boosting-rf/boosting.png" alt="" />
<p class="caption">From Sebastian Raschka’s blog</p>
</div>
<div id="parsnip-2" class="section level4" number="7.6.3.1">
<h4><span class="header-section-number">7.6.3.1</span> parsnip</h4>
<ul>
<li>Build a model</li>
</ul>
<ol style="list-style-type: decimal">
<li>Specify a model</li>
<li>Specify an engine</li>
<li>Specify a mode</li>
</ol>
<div class="sourceCode" id="cb1095"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1095-1"><a href="machine-learning.html#cb1095-1"></a><span class="co"># workflow </span></span>
<span id="cb1095-2"><a href="machine-learning.html#cb1095-2"></a>rand_wf &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">add_formula</span>(target<span class="op">~</span>.)</span>
<span id="cb1095-3"><a href="machine-learning.html#cb1095-3"></a></span>
<span id="cb1095-4"><a href="machine-learning.html#cb1095-4"></a><span class="co"># spec </span></span>
<span id="cb1095-5"><a href="machine-learning.html#cb1095-5"></a>rand_spec &lt;-<span class="st"> </span><span class="kw">rand_forest</span>(</span>
<span id="cb1095-6"><a href="machine-learning.html#cb1095-6"></a>  </span>
<span id="cb1095-7"><a href="machine-learning.html#cb1095-7"></a>           <span class="co"># Mode </span></span>
<span id="cb1095-8"><a href="machine-learning.html#cb1095-8"></a>           <span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb1095-9"><a href="machine-learning.html#cb1095-9"></a>           </span>
<span id="cb1095-10"><a href="machine-learning.html#cb1095-10"></a>           <span class="co"># Tuning hyperparameters</span></span>
<span id="cb1095-11"><a href="machine-learning.html#cb1095-11"></a>           <span class="dt">mtry =</span> <span class="ot">NULL</span>, <span class="co"># The number of predictors to available for splitting at each node  </span></span>
<span id="cb1095-12"><a href="machine-learning.html#cb1095-12"></a>           <span class="dt">min_n =</span> <span class="ot">NULL</span>, <span class="co"># The minimum number of data points needed to keep splitting nodes</span></span>
<span id="cb1095-13"><a href="machine-learning.html#cb1095-13"></a>           <span class="dt">trees =</span> <span class="dv">500</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># The number of trees</span></span>
<span id="cb1095-14"><a href="machine-learning.html#cb1095-14"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;ranger&quot;</span>, </span>
<span id="cb1095-15"><a href="machine-learning.html#cb1095-15"></a>             <span class="co"># We want the importance of predictors to be assessed.</span></span>
<span id="cb1095-16"><a href="machine-learning.html#cb1095-16"></a>             <span class="dt">seed =</span> <span class="dv">1234</span>, </span>
<span id="cb1095-17"><a href="machine-learning.html#cb1095-17"></a>             <span class="dt">importance =</span> <span class="st">&quot;permutation&quot;</span>) </span>
<span id="cb1095-18"><a href="machine-learning.html#cb1095-18"></a></span>
<span id="cb1095-19"><a href="machine-learning.html#cb1095-19"></a>rand_wf &lt;-<span class="st"> </span>rand_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">add_model</span>(rand_spec)</span></code></pre></div>
<ul>
<li>Fit a model</li>
</ul>
<div class="sourceCode" id="cb1096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1096-1"><a href="machine-learning.html#cb1096-1"></a>rand_fit &lt;-<span class="st"> </span>rand_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)))</span></code></pre></div>
</div>
<div id="yardstick-2" class="section level4" number="7.6.3.2">
<h4><span class="header-section-number">7.6.3.2</span> yardstick</h4>
<ul>
<li>Let’s formally test prediction performance.</li>
</ul>
<p><strong>Metrics</strong></p>
<ul>
<li><p><code>accuracy</code>: The proportion of the data predicted correctly</p></li>
<li><p><code>precision</code>: Positive predictive value</p></li>
<li><p><code>recall</code> (specificity): True positive rate (e.g., healthy people really healthy)</p></li>
</ul>
<div class="sourceCode" id="cb1097"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1097-1"><a href="machine-learning.html#cb1097-1"></a><span class="co"># Define performance metrics </span></span>
<span id="cb1097-2"><a href="machine-learning.html#cb1097-2"></a>metrics &lt;-<span class="st"> </span>yardstick<span class="op">::</span><span class="kw">metric_set</span>(accuracy, precision, recall)</span>
<span id="cb1097-3"><a href="machine-learning.html#cb1097-3"></a></span>
<span id="cb1097-4"><a href="machine-learning.html#cb1097-4"></a>rand_fit_viz_metr &lt;-<span class="st"> </span><span class="kw">visualize_class_eval</span>(rand_fit)</span>
<span id="cb1097-5"><a href="machine-learning.html#cb1097-5"></a></span>
<span id="cb1097-6"><a href="machine-learning.html#cb1097-6"></a>rand_fit_viz_metr</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<ul>
<li>Visualize the confusion matrix.</li>
</ul>
<div class="sourceCode" id="cb1098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1098-1"><a href="machine-learning.html#cb1098-1"></a>rand_fit_viz_mat &lt;-<span class="st"> </span><span class="kw">visualize_class_conf</span>(rand_fit)</span>
<span id="cb1098-2"><a href="machine-learning.html#cb1098-2"></a></span>
<span id="cb1098-3"><a href="machine-learning.html#cb1098-3"></a>rand_fit_viz_mat</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
</div>
<div id="tune-2" class="section level4" number="7.6.3.3">
<h4><span class="header-section-number">7.6.3.3</span> tune</h4>
<div id="tune-ingredients-2" class="section level5" number="7.6.3.3.1">
<h5><span class="header-section-number">7.6.3.3.1</span> tune ingredients</h5>
<p>We focus on the following two hyperparameters:</p>
<ul>
<li><p><code>mtry</code>: The number of predictors to available for splitting at each node.</p></li>
<li><p><code>min_n</code>: The minimum number of data points needed to keep splitting nodes.</p></li>
</ul>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1099-1"><a href="machine-learning.html#cb1099-1"></a>tune_spec &lt;-<span class="st"> </span></span>
<span id="cb1099-2"><a href="machine-learning.html#cb1099-2"></a><span class="st">  </span><span class="kw">rand_forest</span>(</span>
<span id="cb1099-3"><a href="machine-learning.html#cb1099-3"></a>           <span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb1099-4"><a href="machine-learning.html#cb1099-4"></a>           </span>
<span id="cb1099-5"><a href="machine-learning.html#cb1099-5"></a>           <span class="co"># Tuning hyperparameters</span></span>
<span id="cb1099-6"><a href="machine-learning.html#cb1099-6"></a>           <span class="dt">mtry =</span> <span class="kw">tune</span>(), </span>
<span id="cb1099-7"><a href="machine-learning.html#cb1099-7"></a>           <span class="dt">min_n =</span> <span class="kw">tune</span>()) <span class="op">%&gt;%</span></span>
<span id="cb1099-8"><a href="machine-learning.html#cb1099-8"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb1099-9"><a href="machine-learning.html#cb1099-9"></a>             <span class="dt">seed =</span> <span class="dv">1234</span>, </span>
<span id="cb1099-10"><a href="machine-learning.html#cb1099-10"></a>             <span class="dt">importance =</span> <span class="st">&quot;permutation&quot;</span>)</span>
<span id="cb1099-11"><a href="machine-learning.html#cb1099-11"></a></span>
<span id="cb1099-12"><a href="machine-learning.html#cb1099-12"></a>rand_grid &lt;-<span class="st"> </span><span class="kw">grid_regular</span>(<span class="kw">mtry</span>(<span class="dt">range =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">10</span>)),</span>
<span id="cb1099-13"><a href="machine-learning.html#cb1099-13"></a>                          <span class="kw">min_n</span>(<span class="dt">range =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">10</span>)),</span>
<span id="cb1099-14"><a href="machine-learning.html#cb1099-14"></a>                          <span class="dt">levels =</span> <span class="dv">5</span>)</span>
<span id="cb1099-15"><a href="machine-learning.html#cb1099-15"></a></span>
<span id="cb1099-16"><a href="machine-learning.html#cb1099-16"></a>rand_grid <span class="op">%&gt;%</span></span>
<span id="cb1099-17"><a href="machine-learning.html#cb1099-17"></a><span class="st">  </span><span class="kw">count</span>(min_n)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   min_n     n
##   &lt;int&gt; &lt;int&gt;
## 1     2     5
## 2     4     5
## 3     6     5
## 4     8     5
## 5    10     5</code></pre>
<div class="sourceCode" id="cb1101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1101-1"><a href="machine-learning.html#cb1101-1"></a><span class="co"># 10-fold cross-validation</span></span>
<span id="cb1101-2"><a href="machine-learning.html#cb1101-2"></a></span>
<span id="cb1101-3"><a href="machine-learning.html#cb1101-3"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co"># for reproducibility </span></span>
<span id="cb1101-4"><a href="machine-learning.html#cb1101-4"></a></span>
<span id="cb1101-5"><a href="machine-learning.html#cb1101-5"></a>rand_folds &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)),</span>
<span id="cb1101-6"><a href="machine-learning.html#cb1101-6"></a>                       <span class="dt">strata =</span> target)</span></code></pre></div>
</div>
<div id="add-these-elements-to-a-workflow-2" class="section level5" number="7.6.3.3.2">
<h5><span class="header-section-number">7.6.3.3.2</span> Add these elements to a workflow</h5>
<div class="sourceCode" id="cb1102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1102-1"><a href="machine-learning.html#cb1102-1"></a><span class="co"># Update workflow </span></span>
<span id="cb1102-2"><a href="machine-learning.html#cb1102-2"></a>rand_wf &lt;-<span class="st"> </span>rand_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">update_model</span>(tune_spec)</span>
<span id="cb1102-3"><a href="machine-learning.html#cb1102-3"></a></span>
<span id="cb1102-4"><a href="machine-learning.html#cb1102-4"></a><span class="co"># Tuning results </span></span>
<span id="cb1102-5"><a href="machine-learning.html#cb1102-5"></a>rand_res &lt;-<span class="st"> </span>rand_wf <span class="op">%&gt;%</span></span>
<span id="cb1102-6"><a href="machine-learning.html#cb1102-6"></a><span class="st">  </span><span class="kw">tune_grid</span>(</span>
<span id="cb1102-7"><a href="machine-learning.html#cb1102-7"></a>    <span class="dt">resamples =</span> rand_folds, </span>
<span id="cb1102-8"><a href="machine-learning.html#cb1102-8"></a>    <span class="dt">grid =</span> rand_grid,</span>
<span id="cb1102-9"><a href="machine-learning.html#cb1102-9"></a>    <span class="dt">metrics =</span> metrics</span>
<span id="cb1102-10"><a href="machine-learning.html#cb1102-10"></a>  )</span></code></pre></div>
</div>
<div id="visualize-2" class="section level5" number="7.6.3.3.3">
<h5><span class="header-section-number">7.6.3.3.3</span> Visualize</h5>
<div class="sourceCode" id="cb1103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1103-1"><a href="machine-learning.html#cb1103-1"></a>rand_res <span class="op">%&gt;%</span></span>
<span id="cb1103-2"><a href="machine-learning.html#cb1103-2"></a><span class="st">  </span><span class="kw">collect_metrics</span>() <span class="op">%&gt;%</span></span>
<span id="cb1103-3"><a href="machine-learning.html#cb1103-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">min_n =</span> <span class="kw">factor</span>(min_n)) <span class="op">%&gt;%</span></span>
<span id="cb1103-4"><a href="machine-learning.html#cb1103-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(mtry, mean, <span class="dt">color =</span> min_n)) <span class="op">+</span></span>
<span id="cb1103-5"><a href="machine-learning.html#cb1103-5"></a><span class="st">  </span><span class="co"># Line + Point plot </span></span>
<span id="cb1103-6"><a href="machine-learning.html#cb1103-6"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="fl">0.6</span>) <span class="op">+</span></span>
<span id="cb1103-7"><a href="machine-learning.html#cb1103-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1103-8"><a href="machine-learning.html#cb1103-8"></a><span class="st">  </span><span class="co"># Subplots </span></span>
<span id="cb1103-9"><a href="machine-learning.html#cb1103-9"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>.metric, </span>
<span id="cb1103-10"><a href="machine-learning.html#cb1103-10"></a>             <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>, </span>
<span id="cb1103-11"><a href="machine-learning.html#cb1103-11"></a>             <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1103-12"><a href="machine-learning.html#cb1103-12"></a><span class="st">  </span><span class="co"># Log scale x </span></span>
<span id="cb1103-13"><a href="machine-learning.html#cb1103-13"></a><span class="st">  </span><span class="kw">scale_x_log10</span>(<span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">label_number</span>()) <span class="op">+</span></span>
<span id="cb1103-14"><a href="machine-learning.html#cb1103-14"></a><span class="st">  </span><span class="co"># Discrete color scale </span></span>
<span id="cb1103-15"><a href="machine-learning.html#cb1103-15"></a><span class="st">  </span><span class="kw">scale_color_viridis_d</span>(<span class="dt">option =</span> <span class="st">&quot;plasma&quot;</span>, <span class="dt">begin =</span> <span class="fl">.9</span>, <span class="dt">end =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb1103-16"><a href="machine-learning.html#cb1103-16"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;The number of predictors to be sampled&quot;</span>,</span>
<span id="cb1103-17"><a href="machine-learning.html#cb1103-17"></a>       <span class="dt">col =</span> <span class="st">&quot;The minimum number of data points needed for splitting&quot;</span>,</span>
<span id="cb1103-18"><a href="machine-learning.html#cb1103-18"></a>       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb1103-19"><a href="machine-learning.html#cb1103-19"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<div class="sourceCode" id="cb1104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1104-1"><a href="machine-learning.html#cb1104-1"></a><span class="co"># Optimal hyperparameter</span></span>
<span id="cb1104-2"><a href="machine-learning.html#cb1104-2"></a>best_tree &lt;-<span class="st"> </span><span class="kw">select_best</span>(rand_res, <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb1104-3"><a href="machine-learning.html#cb1104-3"></a></span>
<span id="cb1104-4"><a href="machine-learning.html#cb1104-4"></a>best_tree</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##    mtry min_n .config
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;  
## 1     1     2 Model01</code></pre>
<div class="sourceCode" id="cb1106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1106-1"><a href="machine-learning.html#cb1106-1"></a><span class="co"># Add the hyperparameter to the workflow </span></span>
<span id="cb1106-2"><a href="machine-learning.html#cb1106-2"></a>finalize_tree &lt;-<span class="st"> </span>rand_wf <span class="op">%&gt;%</span></span>
<span id="cb1106-3"><a href="machine-learning.html#cb1106-3"></a><span class="st">  </span><span class="kw">finalize_workflow</span>(best_tree)</span></code></pre></div>
<div class="sourceCode" id="cb1107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1107-1"><a href="machine-learning.html#cb1107-1"></a>rand_fit_tuned &lt;-<span class="st"> </span>finalize_tree <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1107-2"><a href="machine-learning.html#cb1107-2"></a><span class="st">  </span><span class="kw">fit</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)))</span>
<span id="cb1107-3"><a href="machine-learning.html#cb1107-3"></a></span>
<span id="cb1107-4"><a href="machine-learning.html#cb1107-4"></a><span class="co"># Metrics </span></span>
<span id="cb1107-5"><a href="machine-learning.html#cb1107-5"></a>(rand_fit_viz_metr <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Non-tuned&quot;</span>)) <span class="op">/</span><span class="st"> </span>(<span class="kw">visualize_class_eval</span>(rand_fit_tuned) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tuned&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<div class="sourceCode" id="cb1108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1108-1"><a href="machine-learning.html#cb1108-1"></a><span class="co"># Confusion matrix </span></span>
<span id="cb1108-2"><a href="machine-learning.html#cb1108-2"></a>(rand_fit_viz_mat <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Non-tuned&quot;</span>)) <span class="op">/</span><span class="st"> </span>(<span class="kw">visualize_class_conf</span>(rand_fit_tuned) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tuned&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-44-2.png" width="672" /></p>
<ul>
<li>Visualize variable importance</li>
</ul>
<div class="sourceCode" id="cb1109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1109-1"><a href="machine-learning.html#cb1109-1"></a>rand_fit_tuned <span class="op">%&gt;%</span></span>
<span id="cb1109-2"><a href="machine-learning.html#cb1109-2"></a><span class="st">  </span><span class="kw">pull_workflow_fit</span>() <span class="op">%&gt;%</span></span>
<span id="cb1109-3"><a href="machine-learning.html#cb1109-3"></a><span class="st">  </span>vip<span class="op">::</span><span class="kw">vip</span>()</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
</div>
<div id="test-fit-2" class="section level5" number="7.6.3.3.4">
<h5><span class="header-section-number">7.6.3.3.4</span> Test fit</h5>
<ul>
<li>Apply the tuned model to the test dataset</li>
</ul>
<div class="sourceCode" id="cb1110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1110-1"><a href="machine-learning.html#cb1110-1"></a>test_fit &lt;-<span class="st"> </span>finalize_tree <span class="op">%&gt;%</span></span>
<span id="cb1110-2"><a href="machine-learning.html#cb1110-2"></a><span class="st">  </span><span class="kw">fit</span>(test_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> test_y_class)))</span>
<span id="cb1110-3"><a href="machine-learning.html#cb1110-3"></a></span>
<span id="cb1110-4"><a href="machine-learning.html#cb1110-4"></a><span class="kw">evaluate_class</span>(test_fit)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy  binary         0.933
## 2 precision binary         0.973
## 3 recall    binary         0.878</code></pre>
</div>
</div>
</div>
<div id="boosting-xgboost" class="section level3" number="7.6.4">
<h3><span class="header-section-number">7.6.4</span> Boosting (XGboost)</h3>
<div id="parsnip-3" class="section level4" number="7.6.4.1">
<h4><span class="header-section-number">7.6.4.1</span> parsnip</h4>
<ul>
<li>Build a model</li>
</ul>
<ol style="list-style-type: decimal">
<li>Specify a model</li>
<li>Specify an engine</li>
<li>Specify a mode</li>
</ol>
<div class="sourceCode" id="cb1112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1112-1"><a href="machine-learning.html#cb1112-1"></a><span class="co"># workflow </span></span>
<span id="cb1112-2"><a href="machine-learning.html#cb1112-2"></a>xg_wf &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">add_formula</span>(target<span class="op">~</span>.)</span>
<span id="cb1112-3"><a href="machine-learning.html#cb1112-3"></a></span>
<span id="cb1112-4"><a href="machine-learning.html#cb1112-4"></a><span class="co"># spec </span></span>
<span id="cb1112-5"><a href="machine-learning.html#cb1112-5"></a>xg_spec &lt;-<span class="st"> </span><span class="kw">boost_tree</span>(</span>
<span id="cb1112-6"><a href="machine-learning.html#cb1112-6"></a>  </span>
<span id="cb1112-7"><a href="machine-learning.html#cb1112-7"></a>           <span class="co"># Mode </span></span>
<span id="cb1112-8"><a href="machine-learning.html#cb1112-8"></a>           <span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb1112-9"><a href="machine-learning.html#cb1112-9"></a>           </span>
<span id="cb1112-10"><a href="machine-learning.html#cb1112-10"></a>           <span class="co"># Tuning hyperparameters</span></span>
<span id="cb1112-11"><a href="machine-learning.html#cb1112-11"></a>           </span>
<span id="cb1112-12"><a href="machine-learning.html#cb1112-12"></a>           <span class="co"># The number of trees to fit, aka boosting iterations</span></span>
<span id="cb1112-13"><a href="machine-learning.html#cb1112-13"></a>           <span class="dt">trees =</span> <span class="kw">c</span>(<span class="dv">100</span>, <span class="dv">300</span>, <span class="dv">500</span>, <span class="dv">700</span>, <span class="dv">900</span>),</span>
<span id="cb1112-14"><a href="machine-learning.html#cb1112-14"></a>           <span class="co"># The depth of the decision tree (how many levels of splits).</span></span>
<span id="cb1112-15"><a href="machine-learning.html#cb1112-15"></a>             <span class="dt">tree_depth =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>), </span>
<span id="cb1112-16"><a href="machine-learning.html#cb1112-16"></a>           <span class="co"># Learning rate: lower means the ensemble will adapt more slowly.</span></span>
<span id="cb1112-17"><a href="machine-learning.html#cb1112-17"></a>           <span class="dt">learn_rate =</span> <span class="kw">c</span>(<span class="fl">0.0001</span>, <span class="fl">0.01</span>, <span class="fl">0.2</span>),</span>
<span id="cb1112-18"><a href="machine-learning.html#cb1112-18"></a>           <span class="co"># Stop splitting a tree if we only have this many obs in a tree node.</span></span>
<span id="cb1112-19"><a href="machine-learning.html#cb1112-19"></a>             <span class="dt">min_n =</span> 10L</span>
<span id="cb1112-20"><a href="machine-learning.html#cb1112-20"></a>          ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1112-21"><a href="machine-learning.html#cb1112-21"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) </span>
<span id="cb1112-22"><a href="machine-learning.html#cb1112-22"></a></span>
<span id="cb1112-23"><a href="machine-learning.html#cb1112-23"></a>xg_wf &lt;-<span class="st"> </span>xg_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">add_model</span>(xg_spec)</span></code></pre></div>
<ul>
<li>Fit a model</li>
</ul>
<div class="sourceCode" id="cb1113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1113-1"><a href="machine-learning.html#cb1113-1"></a>xg_fit &lt;-<span class="st"> </span>xg_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)))</span></code></pre></div>
<pre><code>## Warning in begin_iteration:end_iteration: numerical expression has 5 elements:
## only the first used</code></pre>
</div>
<div id="yardstick-3" class="section level4" number="7.6.4.2">
<h4><span class="header-section-number">7.6.4.2</span> yardstick</h4>
<ul>
<li>Let’s formally test prediction performance.</li>
</ul>
<p><strong>Metrics</strong></p>
<ul>
<li><p><code>accuracy</code>: The proportion of the data predicted correctly</p></li>
<li><p><code>precision</code>: Positive predictive value</p></li>
<li><p><code>recall</code> (specificity): True positive rate (e.g., healthy people really healthy)</p></li>
</ul>
<div class="sourceCode" id="cb1115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1115-1"><a href="machine-learning.html#cb1115-1"></a>metrics &lt;-<span class="st"> </span><span class="kw">metric_set</span>(yardstick<span class="op">::</span>accuracy, </span>
<span id="cb1115-2"><a href="machine-learning.html#cb1115-2"></a>                      yardstick<span class="op">::</span>precision, </span>
<span id="cb1115-3"><a href="machine-learning.html#cb1115-3"></a>                      yardstick<span class="op">::</span>recall)</span>
<span id="cb1115-4"><a href="machine-learning.html#cb1115-4"></a></span>
<span id="cb1115-5"><a href="machine-learning.html#cb1115-5"></a><span class="kw">evaluate_class</span>(xg_fit)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy  binary         0.733
## 2 precision binary         0.730
## 3 recall    binary         0.659</code></pre>
<div class="sourceCode" id="cb1117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1117-1"><a href="machine-learning.html#cb1117-1"></a>xg_fit_viz_metr &lt;-<span class="st"> </span><span class="kw">visualize_class_eval</span>(xg_fit)</span>
<span id="cb1117-2"><a href="machine-learning.html#cb1117-2"></a></span>
<span id="cb1117-3"><a href="machine-learning.html#cb1117-3"></a>xg_fit_viz_metr</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<ul>
<li>Visualize the confusion matrix.</li>
</ul>
<div class="sourceCode" id="cb1118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1118-1"><a href="machine-learning.html#cb1118-1"></a>xg_fit_viz_mat &lt;-<span class="st"> </span><span class="kw">visualize_class_conf</span>(xg_fit)</span>
<span id="cb1118-2"><a href="machine-learning.html#cb1118-2"></a></span>
<span id="cb1118-3"><a href="machine-learning.html#cb1118-3"></a>xg_fit_viz_mat</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
</div>
<div id="tune-3" class="section level4" number="7.6.4.3">
<h4><span class="header-section-number">7.6.4.3</span> tune</h4>
<div id="tune-ingredients-3" class="section level5" number="7.6.4.3.1">
<h5><span class="header-section-number">7.6.4.3.1</span> tune ingredients</h5>
<ul>
<li>We focus on the following hyperparameters: <code>trees,</code> <code>tree_depth,</code> <code>learn_rate,</code> <code>min_n,</code> <code>mtry,</code> <code>loss_reduction,</code> and <code>sample_size</code></li>
</ul>
<div class="sourceCode" id="cb1119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1119-1"><a href="machine-learning.html#cb1119-1"></a>tune_spec &lt;-<span class="st"> </span></span>
<span id="cb1119-2"><a href="machine-learning.html#cb1119-2"></a><span class="st">  </span>xg_spec &lt;-<span class="st"> </span><span class="kw">boost_tree</span>(</span>
<span id="cb1119-3"><a href="machine-learning.html#cb1119-3"></a>  </span>
<span id="cb1119-4"><a href="machine-learning.html#cb1119-4"></a>           <span class="co"># Mode </span></span>
<span id="cb1119-5"><a href="machine-learning.html#cb1119-5"></a>           <span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb1119-6"><a href="machine-learning.html#cb1119-6"></a>           </span>
<span id="cb1119-7"><a href="machine-learning.html#cb1119-7"></a>           <span class="co"># Tuning hyperparameters</span></span>
<span id="cb1119-8"><a href="machine-learning.html#cb1119-8"></a>           </span>
<span id="cb1119-9"><a href="machine-learning.html#cb1119-9"></a>           <span class="co"># The number of trees to fit, aka boosting iterations</span></span>
<span id="cb1119-10"><a href="machine-learning.html#cb1119-10"></a>           <span class="dt">trees =</span> <span class="kw">tune</span>(),</span>
<span id="cb1119-11"><a href="machine-learning.html#cb1119-11"></a>           <span class="co"># The depth of the decision tree (how many levels of splits).</span></span>
<span id="cb1119-12"><a href="machine-learning.html#cb1119-12"></a>             <span class="dt">tree_depth =</span> <span class="kw">tune</span>(), </span>
<span id="cb1119-13"><a href="machine-learning.html#cb1119-13"></a>           <span class="co"># Learning rate: lower means the ensemble will adapt more slowly.</span></span>
<span id="cb1119-14"><a href="machine-learning.html#cb1119-14"></a>           <span class="dt">learn_rate =</span> <span class="kw">tune</span>(),</span>
<span id="cb1119-15"><a href="machine-learning.html#cb1119-15"></a>           <span class="co"># Stop splitting a tree if we only have this many obs in a tree node.</span></span>
<span id="cb1119-16"><a href="machine-learning.html#cb1119-16"></a>             <span class="dt">min_n =</span> <span class="kw">tune</span>(),</span>
<span id="cb1119-17"><a href="machine-learning.html#cb1119-17"></a>           <span class="dt">loss_reduction =</span> <span class="kw">tune</span>(),</span>
<span id="cb1119-18"><a href="machine-learning.html#cb1119-18"></a>           <span class="co"># The number of randomly selected hyperparameters </span></span>
<span id="cb1119-19"><a href="machine-learning.html#cb1119-19"></a>           <span class="dt">mtry =</span> <span class="kw">tune</span>(), </span>
<span id="cb1119-20"><a href="machine-learning.html#cb1119-20"></a>           <span class="co"># The size of the data set used for modeling within an iteration</span></span>
<span id="cb1119-21"><a href="machine-learning.html#cb1119-21"></a>           <span class="dt">sample_size =</span> <span class="kw">tune</span>()</span>
<span id="cb1119-22"><a href="machine-learning.html#cb1119-22"></a>          ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1119-23"><a href="machine-learning.html#cb1119-23"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) </span>
<span id="cb1119-24"><a href="machine-learning.html#cb1119-24"></a></span>
<span id="cb1119-25"><a href="machine-learning.html#cb1119-25"></a><span class="co"># Space-filling hyperparameter grids </span></span>
<span id="cb1119-26"><a href="machine-learning.html#cb1119-26"></a>xg_grid &lt;-<span class="st"> </span><span class="kw">grid_latin_hypercube</span>(</span>
<span id="cb1119-27"><a href="machine-learning.html#cb1119-27"></a>  <span class="kw">trees</span>(),</span>
<span id="cb1119-28"><a href="machine-learning.html#cb1119-28"></a>  <span class="kw">tree_depth</span>(),</span>
<span id="cb1119-29"><a href="machine-learning.html#cb1119-29"></a>  <span class="kw">learn_rate</span>(),</span>
<span id="cb1119-30"><a href="machine-learning.html#cb1119-30"></a>  <span class="kw">min_n</span>(),</span>
<span id="cb1119-31"><a href="machine-learning.html#cb1119-31"></a>  <span class="kw">loss_reduction</span>(), </span>
<span id="cb1119-32"><a href="machine-learning.html#cb1119-32"></a>  <span class="dt">sample_size =</span> <span class="kw">sample_prop</span>(),</span>
<span id="cb1119-33"><a href="machine-learning.html#cb1119-33"></a>  <span class="kw">finalize</span>(<span class="kw">mtry</span>(), train_x_class),</span>
<span id="cb1119-34"><a href="machine-learning.html#cb1119-34"></a>  <span class="dt">size =</span> <span class="dv">30</span></span>
<span id="cb1119-35"><a href="machine-learning.html#cb1119-35"></a>  )</span>
<span id="cb1119-36"><a href="machine-learning.html#cb1119-36"></a></span>
<span id="cb1119-37"><a href="machine-learning.html#cb1119-37"></a><span class="co"># 10-fold cross-validation</span></span>
<span id="cb1119-38"><a href="machine-learning.html#cb1119-38"></a></span>
<span id="cb1119-39"><a href="machine-learning.html#cb1119-39"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co"># for reproducibility </span></span>
<span id="cb1119-40"><a href="machine-learning.html#cb1119-40"></a></span>
<span id="cb1119-41"><a href="machine-learning.html#cb1119-41"></a>xg_folds &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)),</span>
<span id="cb1119-42"><a href="machine-learning.html#cb1119-42"></a>                     <span class="dt">strata =</span> target)</span></code></pre></div>
</div>
<div id="add-these-elements-to-a-workflow-3" class="section level5" number="7.6.4.3.2">
<h5><span class="header-section-number">7.6.4.3.2</span> Add these elements to a workflow</h5>
<div class="sourceCode" id="cb1120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1120-1"><a href="machine-learning.html#cb1120-1"></a><span class="co"># Update workflow </span></span>
<span id="cb1120-2"><a href="machine-learning.html#cb1120-2"></a>xg_wf &lt;-<span class="st"> </span>xg_wf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">update_model</span>(tune_spec)</span>
<span id="cb1120-3"><a href="machine-learning.html#cb1120-3"></a></span>
<span id="cb1120-4"><a href="machine-learning.html#cb1120-4"></a><span class="co"># Tuning results </span></span>
<span id="cb1120-5"><a href="machine-learning.html#cb1120-5"></a>xg_res &lt;-<span class="st"> </span>xg_wf <span class="op">%&gt;%</span></span>
<span id="cb1120-6"><a href="machine-learning.html#cb1120-6"></a><span class="st">  </span><span class="kw">tune_grid</span>(</span>
<span id="cb1120-7"><a href="machine-learning.html#cb1120-7"></a>    <span class="dt">resamples =</span> xg_folds, </span>
<span id="cb1120-8"><a href="machine-learning.html#cb1120-8"></a>    <span class="dt">grid =</span> xg_grid,</span>
<span id="cb1120-9"><a href="machine-learning.html#cb1120-9"></a>    <span class="dt">control =</span> <span class="kw">control_grid</span>(<span class="dt">save_pred =</span> <span class="ot">TRUE</span>)</span>
<span id="cb1120-10"><a href="machine-learning.html#cb1120-10"></a>  )</span></code></pre></div>
</div>
<div id="visualize-3" class="section level5" number="7.6.4.3.3">
<h5><span class="header-section-number">7.6.4.3.3</span> Visualize</h5>
<div class="sourceCode" id="cb1121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1121-1"><a href="machine-learning.html#cb1121-1"></a>xg_res <span class="op">%&gt;%</span></span>
<span id="cb1121-2"><a href="machine-learning.html#cb1121-2"></a><span class="st">  </span><span class="kw">collect_metrics</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1121-3"><a href="machine-learning.html#cb1121-3"></a><span class="st">  </span><span class="kw">filter</span>(.metric <span class="op">==</span><span class="st"> &quot;roc_auc&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1121-4"><a href="machine-learning.html#cb1121-4"></a><span class="st">  </span><span class="kw">pivot_longer</span>(mtry<span class="op">:</span>sample_size,</span>
<span id="cb1121-5"><a href="machine-learning.html#cb1121-5"></a>               <span class="dt">values_to =</span> <span class="st">&quot;value&quot;</span>,</span>
<span id="cb1121-6"><a href="machine-learning.html#cb1121-6"></a>               <span class="dt">names_to =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1121-7"><a href="machine-learning.html#cb1121-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">y =</span> mean, <span class="dt">color =</span> parameter)) <span class="op">+</span></span>
<span id="cb1121-8"><a href="machine-learning.html#cb1121-8"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb1121-9"><a href="machine-learning.html#cb1121-9"></a><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span>parameter, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>) <span class="op">+</span></span>
<span id="cb1121-10"><a href="machine-learning.html#cb1121-10"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;AUC&quot;</span>,</span>
<span id="cb1121-11"><a href="machine-learning.html#cb1121-11"></a>         <span class="dt">x =</span> <span class="ot">NULL</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<div class="sourceCode" id="cb1122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1122-1"><a href="machine-learning.html#cb1122-1"></a><span class="co"># Optimal hyperparameter</span></span>
<span id="cb1122-2"><a href="machine-learning.html#cb1122-2"></a>best_xg &lt;-<span class="st"> </span><span class="kw">select_best</span>(xg_res, <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb1122-3"><a href="machine-learning.html#cb1122-3"></a></span>
<span id="cb1122-4"><a href="machine-learning.html#cb1122-4"></a>best_xg </span></code></pre></div>
<pre><code>## # A tibble: 1 x 8
##    mtry trees min_n tree_depth  learn_rate loss_reduction sample_size .config
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;int&gt;       &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
## 1     6    98     4         13 0.000000211  0.00000000336       0.422 Model26</code></pre>
<div class="sourceCode" id="cb1124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1124-1"><a href="machine-learning.html#cb1124-1"></a><span class="co"># Add the hyperparameter to the workflow </span></span>
<span id="cb1124-2"><a href="machine-learning.html#cb1124-2"></a>finalize_xg &lt;-<span class="st"> </span>xg_wf <span class="op">%&gt;%</span></span>
<span id="cb1124-3"><a href="machine-learning.html#cb1124-3"></a><span class="st">  </span><span class="kw">finalize_workflow</span>(best_xg)</span></code></pre></div>
<div class="sourceCode" id="cb1125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1125-1"><a href="machine-learning.html#cb1125-1"></a>xg_fit_tuned &lt;-<span class="st"> </span>finalize_xg <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1125-2"><a href="machine-learning.html#cb1125-2"></a><span class="st">  </span><span class="kw">fit</span>(train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> train_y_class)))</span>
<span id="cb1125-3"><a href="machine-learning.html#cb1125-3"></a></span>
<span id="cb1125-4"><a href="machine-learning.html#cb1125-4"></a><span class="co"># Metrics </span></span>
<span id="cb1125-5"><a href="machine-learning.html#cb1125-5"></a>(xg_fit_viz_metr <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Non-tuned&quot;</span>)) <span class="op">/</span><span class="st"> </span>(<span class="kw">visualize_class_eval</span>(xg_fit_tuned) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tuned&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<div class="sourceCode" id="cb1126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1126-1"><a href="machine-learning.html#cb1126-1"></a><span class="co"># Confusion matrix </span></span>
<span id="cb1126-2"><a href="machine-learning.html#cb1126-2"></a>(xg_fit_viz_mat <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Non-tuned&quot;</span>)) <span class="op">/</span><span class="st"> </span>(<span class="kw">visualize_class_conf</span>(xg_fit_tuned) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tuned&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-56-2.png" width="672" /></p>
<ul>
<li>Visualize variable importance</li>
</ul>
<div class="sourceCode" id="cb1127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1127-1"><a href="machine-learning.html#cb1127-1"></a>xg_fit_tuned <span class="op">%&gt;%</span></span>
<span id="cb1127-2"><a href="machine-learning.html#cb1127-2"></a><span class="st">  </span><span class="kw">pull_workflow_fit</span>() <span class="op">%&gt;%</span></span>
<span id="cb1127-3"><a href="machine-learning.html#cb1127-3"></a><span class="st">  </span>vip<span class="op">::</span><span class="kw">vip</span>()</span></code></pre></div>
<pre><code>## Warning: `as.tibble()` is deprecated as of tibble 2.0.0.
## Please use `as_tibble()` instead.
## The signature and semantics have changed, see `?as_tibble`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
</div>
<div id="test-fit-3" class="section level5" number="7.6.4.3.4">
<h5><span class="header-section-number">7.6.4.3.4</span> Test fit</h5>
<ul>
<li>Apply the tuned model to the test dataset</li>
</ul>
<div class="sourceCode" id="cb1129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1129-1"><a href="machine-learning.html#cb1129-1"></a>test_fit &lt;-<span class="st"> </span>finalize_xg <span class="op">%&gt;%</span></span>
<span id="cb1129-2"><a href="machine-learning.html#cb1129-2"></a><span class="st">  </span><span class="kw">fit</span>(test_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">tibble</span>(<span class="dt">target =</span> test_y_class)))</span>
<span id="cb1129-3"><a href="machine-learning.html#cb1129-3"></a></span>
<span id="cb1129-4"><a href="machine-learning.html#cb1129-4"></a><span class="kw">evaluate_class</span>(test_fit)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy  binary         0.8  
## 2 precision binary         0.795
## 3 recall    binary         0.756</code></pre>
</div>
</div>
</div>
<div id="stacking-superlearner" class="section level3" number="7.6.5">
<h3><span class="header-section-number">7.6.5</span> Stacking (SuperLearner)</h3>
<p>This stacking part of the book heavily relies on <a href="https://github.com/dlab-berkeley/Machine-Learning-in-R/blob/master/07-ensembles.Rmd">Chris Kennedy’s notebook</a>.</p>
<div id="overview-1" class="section level4" number="7.6.5.1">
<h4><span class="header-section-number">7.6.5.1</span> Overview</h4>
<div id="stacking" class="section level5" number="7.6.5.1.1">
<h5><span class="header-section-number">7.6.5.1.1</span> Stacking</h5>
<p>Wolpert, D.H., 1992. <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.1533">Stacked generalization</a>. <em>Neural networks</em>, 5(2), pp.241-259.</p>
<p>Breiman, L., 1996. [Stacked regressions]((<a href="https://statistics.berkeley.edu/sites/default/files/tech-reports/367.pdf" class="uri">https://statistics.berkeley.edu/sites/default/files/tech-reports/367.pdf</a>). <em>Machine learning</em>, 24(1), pp.49-64.</p>
</div>
<div id="superlearner" class="section level5" number="7.6.5.1.2">
<h5><span class="header-section-number">7.6.5.1.2</span> SuperLearner</h5>
<p>The <a href="https://cran.r-project.org/web/packages/SuperLearner/index.html">“SuperLearner” R package</a> is a method that simplifies ensemble learning by allowing you to simultaneously evaluate the cross-validated performance of multiple algorithms and/or a single algorithm with differently tuned hyperparameters. This is a generally advisable approach to machine learning instead of fitting single algorithms.</p>
<p>Let’s see how the four classification algorithms you learned in this workshop (1-lasso, 2-decision tree, 3-random forest, and 4-gradient boosted trees) compare to each other and also to 5-binary logistic regression (<code>glm</code>) and to the 6-mean of Y as a benchmark algorithm, in terms of their cross-validated error!</p>
<p>A “wrapper” is a short function that adapts an algorithm for the SuperLearner package. Check out the different algorithm wrappers offered by SuperLearner:</p>
</div>
</div>
<div id="choose-algorithms" class="section level4" number="7.6.5.2">
<h4><span class="header-section-number">7.6.5.2</span> Choose algorithms</h4>
<div class="sourceCode" id="cb1131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1131-1"><a href="machine-learning.html#cb1131-1"></a><span class="co"># Review available models </span></span>
<span id="cb1131-2"><a href="machine-learning.html#cb1131-2"></a>SuperLearner<span class="op">::</span><span class="kw">listWrappers</span>()</span></code></pre></div>
<pre><code>## All prediction algorithm wrappers in SuperLearner:</code></pre>
<pre><code>##  [1] &quot;SL.bartMachine&quot;      &quot;SL.bayesglm&quot;         &quot;SL.biglasso&quot;        
##  [4] &quot;SL.caret&quot;            &quot;SL.caret.rpart&quot;      &quot;SL.cforest&quot;         
##  [7] &quot;SL.earth&quot;            &quot;SL.extraTrees&quot;       &quot;SL.gam&quot;             
## [10] &quot;SL.gbm&quot;              &quot;SL.glm&quot;              &quot;SL.glm.interaction&quot; 
## [13] &quot;SL.glmnet&quot;           &quot;SL.ipredbagg&quot;        &quot;SL.kernelKnn&quot;       
## [16] &quot;SL.knn&quot;              &quot;SL.ksvm&quot;             &quot;SL.lda&quot;             
## [19] &quot;SL.leekasso&quot;         &quot;SL.lm&quot;               &quot;SL.loess&quot;           
## [22] &quot;SL.logreg&quot;           &quot;SL.mean&quot;             &quot;SL.nnet&quot;            
## [25] &quot;SL.nnls&quot;             &quot;SL.polymars&quot;         &quot;SL.qda&quot;             
## [28] &quot;SL.randomForest&quot;     &quot;SL.ranger&quot;           &quot;SL.ridge&quot;           
## [31] &quot;SL.rpart&quot;            &quot;SL.rpartPrune&quot;       &quot;SL.speedglm&quot;        
## [34] &quot;SL.speedlm&quot;          &quot;SL.step&quot;             &quot;SL.step.forward&quot;    
## [37] &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot;          &quot;SL.svm&quot;             
## [40] &quot;SL.template&quot;         &quot;SL.xgboost&quot;</code></pre>
<pre><code>## 
## All screening algorithm wrappers in SuperLearner:</code></pre>
<pre><code>## [1] &quot;All&quot;
## [1] &quot;screen.corP&quot;           &quot;screen.corRank&quot;        &quot;screen.glmnet&quot;        
## [4] &quot;screen.randomForest&quot;   &quot;screen.SIS&quot;            &quot;screen.template&quot;      
## [7] &quot;screen.ttest&quot;          &quot;write.screen.template&quot;</code></pre>
<div class="sourceCode" id="cb1136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1136-1"><a href="machine-learning.html#cb1136-1"></a><span class="co"># Compile the algorithm wrappers to be used.</span></span>
<span id="cb1136-2"><a href="machine-learning.html#cb1136-2"></a>sl_lib &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="co"># Marginal mean of the outcome () </span></span>
<span id="cb1136-3"><a href="machine-learning.html#cb1136-3"></a>            <span class="st">&quot;SL.glmnet&quot;</span>, <span class="co"># GLM with lasso/elasticnet regularization </span></span>
<span id="cb1136-4"><a href="machine-learning.html#cb1136-4"></a>            <span class="st">&quot;SL.rpart&quot;</span>, <span class="co"># Decision tree </span></span>
<span id="cb1136-5"><a href="machine-learning.html#cb1136-5"></a>            <span class="st">&quot;SL.ranger&quot;</span>, <span class="co"># Random forest  </span></span>
<span id="cb1136-6"><a href="machine-learning.html#cb1136-6"></a>            <span class="st">&quot;SL.xgboost&quot;</span>) <span class="co"># Xgbboost </span></span></code></pre></div>
</div>
<div id="fit-model" class="section level4" number="7.6.5.3">
<h4><span class="header-section-number">7.6.5.3</span> Fit model</h4>
<p>Fit the ensemble!</p>
<div class="sourceCode" id="cb1137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1137-1"><a href="machine-learning.html#cb1137-1"></a><span class="co"># This is a seed that is compatible with multicore parallel processing.</span></span>
<span id="cb1137-2"><a href="machine-learning.html#cb1137-2"></a><span class="co"># See ?set.seed for more information.</span></span>
<span id="cb1137-3"><a href="machine-learning.html#cb1137-3"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="st">&quot;L&#39;Ecuyer-CMRG&quot;</span>) </span>
<span id="cb1137-4"><a href="machine-learning.html#cb1137-4"></a></span>
<span id="cb1137-5"><a href="machine-learning.html#cb1137-5"></a><span class="co"># This will take a few minutes to execute - take a look at the .html file to see the output!</span></span>
<span id="cb1137-6"><a href="machine-learning.html#cb1137-6"></a>cv_sl &lt;-<span class="st">  </span>SuperLearner<span class="op">::</span><span class="kw">CV.SuperLearner</span>(</span>
<span id="cb1137-7"><a href="machine-learning.html#cb1137-7"></a>  <span class="dt">Y =</span> <span class="kw">as.numeric</span>(<span class="kw">as.character</span>(train_y_class)),</span>
<span id="cb1137-8"><a href="machine-learning.html#cb1137-8"></a>  <span class="dt">X =</span> train_x_class,</span>
<span id="cb1137-9"><a href="machine-learning.html#cb1137-9"></a>  <span class="dt">family =</span> <span class="kw">binomial</span>(),</span>
<span id="cb1137-10"><a href="machine-learning.html#cb1137-10"></a>  <span class="co"># For a real analysis we would use V = 10.</span></span>
<span id="cb1137-11"><a href="machine-learning.html#cb1137-11"></a>  <span class="dt">cvControl =</span> <span class="kw">list</span>(<span class="dt">V =</span> 5L, <span class="dt">stratifyCV =</span> <span class="ot">TRUE</span>),</span>
<span id="cb1137-12"><a href="machine-learning.html#cb1137-12"></a>  <span class="dt">SL.library =</span> sl_lib,</span>
<span id="cb1137-13"><a href="machine-learning.html#cb1137-13"></a>  <span class="dt">verbose =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
</div>
<div id="risk" class="section level4" number="7.6.5.4">
<h4><span class="header-section-number">7.6.5.4</span> Risk</h4>
<p>Risk is the average loss, and loss is how far off the prediction was for an individual observation. The lower the risk, the fewer errors the model makes in its prediction. SuperLearner’s default loss metric is squared error <span class="math inline">\((y_{actual} - y_{predicted})^2\)</span>, so the risk is the mean-squared error (just like in ordinary least <em>squares</em> regression). View the summary, plot results, and compute the Area Under the ROC Curve (AUC)!</p>
<div id="summary" class="section level5" number="7.6.5.4.1">
<h5><span class="header-section-number">7.6.5.4.1</span> Summary</h5>
<ul>
<li><code>Discrete SL</code> chooses the best single learner (in this case, <code>SL.glmnet</code> or <code>lasso</code>).</li>
<li><code>SuperLearner</code> takes a weighted average of the <strong>models</strong> using the coefficients (importance of each individual learner in the overall ensemble). Coefficient 0 means that learner is not used at all.</li>
<li><code>SL.mean_All</code> (the weighted mean of <span class="math inline">\(Y\)</span>) is a benchmark algorithm (ignoring features).</li>
</ul>
<div class="sourceCode" id="cb1138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1138-1"><a href="machine-learning.html#cb1138-1"></a><span class="kw">summary</span>(cv_sl)</span></code></pre></div>
<pre><code>## 
## Call:  
## SuperLearner::CV.SuperLearner(Y = as.numeric(as.character(train_y_class)),  
##     X = train_x_class, family = binomial(), SL.library = sl_lib, verbose = FALSE,  
##     cvControl = list(V = 5L, stratifyCV = TRUE)) 
## 
## Risk is based on: Mean Squared Error
## 
## All risk estimates are based on V =  5 
## 
##       Algorithm     Ave        se      Min     Max
##   Super Learner 0.12989 0.0150061 0.066139 0.17771
##     Discrete SL 0.12877 0.0151015 0.063232 0.17771
##     SL.mean_All 0.24802 0.0030531 0.247747 0.24893
##   SL.glmnet_All 0.12877 0.0151015 0.063232 0.17771
##    SL.rpart_All 0.18111 0.0197908 0.137814 0.22434
##   SL.ranger_All 0.14382 0.0134084 0.098362 0.17659
##  SL.xgboost_All 0.15678 0.0169203 0.125424 0.17136</code></pre>
</div>
<div id="plot" class="section level5" number="7.6.5.4.2">
<h5><span class="header-section-number">7.6.5.4.2</span> Plot</h5>
<div class="sourceCode" id="cb1140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1140-1"><a href="machine-learning.html#cb1140-1"></a><span class="co"># Plot the cross-validated risk estimate with 95% CIs.</span></span>
<span id="cb1140-2"><a href="machine-learning.html#cb1140-2"></a></span>
<span id="cb1140-3"><a href="machine-learning.html#cb1140-3"></a><span class="kw">plot</span>(cv_sl)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/cvsl_review-1.png" width="672" /></p>
</div>
</div>
<div id="compute-auc-for-all-estimators" class="section level4" number="7.6.5.5">
<h4><span class="header-section-number">7.6.5.5</span> Compute AUC for all estimators</h4>
<p><strong>ROC</strong></p>
<p>ROC: an ROC (receiver operating characteristic curve) plots the relationship between True Positive Rate (Y-axis) and FALSE Positive Rate (X-axis).</p>
<div class="figure">
<img src="https://developers.google.com/machine-learning/crash-course/images/AUC.svg" alt="" />
<p class="caption">Area Under the ROC Curve</p>
</div>
<p><strong>AUC</strong></p>
<p>AUC: Area Under the ROC Curve</p>
<p>1 = perfect</p>
<p>0.5 = no better than chance</p>
<div class="sourceCode" id="cb1141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1141-1"><a href="machine-learning.html#cb1141-1"></a><span class="kw">auc_table</span>(cv_sl)</span></code></pre></div>
<pre><code>##                      auc         se  ci_lower  ci_upper      p-value
## SL.mean_All    0.5000000 0.06879264 0.3651689 0.6348311 3.510583e-09
## SL.rpart_All   0.7911151 0.04274540 0.7073356 0.8748945 6.063783e-03
## SL.xgboost_All 0.8465704 0.02821590 0.7912682 0.9018725 3.327502e-02
## SL.ranger_All  0.8771186 0.02369447 0.8306783 0.9235589 1.852476e-01
## SuperLearner   0.8962367 0.02136205 0.8543678 0.9381055 4.608180e-01
## SL.glmnet_All  0.8983381 0.02119261 0.8568013 0.9398749 5.000000e-01
## DiscreteSL     0.8983381 0.02119261 0.8568013 0.9398749 5.000000e-01</code></pre>
<div id="plot-the-roc-curve-for-the-best-estimator-discretsl" class="section level5" number="7.6.5.5.1">
<h5><span class="header-section-number">7.6.5.5.1</span> Plot the ROC curve for the best estimator (DiscretSL)</h5>
<div class="sourceCode" id="cb1143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1143-1"><a href="machine-learning.html#cb1143-1"></a><span class="kw">plot_roc</span>(cv_sl)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
</div>
<div id="review-weight-distribution-for-the-superlearner" class="section level5" number="7.6.5.5.2">
<h5><span class="header-section-number">7.6.5.5.2</span> Review weight distribution for the SuperLearner</h5>
<div class="sourceCode" id="cb1144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1144-1"><a href="machine-learning.html#cb1144-1"></a><span class="kw">print</span>(<span class="kw">cvsl_weights</span>(cv_sl), <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>##  # Learner    Mean      SD     Min     Max
##  1  glmnet 0.92421 0.07095 0.84928 1.00000
##  2  ranger 0.06432 0.06919 0.00000 0.15072
##  3 xgboost 0.01059 0.02368 0.00000 0.05295
##  4    mean 0.00082 0.00183 0.00000 0.00410
##  5   rpart 0.00006 0.00013 0.00000 0.00030</code></pre>
<p>General stacking approach is available in the tidymodels framework through <a href="https://github.com/tidymodels/stacks"><code>stacks</code></a> package (developmental stage).</p>
<p>However, SuperLearner is currently not available in the tidymodels framework. If you’d like to, you can easily build and add a parsnip model. If you are interested in knowing more about it, please take a look at <a href="https://www.tidymodels.org/learn/develop/models/">this vignette</a> of the tidymodels.</p>
</div>
</div>
</div>
<div id="applications-2" class="section level3" number="7.6.6">
<h3><span class="header-section-number">7.6.6</span> Applications</h3>
<div id="bandit-algorithm-optimizing-an-experiment" class="section level4" number="7.6.6.1">
<h4><span class="header-section-number">7.6.6.1</span> Bandit algorithm (optimizing an experiment)</h4>
</div>
<div id="causal-forest-estimating-heterogeneous-treatment-effect" class="section level4" number="7.6.6.2">
<h4><span class="header-section-number">7.6.6.2</span> Causal forest (estimating heterogeneous treatment effect)</h4>
</div>
</div>
</div>
<div id="unsupervised-learning" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Unsupervised learning</h2>
<p>x -&gt; f - &gt; y (not defined)</p>
<div id="dimension-reduction" class="section level3" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Dimension reduction</h3>
<div class="figure">
<img src="https://i.stack.imgur.com/Q7HIP.gif" alt="" />
<p class="caption">Projecting 2D-data to a line (PCA). From vas3k.com</p>
</div>
<div id="correlation-analysis" class="section level4" number="7.7.1.1">
<h4><span class="header-section-number">7.7.1.1</span> Correlation analysis</h4>
<ul>
<li><p>Notice some problems?</p>
<ul>
<li><p>NAs</p></li>
<li><p>Scaling issues</p></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1146-1"><a href="machine-learning.html#cb1146-1"></a>data_original <span class="op">%&gt;%</span></span>
<span id="cb1146-2"><a href="machine-learning.html#cb1146-2"></a><span class="st">  </span>corrr<span class="op">::</span><span class="kw">correlate</span>()</span></code></pre></div>
<pre><code>## 
## Correlation method: &#39;pearson&#39;
## Missing treated using: &#39;pairwise.complete.obs&#39;</code></pre>
<pre><code>## # A tibble: 14 x 15
##    rowname     age     sex      cp trestbps     chol      fbs restecg  thalach
##    &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;
##  1 age     NA      -0.0984 -0.0687   0.279   0.214    0.121   -0.116  -0.399  
##  2 sex     -0.0984 NA      -0.0494  -0.0568 -0.198    0.0450  -0.0582 -0.0440 
##  3 cp      -0.0687 -0.0494 NA        0.0476 -0.0769   0.0944   0.0444  0.296  
##  4 trestb…  0.279  -0.0568  0.0476  NA       0.123    0.178   -0.114  -0.0467 
##  5 chol     0.214  -0.198  -0.0769   0.123  NA        0.0133  -0.151  -0.00994
##  6 fbs      0.121   0.0450  0.0944   0.178   0.0133  NA       -0.0842 -0.00857
##  7 restecg -0.116  -0.0582  0.0444  -0.114  -0.151   -0.0842  NA       0.0441 
##  8 thalach -0.399  -0.0440  0.296   -0.0467 -0.00994 -0.00857  0.0441 NA      
##  9 exang    0.0968  0.142  -0.394    0.0676  0.0670   0.0257  -0.0707 -0.379  
## 10 oldpeak  0.210   0.0961 -0.149    0.193   0.0540   0.00575 -0.0588 -0.344  
## 11 slope   -0.169  -0.0307  0.120   -0.121  -0.00404 -0.0599   0.0930  0.387  
## 12 ca       0.276   0.118  -0.181    0.101   0.0705   0.138   -0.0720 -0.213  
## 13 thal     0.0680  0.210  -0.162    0.0622  0.0988  -0.0320  -0.0120 -0.0964 
## 14 target  -0.225  -0.281   0.434   -0.145  -0.0852  -0.0280   0.137   0.422  
## # … with 6 more variables: exang &lt;dbl&gt;, oldpeak &lt;dbl&gt;, slope &lt;dbl&gt;, ca &lt;dbl&gt;,
## #   thal &lt;dbl&gt;, target &lt;dbl&gt;</code></pre>
</div>
<div id="preprocessing" class="section level4" number="7.7.1.2">
<h4><span class="header-section-number">7.7.1.2</span> Preprocessing</h4>
<p><code>recipe</code> is essential for preprocesssing multiple features at once.</p>
<div class="sourceCode" id="cb1149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1149-1"><a href="machine-learning.html#cb1149-1"></a>pca_recipe &lt;-<span class="st"> </span><span class="kw">recipe</span>(<span class="op">~</span>., <span class="dt">data =</span> data_original) <span class="op">%&gt;%</span></span>
<span id="cb1149-2"><a href="machine-learning.html#cb1149-2"></a><span class="st">  </span><span class="co"># Imputing NAs using mean </span></span>
<span id="cb1149-3"><a href="machine-learning.html#cb1149-3"></a><span class="st">  </span><span class="kw">step_meanimpute</span>(<span class="kw">all_predictors</span>()) <span class="op">%&gt;%</span></span>
<span id="cb1149-4"><a href="machine-learning.html#cb1149-4"></a><span class="st">  </span><span class="co"># Normalize some numeric variables </span></span>
<span id="cb1149-5"><a href="machine-learning.html#cb1149-5"></a><span class="st">  </span><span class="kw">step_normalize</span>(<span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;trestbps&quot;</span>, <span class="st">&quot;chol&quot;</span>, <span class="st">&quot;thalach&quot;</span>, <span class="st">&quot;oldpeak&quot;</span>)) </span></code></pre></div>
</div>
<div id="pca-analysis" class="section level4" number="7.7.1.3">
<h4><span class="header-section-number">7.7.1.3</span> PCA analysis</h4>
<div class="sourceCode" id="cb1150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1150-1"><a href="machine-learning.html#cb1150-1"></a>pca_res &lt;-<span class="st"> </span>pca_recipe <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1150-2"><a href="machine-learning.html#cb1150-2"></a><span class="st">  </span><span class="kw">step_pca</span>(<span class="kw">all_predictors</span>(), </span>
<span id="cb1150-3"><a href="machine-learning.html#cb1150-3"></a>           <span class="dt">id =</span> <span class="st">&quot;pca&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># id argument identifies each PCA step </span></span>
<span id="cb1150-4"><a href="machine-learning.html#cb1150-4"></a><span class="st">  </span><span class="kw">prep</span>()</span>
<span id="cb1150-5"><a href="machine-learning.html#cb1150-5"></a></span>
<span id="cb1150-6"><a href="machine-learning.html#cb1150-6"></a>pca_res <span class="op">%&gt;%</span></span>
<span id="cb1150-7"><a href="machine-learning.html#cb1150-7"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">id =</span> <span class="st">&quot;pca&quot;</span>) </span></code></pre></div>
<pre><code>## # A tibble: 196 x 4
##    terms        value component id   
##    &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
##  1 age      -0.00101  PC1       pca  
##  2 sex       0.216    PC1       pca  
##  3 cp        0.321    PC1       pca  
##  4 trestbps  0.00118  PC1       pca  
##  5 chol     -0.000292 PC1       pca  
##  6 fbs       0.0468   PC1       pca  
##  7 restecg   0.166    PC1       pca  
##  8 thalach   0.0137   PC1       pca  
##  9 exang     0.0962   PC1       pca  
## 10 oldpeak  -0.00863  PC1       pca  
## # … with 186 more rows</code></pre>
<div id="screeplot" class="section level5" number="7.7.1.3.1">
<h5><span class="header-section-number">7.7.1.3.1</span> Screeplot</h5>
<div class="sourceCode" id="cb1152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1152-1"><a href="machine-learning.html#cb1152-1"></a>pca_recipe <span class="op">%&gt;%</span></span>
<span id="cb1152-2"><a href="machine-learning.html#cb1152-2"></a><span class="st">  </span><span class="kw">step_pca</span>(<span class="kw">all_predictors</span>(), </span>
<span id="cb1152-3"><a href="machine-learning.html#cb1152-3"></a>           <span class="dt">id =</span> <span class="st">&quot;pca&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># id argument identifies each PCA step </span></span>
<span id="cb1152-4"><a href="machine-learning.html#cb1152-4"></a><span class="st">  </span><span class="kw">prep</span>() <span class="op">%&gt;%</span></span>
<span id="cb1152-5"><a href="machine-learning.html#cb1152-5"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">id =</span> <span class="st">&quot;pca&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;variance&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1152-6"><a href="machine-learning.html#cb1152-6"></a><span class="st">  </span><span class="kw">filter</span>(terms <span class="op">==</span><span class="st"> &quot;percent variance&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1152-7"><a href="machine-learning.html#cb1152-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> component, <span class="dt">y =</span> value)) <span class="op">+</span></span>
<span id="cb1152-8"><a href="machine-learning.html#cb1152-8"></a><span class="st">    </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1152-9"><a href="machine-learning.html#cb1152-9"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;PCAs of heart disease&quot;</span>,</span>
<span id="cb1152-10"><a href="machine-learning.html#cb1152-10"></a>         <span class="dt">y =</span> <span class="st">&quot;% of variance&quot;</span>,</span>
<span id="cb1152-11"><a href="machine-learning.html#cb1152-11"></a>         <span class="dt">title =</span> <span class="st">&quot;Scree plot&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
</div>
<div id="view-factor-loadings" class="section level5" number="7.7.1.3.2">
<h5><span class="header-section-number">7.7.1.3.2</span> View factor loadings</h5>
<p>Loadings are the covariances between the features and the principal components (=eigenvectors).</p>
<div class="sourceCode" id="cb1153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1153-1"><a href="machine-learning.html#cb1153-1"></a>pca_recipe <span class="op">%&gt;%</span></span>
<span id="cb1153-2"><a href="machine-learning.html#cb1153-2"></a><span class="st">  </span><span class="kw">step_pca</span>(<span class="kw">all_predictors</span>(), </span>
<span id="cb1153-3"><a href="machine-learning.html#cb1153-3"></a>           <span class="dt">id =</span> <span class="st">&quot;pca&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># id argument identifies each PCA step </span></span>
<span id="cb1153-4"><a href="machine-learning.html#cb1153-4"></a><span class="st">  </span><span class="kw">prep</span>() <span class="op">%&gt;%</span></span>
<span id="cb1153-5"><a href="machine-learning.html#cb1153-5"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">id =</span> <span class="st">&quot;pca&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1153-6"><a href="machine-learning.html#cb1153-6"></a><span class="st">  </span><span class="kw">filter</span>(component <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PC1&quot;</span>, <span class="st">&quot;PC2&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb1153-7"><a href="machine-learning.html#cb1153-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(terms, value), <span class="dt">y =</span> value, </span>
<span id="cb1153-8"><a href="machine-learning.html#cb1153-8"></a>             <span class="dt">fill =</span> component)) <span class="op">+</span></span>
<span id="cb1153-9"><a href="machine-learning.html#cb1153-9"></a><span class="st">    </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span></span>
<span id="cb1153-10"><a href="machine-learning.html#cb1153-10"></a><span class="st">    </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1153-11"><a href="machine-learning.html#cb1153-11"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Terms&quot;</span>,</span>
<span id="cb1153-12"><a href="machine-learning.html#cb1153-12"></a>         <span class="dt">y =</span> <span class="st">&quot;Contribtutions&quot;</span>,</span>
<span id="cb1153-13"><a href="machine-learning.html#cb1153-13"></a>         <span class="dt">fill =</span> <span class="st">&quot;PCAs&quot;</span>) </span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<p>You can use these low-dimensional data to solve prediction problems. Compressing feature space via dimension reduction techniques is called feature extraction. PCA is one way of doing this.</p>
</div>
</div>
</div>
<div id="topic-modeling" class="section level3" number="7.7.2">
<h3><span class="header-section-number">7.7.2</span> Topic modeling</h3>
<div id="setup-3" class="section level4" number="7.7.2.1">
<h4><span class="header-section-number">7.7.2.1</span> Setup</h4>
<div class="sourceCode" id="cb1154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1154-1"><a href="machine-learning.html#cb1154-1"></a>pacman<span class="op">::</span><span class="kw">p_load</span>(tidytext, <span class="co"># tidy text analysis</span></span>
<span id="cb1154-2"><a href="machine-learning.html#cb1154-2"></a>               glue, <span class="co"># paste string and objects                </span></span>
<span id="cb1154-3"><a href="machine-learning.html#cb1154-3"></a>               stm, <span class="co"># structural topic modeling</span></span>
<span id="cb1154-4"><a href="machine-learning.html#cb1154-4"></a>               gutenbergr) <span class="co"># toy datasets </span></span></code></pre></div>
</div>
<div id="dataset-1" class="section level4" number="7.7.2.2">
<h4><span class="header-section-number">7.7.2.2</span> Dataset</h4>
<p>The data munging process draws on <a href="https://juliasilge.com/blog/sherlock-holmes-stm/">Julia Silge’s blog post</a>.</p>
<div class="sourceCode" id="cb1155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1155-1"><a href="machine-learning.html#cb1155-1"></a>sherlock_raw &lt;-<span class="st"> </span><span class="kw">gutenberg_download</span>(<span class="dv">1661</span>)</span></code></pre></div>
<pre><code>## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest</code></pre>
<pre><code>## Using mirror http://aleph.gutenberg.org</code></pre>
<div class="sourceCode" id="cb1158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1158-1"><a href="machine-learning.html#cb1158-1"></a><span class="kw">glimpse</span>(sherlock_raw)</span></code></pre></div>
<pre><code>## Rows: 12,648
## Columns: 2
## $ gutenberg_id &lt;int&gt; 1661, 1661, 1661, 1661, 1661, 1661, 1661, 1661, 1661, 16…
## $ text         &lt;chr&gt; &quot;THE ADVENTURES OF SHERLOCK HOLMES&quot;, &quot;&quot;, &quot;by&quot;, &quot;&quot;, &quot;SIR …</code></pre>
<div class="sourceCode" id="cb1160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1160-1"><a href="machine-learning.html#cb1160-1"></a>sherlock &lt;-<span class="st"> </span>sherlock_raw <span class="op">%&gt;%</span></span>
<span id="cb1160-2"><a href="machine-learning.html#cb1160-2"></a><span class="st">  </span><span class="co"># Mutate story using a conditional statement </span></span>
<span id="cb1160-3"><a href="machine-learning.html#cb1160-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">story =</span> <span class="kw">ifelse</span>(<span class="kw">str_starts</span>(text, <span class="st">&quot;ADVENTURE&quot;</span>), </span>
<span id="cb1160-4"><a href="machine-learning.html#cb1160-4"></a>                                   text, <span class="ot">NA</span>)) <span class="op">%&gt;%</span></span>
<span id="cb1160-5"><a href="machine-learning.html#cb1160-5"></a><span class="st">  </span><span class="co"># Fill in missing values with next value  </span></span>
<span id="cb1160-6"><a href="machine-learning.html#cb1160-6"></a><span class="st">  </span>tidyr<span class="op">::</span><span class="kw">fill</span>(story, <span class="dt">.direction =</span> <span class="st">&quot;down&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1160-7"><a href="machine-learning.html#cb1160-7"></a><span class="st">  </span><span class="co"># Filter </span></span>
<span id="cb1160-8"><a href="machine-learning.html#cb1160-8"></a><span class="st">  </span><span class="kw">filter</span>(story <span class="op">!=</span><span class="st"> &quot;THE ADVENTURES OF SHERLOCK HOLMES&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1160-9"><a href="machine-learning.html#cb1160-9"></a><span class="st">  </span><span class="co"># Factor </span></span>
<span id="cb1160-10"><a href="machine-learning.html#cb1160-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">story =</span> <span class="kw">factor</span>(story, <span class="dt">levels =</span> <span class="kw">unique</span>(story)))</span>
<span id="cb1160-11"><a href="machine-learning.html#cb1160-11"></a></span>
<span id="cb1160-12"><a href="machine-learning.html#cb1160-12"></a>sherlock &lt;-<span class="st"> </span>sherlock[,<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>]</span></code></pre></div>
</div>
<div id="key-ideas" class="section level4" number="7.7.2.3">
<h4><span class="header-section-number">7.7.2.3</span> Key ideas</h4>
<ul>
<li><p>Topics as <strong>distributions</strong> of words</p></li>
<li><p>Documents as <strong>distributions</strong> of topics</p></li>
<li><p>What distributions?</p>
<ul>
<li><p>Probability</p></li>
<li><p>Multinominal (e.g., Latent Dirichlet Distribution)</p></li>
</ul></li>
<li><p>Words lie on a lower dimensional space (dimension reduction)</p></li>
<li><p>Co-occurrence of words (clustering)</p></li>
<li><p>Bag of words (feature engineering)</p>
<ul>
<li>Upside: easy and fast (also quite working well)</li>
<li>Downside: ignored grammatical structures and rich interactions among words (Alternative: word embeddings. Please check out <a href="http://text2vec.org/">text2vec</a>)</li>
</ul></li>
</ul>
</div>
<div id="exploratory-data-analysis" class="section level4" number="7.7.2.4">
<h4><span class="header-section-number">7.7.2.4</span> Exploratory data analysis</h4>
<div class="sourceCode" id="cb1161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1161-1"><a href="machine-learning.html#cb1161-1"></a>sherlock_n &lt;-<span class="st"> </span>sherlock <span class="op">%&gt;%</span></span>
<span id="cb1161-2"><a href="machine-learning.html#cb1161-2"></a><span class="st">  </span><span class="kw">unnest_tokens</span>(<span class="dt">output =</span> word,</span>
<span id="cb1161-3"><a href="machine-learning.html#cb1161-3"></a>                <span class="dt">input =</span> text) <span class="op">%&gt;%</span></span>
<span id="cb1161-4"><a href="machine-learning.html#cb1161-4"></a><span class="st">  </span><span class="kw">count</span>(story, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</span>
<span id="cb1161-5"><a href="machine-learning.html#cb1161-5"></a></span>
<span id="cb1161-6"><a href="machine-learning.html#cb1161-6"></a>sherlock_total_n &lt;-<span class="st"> </span>sherlock_n <span class="op">%&gt;%</span></span>
<span id="cb1161-7"><a href="machine-learning.html#cb1161-7"></a><span class="st">  </span><span class="kw">group_by</span>(story) <span class="op">%&gt;%</span></span>
<span id="cb1161-8"><a href="machine-learning.html#cb1161-8"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">total =</span> <span class="kw">sum</span>(n))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb1163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1163-1"><a href="machine-learning.html#cb1163-1"></a>sherlock_words &lt;-<span class="st"> </span>sherlock_n <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(sherlock_total_n)</span></code></pre></div>
<pre><code>## Joining, by = &quot;story&quot;</code></pre>
<div class="sourceCode" id="cb1165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1165-1"><a href="machine-learning.html#cb1165-1"></a>sherlock_words <span class="op">%&gt;%</span></span>
<span id="cb1165-2"><a href="machine-learning.html#cb1165-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">freq =</span> n<span class="op">/</span>total) <span class="op">%&gt;%</span></span>
<span id="cb1165-3"><a href="machine-learning.html#cb1165-3"></a><span class="st">  </span><span class="kw">group_by</span>(story) <span class="op">%&gt;%</span></span>
<span id="cb1165-4"><a href="machine-learning.html#cb1165-4"></a><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb1165-5"><a href="machine-learning.html#cb1165-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(word, freq), </span>
<span id="cb1165-6"><a href="machine-learning.html#cb1165-6"></a>             <span class="dt">y =</span> freq, </span>
<span id="cb1165-7"><a href="machine-learning.html#cb1165-7"></a>             <span class="dt">fill =</span> story)) <span class="op">+</span></span>
<span id="cb1165-8"><a href="machine-learning.html#cb1165-8"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1165-9"><a href="machine-learning.html#cb1165-9"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1165-10"><a href="machine-learning.html#cb1165-10"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>story, </span>
<span id="cb1165-11"><a href="machine-learning.html#cb1165-11"></a>             <span class="dt">ncol =</span> <span class="dv">2</span>, </span>
<span id="cb1165-12"><a href="machine-learning.html#cb1165-12"></a>             <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="op">+</span></span>
<span id="cb1165-13"><a href="machine-learning.html#cb1165-13"></a><span class="st">  </span><span class="kw">scale_fill_viridis_d</span>() <span class="op">+</span></span>
<span id="cb1165-14"><a href="machine-learning.html#cb1165-14"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<pre><code>## Selecting by freq</code></pre>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
</div>
<div id="stm" class="section level4" number="7.7.2.5">
<h4><span class="header-section-number">7.7.2.5</span> STM</h4>
<div id="turn-text-into-document-term-matrix" class="section level5" number="7.7.2.5.1">
<h5><span class="header-section-number">7.7.2.5.1</span> Turn text into document-term matrix</h5>
<p><code>stm</code> package has its own preprocessing function.</p>
<div class="sourceCode" id="cb1167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1167-1"><a href="machine-learning.html#cb1167-1"></a>dtm &lt;-<span class="st"> </span><span class="kw">textProcessor</span>(<span class="dt">documents =</span> sherlock<span class="op">$</span>text,</span>
<span id="cb1167-2"><a href="machine-learning.html#cb1167-2"></a>                     <span class="dt">metadata =</span> sherlock, </span>
<span id="cb1167-3"><a href="machine-learning.html#cb1167-3"></a>                     <span class="dt">removestopwords =</span> <span class="ot">TRUE</span>,</span>
<span id="cb1167-4"><a href="machine-learning.html#cb1167-4"></a>                     <span class="dt">verbose =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
</div>
<div id="tuning-k" class="section level5" number="7.7.2.5.2">
<h5><span class="header-section-number">7.7.2.5.2</span> Tuning K</h5>
<ul>
<li>K is the number of topics.</li>
<li>Let’s try K = 5, 10, 15.</li>
</ul>
<div class="sourceCode" id="cb1168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1168-1"><a href="machine-learning.html#cb1168-1"></a>test_res &lt;-<span class="st"> </span><span class="kw">searchK</span>(dtm<span class="op">$</span>documents, dtm<span class="op">$</span>vocab, </span>
<span id="cb1168-2"><a href="machine-learning.html#cb1168-2"></a>                   <span class="dt">K =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>),</span>
<span id="cb1168-3"><a href="machine-learning.html#cb1168-3"></a>                   <span class="dt">prevalence =</span><span class="op">~</span><span class="st"> </span>story, </span>
<span id="cb1168-4"><a href="machine-learning.html#cb1168-4"></a>                   <span class="dt">data =</span> dtm<span class="op">$</span>meta)</span></code></pre></div>
<pre><code>## Beginning Spectral Initialization 
##   Calculating the gram matrix...
##   Finding anchor words...
##      .....
##   Recovering initialization...
##      ........................................................
## Initialization complete.
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.581) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -7.482, relative change = 1.312e-02) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -7.408, relative change = 9.916e-03) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -7.383, relative change = 3.336e-03) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -7.372, relative change = 1.424e-03) 
## Topic 1: holm, now, come, look, yes 
##  Topic 2: upon, littl, man, hand, door 
##  Topic 3: know, think, came, back, day 
##  Topic 4: said, will, can, face, matter 
##  Topic 5: one, see, shall, time, must 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -7.367, relative change = 6.889e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -7.365, relative change = 3.221e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 8 (approx. per word bound = -7.364, relative change = 1.281e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 9 (approx. per word bound = -7.364, relative change = 1.012e-05) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Model Converged 
## Beginning Spectral Initialization 
##   Calculating the gram matrix...
##   Finding anchor words...
##      ..........
##   Recovering initialization...
##      ........................................................
## Initialization complete.
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.666) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -7.481, relative change = 2.408e-02) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -7.387, relative change = 1.265e-02) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -7.361, relative change = 3.497e-03) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -7.351, relative change = 1.396e-03) 
## Topic 1: upon, littl, paper, even, came 
##  Topic 2: holm, back, two, busi, sat 
##  Topic 3: one, case, word, remark, point 
##  Topic 4: come, said, room, miss, say 
##  Topic 5: said, man, eye, yes, took 
##  Topic 6: may, just, away, fact, mind 
##  Topic 7: see, one, time, face, look 
##  Topic 8: know, now, can, hand, must 
##  Topic 9: will, sherlock, two, might, famili 
##  Topic 10: tabl, heard, die, might, record 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -7.346, relative change = 7.034e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -7.342, relative change = 5.221e-04) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 8 (approx. per word bound = -7.338, relative change = 5.161e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 9 (approx. per word bound = -7.336, relative change = 2.460e-04) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Model Converged 
## Beginning Spectral Initialization 
##   Calculating the gram matrix...
##   Finding anchor words...
##      ...............
##   Recovering initialization...
##      ........................................................
## Initialization complete.
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.738) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -7.461, relative change = 3.577e-02) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -7.367, relative change = 1.264e-02) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -7.343, relative change = 3.252e-03) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -7.333, relative change = 1.367e-03) 
## Topic 1: matter, like, made, much, street 
##  Topic 2: look, door, face, room, saw 
##  Topic 3: sir, someth, wife, mean, instant 
##  Topic 4: said, holm, ask, well, miss 
##  Topic 5: morn, littl, remark, quit, interest 
##  Topic 6: back, chair, close, get, step 
##  Topic 7: time, read, put, seen, part 
##  Topic 8: two, now, case, cri, yet 
##  Topic 9: upon, one, sherlock, famili, knew 
##  Topic 10: may, howev, tell, long, clear 
##  Topic 11: will, think, shall, good, came 
##  Topic 12: see, littl, hand, yes, way 
##  Topic 13: holm, answer, turn, return, mrs 
##  Topic 14: man, reason, certain, strang, crime 
##  Topic 15: might, twist, hand, never, come 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -7.328, relative change = 7.011e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -7.324, relative change = 4.535e-04) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 8 (approx. per word bound = -7.322, relative change = 3.650e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 9 (approx. per word bound = -7.320, relative change = 2.220e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 10 (approx. per word bound = -7.318, relative change = 2.408e-04) 
## Topic 1: matter, much, like, even, away 
##  Topic 2: look, room, door, face, saw 
##  Topic 3: sir, went, someth, wife, dark 
##  Topic 4: said, holm, well, ask, heard 
##  Topic 5: quit, morn, remark, left, give 
##  Topic 6: back, get, chair, step, close 
##  Topic 7: time, put, seen, paper, three 
##  Topic 8: two, case, cri, seem, yet 
##  Topic 9: upon, one, sherlock, knew, famili 
##  Topic 10: may, howev, tell, long, clear 
##  Topic 11: will, think, come, shall, can 
##  Topic 12: see, littl, hand, yes, way 
##  Topic 13: turn, holm, answer, return, observ 
##  Topic 14: man, reason, certain, strang, lord 
##  Topic 15: might, thing, follow, told, help 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 11 (approx. per word bound = -7.317, relative change = 1.808e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 12 (approx. per word bound = -7.316, relative change = 1.221e-04) 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Completing Iteration 13 (approx. per word bound = -7.315, relative change = 8.460e-05) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 14 (approx. per word bound = -7.315, relative change = 4.530e-05) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 15 (approx. per word bound = -7.315, relative change = 2.133e-05) 
## Topic 1: matter, much, like, even, made 
##  Topic 2: look, room, door, face, eye 
##  Topic 3: sir, went, someth, wife, dark 
##  Topic 4: said, holm, well, ask, know 
##  Topic 5: quit, remark, morn, left, found 
##  Topic 6: back, get, chair, step, close 
##  Topic 7: time, year, paper, put, seen 
##  Topic 8: two, case, seem, cri, yet 
##  Topic 9: upon, one, sherlock, knew, famili 
##  Topic 10: may, howev, tell, long, clear 
##  Topic 11: will, come, think, now, can 
##  Topic 12: littl, see, hand, yes, way 
##  Topic 13: turn, answer, return, holm, observ 
##  Topic 14: man, reason, certain, strang, lord 
##  Topic 15: might, make, thing, word, follow 
## ....................................................................................................
## Completed E-Step (2 seconds). 
## Completed M-Step. 
## Model Converged</code></pre>
</div>
<div id="evaludating-models" class="section level5" number="7.7.2.5.3">
<h5><span class="header-section-number">7.7.2.5.3</span> Evaludating models</h5>
<p>There are several metrics to assess the performance of topic models: the held-out likelihood, residuals, semantic coherence, and exclusivity. In this course, we examine the relationship between semantic coherence and exclusivity to understand the trade-off involved in selecting K.</p>
<div class="sourceCode" id="cb1170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1170-1"><a href="machine-learning.html#cb1170-1"></a>test_res<span class="op">$</span>results <span class="op">%&gt;%</span></span>
<span id="cb1170-2"><a href="machine-learning.html#cb1170-2"></a><span class="st">  </span><span class="kw">unnest</span>(K, exclus, semcoh) <span class="op">%&gt;%</span></span>
<span id="cb1170-3"><a href="machine-learning.html#cb1170-3"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(K, exclus, semcoh) <span class="op">%&gt;%</span></span>
<span id="cb1170-4"><a href="machine-learning.html#cb1170-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">K =</span> <span class="kw">as.factor</span>(K)) <span class="op">%&gt;%</span></span>
<span id="cb1170-5"><a href="machine-learning.html#cb1170-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> exclus, <span class="dt">y =</span> semcoh)) <span class="op">+</span></span>
<span id="cb1170-6"><a href="machine-learning.html#cb1170-6"></a><span class="st">    </span><span class="kw">geom_text</span>(<span class="dt">label =</span> <span class="kw">glue</span>(<span class="st">&quot;K = {test_res$results$K}&quot;</span>),</span>
<span id="cb1170-7"><a href="machine-learning.html#cb1170-7"></a>              <span class="dt">size =</span> <span class="dv">5</span>,</span>
<span id="cb1170-8"><a href="machine-learning.html#cb1170-8"></a>              <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: unnest() has a new interface. See ?unnest for details.
## Try `df %&gt;% unnest(c(K, exclus, semcoh))`, with `mutate()` if needed</code></pre>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
</div>
<div id="finalize" class="section level5" number="7.7.2.5.4">
<h5><span class="header-section-number">7.7.2.5.4</span> Finalize</h5>
<div class="sourceCode" id="cb1172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1172-1"><a href="machine-learning.html#cb1172-1"></a>final_stm &lt;-<span class="st"> </span><span class="kw">stm</span>(dtm<span class="op">$</span>documents, </span>
<span id="cb1172-2"><a href="machine-learning.html#cb1172-2"></a>                 dtm<span class="op">$</span>vocab, </span>
<span id="cb1172-3"><a href="machine-learning.html#cb1172-3"></a>                 <span class="dt">K =</span> <span class="dv">10</span>, <span class="dt">prevalence =</span><span class="op">~</span><span class="st"> </span>story,</span>
<span id="cb1172-4"><a href="machine-learning.html#cb1172-4"></a>                 <span class="dt">max.em.its =</span> <span class="dv">75</span>, </span>
<span id="cb1172-5"><a href="machine-learning.html#cb1172-5"></a>                 <span class="dt">data =</span> dtm<span class="op">$</span>meta, </span>
<span id="cb1172-6"><a href="machine-learning.html#cb1172-6"></a>                 <span class="dt">init.type=</span><span class="st">&quot;Spectral&quot;</span>,</span>
<span id="cb1172-7"><a href="machine-learning.html#cb1172-7"></a>                 <span class="dt">seed =</span> <span class="dv">1234567</span>,</span>
<span id="cb1172-8"><a href="machine-learning.html#cb1172-8"></a>                 <span class="dt">verbose =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
</div>
<div id="explore-the-results" class="section level5" number="7.7.2.5.5">
<h5><span class="header-section-number">7.7.2.5.5</span> Explore the results</h5>
<ul>
<li>Using the <code>stm</code> pacakge.</li>
</ul>
<div class="sourceCode" id="cb1173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1173-1"><a href="machine-learning.html#cb1173-1"></a><span class="co"># plot</span></span>
<span id="cb1173-2"><a href="machine-learning.html#cb1173-2"></a><span class="kw">plot</span>(final_stm)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<ul>
<li>Using ggplot2</li>
</ul>
<div class="sourceCode" id="cb1174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1174-1"><a href="machine-learning.html#cb1174-1"></a><span class="co"># tidy  </span></span>
<span id="cb1174-2"><a href="machine-learning.html#cb1174-2"></a>tidy_stm &lt;-<span class="st"> </span><span class="kw">tidy</span>(final_stm)</span>
<span id="cb1174-3"><a href="machine-learning.html#cb1174-3"></a></span>
<span id="cb1174-4"><a href="machine-learning.html#cb1174-4"></a><span class="co"># top terms</span></span>
<span id="cb1174-5"><a href="machine-learning.html#cb1174-5"></a>tidy_stm <span class="op">%&gt;%</span></span>
<span id="cb1174-6"><a href="machine-learning.html#cb1174-6"></a><span class="st">    </span><span class="kw">group_by</span>(topic) <span class="op">%&gt;%</span></span>
<span id="cb1174-7"><a href="machine-learning.html#cb1174-7"></a><span class="st">    </span><span class="kw">top_n</span>(<span class="dv">10</span>, beta) <span class="op">%&gt;%</span></span>
<span id="cb1174-8"><a href="machine-learning.html#cb1174-8"></a><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb1174-9"><a href="machine-learning.html#cb1174-9"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">fct_reorder</span>(term, beta), beta, <span class="dt">fill =</span> <span class="kw">as.factor</span>(topic))) <span class="op">+</span></span>
<span id="cb1174-10"><a href="machine-learning.html#cb1174-10"></a><span class="st">    </span><span class="kw">geom_col</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb1174-11"><a href="machine-learning.html#cb1174-11"></a><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>topic, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="op">+</span></span>
<span id="cb1174-12"><a href="machine-learning.html#cb1174-12"></a><span class="st">    </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1174-13"><a href="machine-learning.html#cb1174-13"></a><span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span>percent) <span class="op">+</span></span>
<span id="cb1174-14"><a href="machine-learning.html#cb1174-14"></a><span class="st">    </span><span class="kw">scale_fill_viridis_d</span>()</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
</div>
</div>
</div>
</div>
<div id="bias-and-fairness-in-machine-learning" class="section level2" number="7.8">
<h2><span class="header-section-number">7.8</span> Bias and fairness in machine learning</h2>
<p>This section introduces the issues surrounding the fairness and bias in machine learning applications with a focus on the ProPublica’s Analysis of the COMPAS algorithm. I revised <a href="https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb">the ProPublica’s original R and Python code</a> to increase its code readability.</p>
<div class="figure">
<img src="https://wp.technologyreview.com/wp-content/uploads/2019/10/mit-alg-yb-02-7.gif?fit=1444,962" alt="" />
<p class="caption">A gif of defendants being put into an algorithm by SELMAN DESIGN</p>
</div>
<p><strong>Outline</strong></p>
<ol style="list-style-type: decimal">
<li>Bias in the data</li>
</ol>
<ul>
<li>Risk of Recidivism Data</li>
<li>Risk of Violent Recidivism Data</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Bias in the algorithm</li>
</ol>
<p><strong>References</strong></p>
<p>For more information on the ProPublica’s Machine Bias project, we encourage to check out the following references.</p>
<ul>
<li><p><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing/">Argument</a> by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner</p></li>
<li><p><a href="https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/">Counterargument</a> by Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel</p></li>
<li><p><a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm/">Methodology</a></p></li>
</ul>
<div id="bias-in-the-data-risk-of-recidivism-analysis" class="section level3" number="7.8.1">
<h3><span class="header-section-number">7.8.1</span> Bias in the Data (Risk of Recidivism Analysis)</h3>
<div id="setup-4" class="section level4" number="7.8.1.1">
<h4><span class="header-section-number">7.8.1.1</span> Setup</h4>
<div class="sourceCode" id="cb1175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1175-1"><a href="machine-learning.html#cb1175-1"></a><span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;pacman&quot;</span>)) <span class="kw">install.packages</span>(<span class="st">&quot;pacman&quot;</span>)</span></code></pre></div>
<pre><code>## Loading required package: pacman</code></pre>
<div class="sourceCode" id="cb1177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1177-1"><a href="machine-learning.html#cb1177-1"></a>pacman<span class="op">::</span><span class="kw">p_load</span>(</span>
<span id="cb1177-2"><a href="machine-learning.html#cb1177-2"></a> tidyverse, <span class="co"># tidyverse packages </span></span>
<span id="cb1177-3"><a href="machine-learning.html#cb1177-3"></a> conflicted, <span class="co"># an alternative conflict resolution strategy </span></span>
<span id="cb1177-4"><a href="machine-learning.html#cb1177-4"></a> ggthemes, <span class="co"># other themes for ggplot2 </span></span>
<span id="cb1177-5"><a href="machine-learning.html#cb1177-5"></a> patchwork, <span class="co"># arranging ggplots</span></span>
<span id="cb1177-6"><a href="machine-learning.html#cb1177-6"></a> scales, <span class="co"># rescaling </span></span>
<span id="cb1177-7"><a href="machine-learning.html#cb1177-7"></a> survival, <span class="co"># survival analysis</span></span>
<span id="cb1177-8"><a href="machine-learning.html#cb1177-8"></a> broom, <span class="co"># for modeling</span></span>
<span id="cb1177-9"><a href="machine-learning.html#cb1177-9"></a> here, <span class="co"># reproducibility </span></span>
<span id="cb1177-10"><a href="machine-learning.html#cb1177-10"></a> glue <span class="co"># pasting strings and objects </span></span>
<span id="cb1177-11"><a href="machine-learning.html#cb1177-11"></a>)</span>
<span id="cb1177-12"><a href="machine-learning.html#cb1177-12"></a></span>
<span id="cb1177-13"><a href="machine-learning.html#cb1177-13"></a><span class="co"># To avoid conflicts </span></span>
<span id="cb1177-14"><a href="machine-learning.html#cb1177-14"></a><span class="kw">conflict_prefer</span>(<span class="st">&quot;filter&quot;</span>, <span class="st">&quot;dplyr&quot;</span>) </span></code></pre></div>
<pre><code>## [conflicted] Will prefer dplyr::filter over any other package</code></pre>
<div class="sourceCode" id="cb1179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1179-1"><a href="machine-learning.html#cb1179-1"></a><span class="kw">conflict_prefer</span>(<span class="st">&quot;select&quot;</span>, <span class="st">&quot;dplyr&quot;</span>) </span></code></pre></div>
<pre><code>## [conflicted] Will prefer dplyr::select over any other package</code></pre>
</div>
<div id="load-data" class="section level4" number="7.8.1.2">
<h4><span class="header-section-number">7.8.1.2</span> Load data</h4>
<p>We select fields for severity of charge, number of priors, demographics, age, sex, COMPAS scores, and whether each person was accused of a crime within two years.</p>
<div class="sourceCode" id="cb1181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1181-1"><a href="machine-learning.html#cb1181-1"></a>two_years &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;compas-scores-two-years.csv&quot;</span>))</span></code></pre></div>
<pre><code>## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt;
## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49]</code></pre>
<div class="sourceCode" id="cb1183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1183-1"><a href="machine-learning.html#cb1183-1"></a><span class="kw">glue</span>(<span class="st">&quot;N of observations (rows): {nrow(two_years)}</span></span>
<span id="cb1183-2"><a href="machine-learning.html#cb1183-2"></a><span class="st">      N of variables (columns): {ncol(two_years)}&quot;</span>)</span></code></pre></div>
<pre><code>## N of observations (rows): 7214
## N of variables (columns): 53</code></pre>
</div>
<div id="wrangling" class="section level4" number="7.8.1.3">
<h4><span class="header-section-number">7.8.1.3</span> Wrangling</h4>
<ul>
<li>Not all of the observations are useable for the first round of analysis.</li>
<li>There are a number of reasons to remove rows because of missing data:
<ul>
<li>If the charge date of a defendants COMPAS scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.</li>
<li>We coded the recidivist flag – is_recid – to be -1 if we could not find a COMPAS case at all.</li>
<li>In a similar vein, ordinary traffic offenses – those with a c_charge_degree of ‘O’ – will not result in Jail time are removed (only two of them).</li>
<li>We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.</li>
</ul></li>
<li>Create a function</li>
</ul>
<div class="sourceCode" id="cb1185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1185-1"><a href="machine-learning.html#cb1185-1"></a>wrangle_data &lt;-<span class="st"> </span><span class="cf">function</span>(data){</span>
<span id="cb1185-2"><a href="machine-learning.html#cb1185-2"></a></span>
<span id="cb1185-3"><a href="machine-learning.html#cb1185-3"></a>df &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1185-4"><a href="machine-learning.html#cb1185-4"></a><span class="st">    </span></span>
<span id="cb1185-5"><a href="machine-learning.html#cb1185-5"></a><span class="st">    </span><span class="co"># Select variables </span></span>
<span id="cb1185-6"><a href="machine-learning.html#cb1185-6"></a><span class="st">    </span><span class="kw">select</span>(age, c_charge_degree, race, age_cat, score_text, sex, priors_count, days_b_screening_arrest, decile_score, is_recid, two_year_recid, </span>
<span id="cb1185-7"><a href="machine-learning.html#cb1185-7"></a>         c_jail_in, c_jail_out) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1185-8"><a href="machine-learning.html#cb1185-8"></a><span class="st">    </span><span class="co"># Filter rows </span></span>
<span id="cb1185-9"><a href="machine-learning.html#cb1185-9"></a><span class="st">    </span><span class="kw">filter</span>(days_b_screening_arrest <span class="op">&lt;=</span><span class="st"> </span><span class="dv">30</span>,</span>
<span id="cb1185-10"><a href="machine-learning.html#cb1185-10"></a>           days_b_screening_arrest <span class="op">&gt;=</span><span class="st"> </span><span class="dv">-30</span>, </span>
<span id="cb1185-11"><a href="machine-learning.html#cb1185-11"></a>           is_recid <span class="op">!=</span><span class="st"> </span><span class="dv">-1</span>,</span>
<span id="cb1185-12"><a href="machine-learning.html#cb1185-12"></a>           c_charge_degree <span class="op">!=</span><span class="st"> &quot;O&quot;</span>,</span>
<span id="cb1185-13"><a href="machine-learning.html#cb1185-13"></a>           score_text <span class="op">!=</span><span class="st"> &#39;N/A&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1185-14"><a href="machine-learning.html#cb1185-14"></a><span class="st">    </span><span class="co"># Mutate variables </span></span>
<span id="cb1185-15"><a href="machine-learning.html#cb1185-15"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">length_of_stay =</span> <span class="kw">as.numeric</span>(<span class="kw">as.Date</span>(c_jail_out) <span class="op">-</span><span class="st"> </span><span class="kw">as.Date</span>(c_jail_in)),</span>
<span id="cb1185-16"><a href="machine-learning.html#cb1185-16"></a>           <span class="dt">c_charge_degree =</span> <span class="kw">factor</span>(c_charge_degree),</span>
<span id="cb1185-17"><a href="machine-learning.html#cb1185-17"></a>           <span class="dt">age_cat =</span> <span class="kw">factor</span>(age_cat),</span>
<span id="cb1185-18"><a href="machine-learning.html#cb1185-18"></a>           <span class="dt">race =</span> <span class="kw">factor</span>(race, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Caucasian&quot;</span>,<span class="st">&quot;African-American&quot;</span>,<span class="st">&quot;Hispanic&quot;</span>,<span class="st">&quot;Other&quot;</span>,<span class="st">&quot;Asian&quot;</span>,<span class="st">&quot;Native American&quot;</span>)),</span>
<span id="cb1185-19"><a href="machine-learning.html#cb1185-19"></a>           <span class="dt">sex =</span> <span class="kw">factor</span>(sex, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>,<span class="st">&quot;Female&quot;</span>)),</span>
<span id="cb1185-20"><a href="machine-learning.html#cb1185-20"></a>           <span class="dt">score_text =</span> <span class="kw">factor</span>(score_text, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>)),</span>
<span id="cb1185-21"><a href="machine-learning.html#cb1185-21"></a>           <span class="dt">score =</span> score_text,</span>
<span id="cb1185-22"><a href="machine-learning.html#cb1185-22"></a><span class="co"># I added this new variable to test whether measuring the DV as a binary or continuous var makes a difference </span></span>
<span id="cb1185-23"><a href="machine-learning.html#cb1185-23"></a>           <span class="dt">score_num =</span> <span class="kw">as.numeric</span>(score_text)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1185-24"><a href="machine-learning.html#cb1185-24"></a><span class="st">    </span><span class="co"># Rename variables </span></span>
<span id="cb1185-25"><a href="machine-learning.html#cb1185-25"></a><span class="st">    </span><span class="kw">rename</span>(<span class="dt">crime =</span> c_charge_degree,</span>
<span id="cb1185-26"><a href="machine-learning.html#cb1185-26"></a>           <span class="dt">gender =</span> sex)</span>
<span id="cb1185-27"><a href="machine-learning.html#cb1185-27"></a>        </span>
<span id="cb1185-28"><a href="machine-learning.html#cb1185-28"></a><span class="kw">return</span>(df)}</span></code></pre></div>
<ul>
<li>Apply the function to the data</li>
</ul>
<div class="sourceCode" id="cb1186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1186-1"><a href="machine-learning.html#cb1186-1"></a>df &lt;-<span class="st"> </span><span class="kw">wrangle_data</span>(two_years)</span>
<span id="cb1186-2"><a href="machine-learning.html#cb1186-2"></a></span>
<span id="cb1186-3"><a href="machine-learning.html#cb1186-3"></a><span class="kw">names</span>(df)</span></code></pre></div>
<pre><code>##  [1] &quot;age&quot;                     &quot;crime&quot;                  
##  [3] &quot;race&quot;                    &quot;age_cat&quot;                
##  [5] &quot;score_text&quot;              &quot;gender&quot;                 
##  [7] &quot;priors_count&quot;            &quot;days_b_screening_arrest&quot;
##  [9] &quot;decile_score&quot;            &quot;is_recid&quot;               
## [11] &quot;two_year_recid&quot;          &quot;c_jail_in&quot;              
## [13] &quot;c_jail_out&quot;              &quot;length_of_stay&quot;         
## [15] &quot;score&quot;                   &quot;score_num&quot;</code></pre>
<div class="sourceCode" id="cb1188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1188-1"><a href="machine-learning.html#cb1188-1"></a><span class="co"># Check whether the function works as expected</span></span>
<span id="cb1188-2"><a href="machine-learning.html#cb1188-2"></a><span class="kw">head</span>(df, <span class="dv">5</span>)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 16
##     age crime race  age_cat score_text gender priors_count days_b_screenin…
##   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt;      &lt;fct&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1    69 F     Other Greate… Low        Male              0               -1
## 2    34 F     Afri… 25 - 45 Low        Male              0               -1
## 3    24 F     Afri… Less t… Low        Male              4               -1
## 4    44 M     Other 25 - 45 Low        Male              0                0
## 5    41 F     Cauc… 25 - 45 Medium     Male             14               -1
## # … with 8 more variables: decile_score &lt;dbl&gt;, is_recid &lt;dbl&gt;,
## #   two_year_recid &lt;dbl&gt;, c_jail_in &lt;dttm&gt;, c_jail_out &lt;dttm&gt;,
## #   length_of_stay &lt;dbl&gt;, score &lt;fct&gt;, score_num &lt;dbl&gt;</code></pre>
</div>
<div id="descriptive-analysis" class="section level4" number="7.8.1.4">
<h4><span class="header-section-number">7.8.1.4</span> Descriptive analysis</h4>
<ul>
<li>Higher COMPAS scores are slightly correlated with a longer length of stay.</li>
</ul>
<div class="sourceCode" id="cb1190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1190-1"><a href="machine-learning.html#cb1190-1"></a><span class="kw">cor</span>(df<span class="op">$</span>length_of_stay, df<span class="op">$</span>decile_score)</span></code></pre></div>
<pre><code>## [1] 0.2073297</code></pre>
<div class="sourceCode" id="cb1192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1192-1"><a href="machine-learning.html#cb1192-1"></a>df <span class="op">%&gt;%</span></span>
<span id="cb1192-2"><a href="machine-learning.html#cb1192-2"></a><span class="st">  </span><span class="kw">group_by</span>(score) <span class="op">%&gt;%</span></span>
<span id="cb1192-3"><a href="machine-learning.html#cb1192-3"></a><span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span></span>
<span id="cb1192-4"><a href="machine-learning.html#cb1192-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> score, <span class="dt">y =</span> n)) <span class="op">+</span></span>
<span id="cb1192-5"><a href="machine-learning.html#cb1192-5"></a><span class="st">    </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1192-6"><a href="machine-learning.html#cb1192-6"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Score&quot;</span>,</span>
<span id="cb1192-7"><a href="machine-learning.html#cb1192-7"></a>         <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb1192-8"><a href="machine-learning.html#cb1192-8"></a>         <span class="dt">title =</span> <span class="st">&quot;Score distribution&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<p>Judges are often presented with two sets of scores from the COMPAS system – one that classifies people into High, Medium and Low risk, and a corresponding decile score. There is a clear downward trend in the decile scores as those scores increase for white defendants.</p>
<div class="sourceCode" id="cb1193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1193-1"><a href="machine-learning.html#cb1193-1"></a>df <span class="op">%&gt;%</span></span>
<span id="cb1193-2"><a href="machine-learning.html#cb1193-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">ordered</span>(decile_score))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1193-3"><a href="machine-learning.html#cb1193-3"></a><span class="st">          </span><span class="kw">geom_bar</span>() <span class="op">+</span></span>
<span id="cb1193-4"><a href="machine-learning.html#cb1193-4"></a><span class="st">          </span><span class="kw">facet_wrap</span>(<span class="op">~</span>race, <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1193-5"><a href="machine-learning.html#cb1193-5"></a><span class="st">          </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Decile Score&quot;</span>,</span>
<span id="cb1193-6"><a href="machine-learning.html#cb1193-6"></a>               <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb1193-7"><a href="machine-learning.html#cb1193-7"></a>               <span class="dt">Title =</span> <span class="st">&quot;Defendant&#39;s Decile Score&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
</div>
<div id="modeling" class="section level4" number="7.8.1.5">
<h4><span class="header-section-number">7.8.1.5</span> Modeling</h4>
<p>After filtering out bad rows, our first question is whether there is a significant difference in COMPAS scores between races. To do so we need to change some variables into factors, and run a logistic regression, comparing low scores to high scores.</p>
<ul>
<li>Model building</li>
</ul>
<div class="sourceCode" id="cb1194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1194-1"><a href="machine-learning.html#cb1194-1"></a>model_data &lt;-<span class="st"> </span><span class="cf">function</span>(data){</span>
<span id="cb1194-2"><a href="machine-learning.html#cb1194-2"></a></span>
<span id="cb1194-3"><a href="machine-learning.html#cb1194-3"></a><span class="co"># Logistic regression model</span></span>
<span id="cb1194-4"><a href="machine-learning.html#cb1194-4"></a>lr_model &lt;-<span class="st"> </span><span class="kw">glm</span>(score <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age_cat <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>priors_count <span class="op">+</span><span class="st"> </span>crime <span class="op">+</span><span class="st"> </span>two_year_recid, </span>
<span id="cb1194-5"><a href="machine-learning.html#cb1194-5"></a>             <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> data)</span>
<span id="cb1194-6"><a href="machine-learning.html#cb1194-6"></a></span>
<span id="cb1194-7"><a href="machine-learning.html#cb1194-7"></a><span class="co"># OLS, DV = score_num</span></span>
<span id="cb1194-8"><a href="machine-learning.html#cb1194-8"></a>ols_model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(score_num <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age_cat <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>priors_count <span class="op">+</span><span class="st"> </span>crime <span class="op">+</span><span class="st"> </span>two_year_recid, <span class="dt">data =</span> data)</span>
<span id="cb1194-9"><a href="machine-learning.html#cb1194-9"></a></span>
<span id="cb1194-10"><a href="machine-learning.html#cb1194-10"></a><span class="co"># OLS, DV = decile_score </span></span>
<span id="cb1194-11"><a href="machine-learning.html#cb1194-11"></a>ols_model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(decile_score <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age_cat <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>priors_count <span class="op">+</span><span class="st"> </span>crime <span class="op">+</span><span class="st"> </span>two_year_recid, <span class="dt">data =</span> data)</span>
<span id="cb1194-12"><a href="machine-learning.html#cb1194-12"></a></span>
<span id="cb1194-13"><a href="machine-learning.html#cb1194-13"></a><span class="co"># Extract model outcomes with confidence intervals </span></span>
<span id="cb1194-14"><a href="machine-learning.html#cb1194-14"></a>lr_est &lt;-<span class="st"> </span>lr_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1194-15"><a href="machine-learning.html#cb1194-15"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) </span>
<span id="cb1194-16"><a href="machine-learning.html#cb1194-16"></a></span>
<span id="cb1194-17"><a href="machine-learning.html#cb1194-17"></a>ols_est1 &lt;-<span class="st"> </span>ols_model1 <span class="op">%&gt;%</span></span>
<span id="cb1194-18"><a href="machine-learning.html#cb1194-18"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) </span>
<span id="cb1194-19"><a href="machine-learning.html#cb1194-19"></a></span>
<span id="cb1194-20"><a href="machine-learning.html#cb1194-20"></a>ols_est2 &lt;-<span class="st"> </span>ols_model2 <span class="op">%&gt;%</span></span>
<span id="cb1194-21"><a href="machine-learning.html#cb1194-21"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) </span>
<span id="cb1194-22"><a href="machine-learning.html#cb1194-22"></a></span>
<span id="cb1194-23"><a href="machine-learning.html#cb1194-23"></a><span class="co"># AIC scores </span></span>
<span id="cb1194-24"><a href="machine-learning.html#cb1194-24"></a>lr_AIC &lt;-<span class="st"> </span><span class="kw">AIC</span>(lr_model)</span>
<span id="cb1194-25"><a href="machine-learning.html#cb1194-25"></a>ols_AIC1 &lt;-<span class="st"> </span><span class="kw">AIC</span>(ols_model1)</span>
<span id="cb1194-26"><a href="machine-learning.html#cb1194-26"></a>ols_AIC2 &lt;-<span class="st"> </span><span class="kw">AIC</span>(ols_model2)</span>
<span id="cb1194-27"><a href="machine-learning.html#cb1194-27"></a>    </span>
<span id="cb1194-28"><a href="machine-learning.html#cb1194-28"></a><span class="kw">list</span>(lr_est, ols_est1, ols_est2, </span>
<span id="cb1194-29"><a href="machine-learning.html#cb1194-29"></a>     lr_AIC, ols_AIC1, ols_AIC2)</span>
<span id="cb1194-30"><a href="machine-learning.html#cb1194-30"></a></span>
<span id="cb1194-31"><a href="machine-learning.html#cb1194-31"></a>}</span></code></pre></div>
<ul>
<li>Model comparisons</li>
</ul>
<div class="sourceCode" id="cb1195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1195-1"><a href="machine-learning.html#cb1195-1"></a><span class="kw">glue</span>(<span class="st">&quot;AIC score of logistic regression: {model_data(df)[4]} </span></span>
<span id="cb1195-2"><a href="machine-learning.html#cb1195-2"></a><span class="st">      AIC score of OLS regression (with categorical DV):  {model_data(df)[5]}</span></span>
<span id="cb1195-3"><a href="machine-learning.html#cb1195-3"></a><span class="st">      AIC score of OLS regression (with continuous DV): {model_data(df)[6]}&quot;</span>)</span></code></pre></div>
<pre><code>## AIC score of logistic regression: 6192.40169473357 
## AIC score of OLS regression (with categorical DV):  11772.1148541111
## AIC score of OLS regression (with continuous DV): 26779.9512226999</code></pre>
<ul>
<li>Logistic regression model</li>
</ul>
<div class="sourceCode" id="cb1197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1197-1"><a href="machine-learning.html#cb1197-1"></a>lr_model &lt;-<span class="st"> </span><span class="kw">model_data</span>(df)[<span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">data.frame</span>()</span>
<span id="cb1197-2"><a href="machine-learning.html#cb1197-2"></a></span>
<span id="cb1197-3"><a href="machine-learning.html#cb1197-3"></a>lr_model <span class="op">%&gt;%</span></span>
<span id="cb1197-4"><a href="machine-learning.html#cb1197-4"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1197-5"><a href="machine-learning.html#cb1197-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">gsub</span>(<span class="st">&quot;race|age_cat|gender|M&quot;</span>,<span class="st">&quot;&quot;</span>, term)) <span class="op">%&gt;%</span></span>
<span id="cb1197-6"><a href="machine-learning.html#cb1197-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(term, estimate), <span class="dt">y =</span> estimate, <span class="dt">ymax =</span> conf.high, <span class="dt">ymin =</span> conf.low)) <span class="op">+</span></span>
<span id="cb1197-7"><a href="machine-learning.html#cb1197-7"></a><span class="st">  </span><span class="kw">geom_pointrange</span>() <span class="op">+</span></span>
<span id="cb1197-8"><a href="machine-learning.html#cb1197-8"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1197-9"><a href="machine-learning.html#cb1197-9"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Estimate&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb1197-10"><a href="machine-learning.html#cb1197-10"></a>      <span class="dt">title =</span> <span class="st">&quot;Logistic regression&quot;</span>) <span class="op">+</span></span>
<span id="cb1197-11"><a href="machine-learning.html#cb1197-11"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-88-1.png" width="672" /></p>
<p>Logistic regression coefficients are log odds ratios. Remember an odd is <span class="math inline">\(\frac{p}{1-p}\)</span>. p could be defined as a success and 1-p could be as a failure. Here, coefficient 1 indicates equal probability for the binary outcomes. Coefficient greater than 1 indicates strong chance for p and weak chance for 1-p. Coefficient smaller than 1 indicates the opposite. Nonetheless, the exact interpretation is not very interpretive as an odd of 2.0 corresponds to the probability of 1/3 (!).</p>
<p>(To refresh your memory, note that probability is bounded between [0, 1]. Odds ranges between 0 and infinity. Log odds ranges from negative to positive infinity. We’re going through this hassle because we used log function to map predictor variables to probability to fit the model to the binary outcomes.)</p>
<p>In this case, we reinterpret coefficients by turning log odds ratios into relative risks. Relative risk = odds ratio / 1 - p0 + (p0 * odds ratio) p-0 is the baseline risk. For more information on relative risks and its value in statistical communication, see <a href="https://www.bmj.com/content/348/bmj.f7450">Grant</a> (2014), <a href="https://www.jstatsoft.org/article/view/v055i05">Wang</a> (2013), and <a href="https://jamanetwork.com/journals/jama/fullarticle/188182">Zhang and Yu</a> (1998).</p>
<div class="sourceCode" id="cb1198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1198-1"><a href="machine-learning.html#cb1198-1"></a>odds_to_risk &lt;-<span class="st"> </span><span class="cf">function</span>(model){</span>
<span id="cb1198-2"><a href="machine-learning.html#cb1198-2"></a>    </span>
<span id="cb1198-3"><a href="machine-learning.html#cb1198-3"></a>    <span class="co"># Calculating p0 (baseline or control group)</span></span>
<span id="cb1198-4"><a href="machine-learning.html#cb1198-4"></a>    intercept &lt;-<span class="st"> </span>model<span class="op">$</span>estimate[model<span class="op">$</span>term <span class="op">==</span><span class="st"> &quot;(Intercept)&quot;</span>]</span>
<span id="cb1198-5"><a href="machine-learning.html#cb1198-5"></a>    control &lt;-<span class="st"> </span><span class="kw">exp</span>(intercept) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(intercept)) </span>
<span id="cb1198-6"><a href="machine-learning.html#cb1198-6"></a>    </span>
<span id="cb1198-7"><a href="machine-learning.html#cb1198-7"></a>    <span class="co"># Calculating relative risk </span></span>
<span id="cb1198-8"><a href="machine-learning.html#cb1198-8"></a>    model &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>)</span>
<span id="cb1198-9"><a href="machine-learning.html#cb1198-9"></a>    model<span class="op">$</span>relative_risk &lt;-<span class="st"> </span>(<span class="kw">exp</span>(model<span class="op">$</span>estimate) <span class="op">/</span><span class="st"> </span></span>
<span id="cb1198-10"><a href="machine-learning.html#cb1198-10"></a><span class="st">                        </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>control <span class="op">+</span><span class="st"> </span>(control <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(model<span class="op">$</span>estimate)))) </span>
<span id="cb1198-11"><a href="machine-learning.html#cb1198-11"></a>    </span>
<span id="cb1198-12"><a href="machine-learning.html#cb1198-12"></a>    <span class="kw">return</span>(model)</span>
<span id="cb1198-13"><a href="machine-learning.html#cb1198-13"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb1199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1199-1"><a href="machine-learning.html#cb1199-1"></a><span class="kw">odds_to_risk</span>(lr_model) <span class="op">%&gt;%</span></span>
<span id="cb1199-2"><a href="machine-learning.html#cb1199-2"></a><span class="st">  </span><span class="kw">relocate</span>(relative_risk) <span class="op">%&gt;%</span></span>
<span id="cb1199-3"><a href="machine-learning.html#cb1199-3"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(relative_risk))</span></code></pre></div>
<pre><code>##    relative_risk                   term   estimate  std.error   statistic
## 1      2.6152880    raceNative American  1.3942077 0.76611816   1.8198338
## 2      2.4961195    age_catLess than 25  1.3083903 0.07592869  17.2318308
## 3      1.6882587         two_year_recid  0.6858625 0.06401955  10.7133288
## 4      1.4528374   raceAfrican-American  0.4772070 0.06934914   6.8812245
## 5      1.2402135           priors_count  0.2689453 0.01110379  24.2210342
## 6      1.1947947           genderFemale  0.2212667 0.07951020   2.7828714
## 7      0.8077863              raceAsian -0.2544147 0.47821105  -0.5320135
## 8      0.7692955                 crimeM -0.3112408 0.06654750  -4.6769729
## 9      0.6948050           raceHispanic -0.4283949 0.12812549  -3.3435572
## 10     0.4865228              raceOther -0.8263469 0.16208006  -5.0983873
## 11     0.2971899 age_catGreater than 45 -1.3556332 0.09908053 -13.6821355
##          p.value    conf.low  conf.high
## 1   6.878432e-02 -0.05694017  3.0383160
## 2   1.532239e-66  1.16008750  1.4577645
## 3   8.813460e-27  0.56039880  0.8113799
## 4   5.934025e-12  0.34137020  0.6132514
## 5  1.335783e-129  0.24750487  0.2910343
## 6   5.388016e-03  0.06532360  0.3770591
## 7   5.947167e-01 -1.25877950  0.6389894
## 8   2.911407e-06 -0.44178937 -0.1808904
## 9   8.271164e-04 -0.68190124 -0.1794075
## 10  3.425594e-07 -1.15026143 -0.5142075
## 11  1.298233e-42 -1.55226716 -1.1637224</code></pre>
<p>Relative risk score 1.45 (African American) indicates that black defendants are 45% more likely than white defendants to receive a higher score.</p>
<p>The plot visualizes this and other results from the table.</p>
<div class="sourceCode" id="cb1201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1201-1"><a href="machine-learning.html#cb1201-1"></a><span class="kw">odds_to_risk</span>(lr_model) <span class="op">%&gt;%</span></span>
<span id="cb1201-2"><a href="machine-learning.html#cb1201-2"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">gsub</span>(<span class="st">&quot;race|age_cat|gender&quot;</span>,<span class="st">&quot;&quot;</span>, term)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1201-3"><a href="machine-learning.html#cb1201-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(term, relative_risk), <span class="dt">y =</span> relative_risk)) <span class="op">+</span></span>
<span id="cb1201-4"><a href="machine-learning.html#cb1201-4"></a><span class="st">        </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb1201-5"><a href="machine-learning.html#cb1201-5"></a><span class="st">        </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1201-6"><a href="machine-learning.html#cb1201-6"></a><span class="st">        </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Likelihood&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb1201-7"><a href="machine-learning.html#cb1201-7"></a>             <span class="dt">title =</span> <span class="st">&quot;Logistic regression&quot;</span>) <span class="op">+</span></span>
<span id="cb1201-8"><a href="machine-learning.html#cb1201-8"></a><span class="st">        </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb1201-9"><a href="machine-learning.html#cb1201-9"></a><span class="st">        </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-91-1.png" width="672" /></p>
</div>
</div>
<div id="bias-in-the-data-risk-of-violent-recidivism-analysis" class="section level3" number="7.8.2">
<h3><span class="header-section-number">7.8.2</span> Bias in the Data (Risk of Violent Recidivism Analysis)</h3>
<div id="setup-5" class="section level4" number="7.8.2.1">
<h4><span class="header-section-number">7.8.2.1</span> Setup</h4>
<div class="sourceCode" id="cb1202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1202-1"><a href="machine-learning.html#cb1202-1"></a><span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;pacman&quot;</span>)) <span class="kw">install.packages</span>(<span class="st">&quot;pacman&quot;</span>)</span>
<span id="cb1202-2"><a href="machine-learning.html#cb1202-2"></a></span>
<span id="cb1202-3"><a href="machine-learning.html#cb1202-3"></a>pacman<span class="op">::</span><span class="kw">p_load</span>(</span>
<span id="cb1202-4"><a href="machine-learning.html#cb1202-4"></a> tidyverse, <span class="co"># tidyverse packages </span></span>
<span id="cb1202-5"><a href="machine-learning.html#cb1202-5"></a> conflicted, <span class="co"># an alternative conflict resolution strategy </span></span>
<span id="cb1202-6"><a href="machine-learning.html#cb1202-6"></a> ggthemes, <span class="co"># other themes for ggplot2 </span></span>
<span id="cb1202-7"><a href="machine-learning.html#cb1202-7"></a> patchwork, <span class="co"># arranging ggplots</span></span>
<span id="cb1202-8"><a href="machine-learning.html#cb1202-8"></a> scales, <span class="co"># rescaling </span></span>
<span id="cb1202-9"><a href="machine-learning.html#cb1202-9"></a> survival, <span class="co"># survival analysis</span></span>
<span id="cb1202-10"><a href="machine-learning.html#cb1202-10"></a> broom, <span class="co"># for modeling</span></span>
<span id="cb1202-11"><a href="machine-learning.html#cb1202-11"></a> here, <span class="co"># reproducibility </span></span>
<span id="cb1202-12"><a href="machine-learning.html#cb1202-12"></a> glue <span class="co"># pasting strings and objects </span></span>
<span id="cb1202-13"><a href="machine-learning.html#cb1202-13"></a>)</span>
<span id="cb1202-14"><a href="machine-learning.html#cb1202-14"></a></span>
<span id="cb1202-15"><a href="machine-learning.html#cb1202-15"></a><span class="co"># To avoid conflicts </span></span>
<span id="cb1202-16"><a href="machine-learning.html#cb1202-16"></a><span class="kw">conflict_prefer</span>(<span class="st">&quot;filter&quot;</span>, <span class="st">&quot;dplyr&quot;</span>) </span></code></pre></div>
<pre><code>## [conflicted] Removing existing preference</code></pre>
<pre><code>## [conflicted] Will prefer dplyr::filter over any other package</code></pre>
<div class="sourceCode" id="cb1205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1205-1"><a href="machine-learning.html#cb1205-1"></a><span class="kw">conflict_prefer</span>(<span class="st">&quot;select&quot;</span>, <span class="st">&quot;dplyr&quot;</span>) </span></code></pre></div>
<pre><code>## [conflicted] Removing existing preference</code></pre>
<pre><code>## [conflicted] Will prefer dplyr::select over any other package</code></pre>
<div class="sourceCode" id="cb1208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1208-1"><a href="machine-learning.html#cb1208-1"></a><span class="co"># Set themes </span></span>
<span id="cb1208-2"><a href="machine-learning.html#cb1208-2"></a><span class="kw">theme_set</span>(ggthemes<span class="op">::</span><span class="kw">theme_fivethirtyeight</span>())</span></code></pre></div>
</div>
<div id="load-data-1" class="section level4" number="7.8.2.2">
<h4><span class="header-section-number">7.8.2.2</span> Load data</h4>
<div class="sourceCode" id="cb1209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1209-1"><a href="machine-learning.html#cb1209-1"></a>two_years_violent &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span> ,<span class="st">&quot;compas-scores-two-years-violent.csv&quot;</span>))</span></code></pre></div>
<pre><code>## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt;
## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49], &#39;two_year_recid&#39;
## =&gt; &#39;two_year_recid_1&#39; [54]</code></pre>
<pre><code>## 
## ── Column specification ───────────────────────────────────────────────────────────────
## cols(
##   .default = col_double(),
##   name = col_character(),
##   first = col_character(),
##   last = col_character(),
##   compas_screening_date = col_date(format = &quot;&quot;),
##   sex = col_character(),
##   dob = col_date(format = &quot;&quot;),
##   age_cat = col_character(),
##   race = col_character(),
##   c_jail_in = col_datetime(format = &quot;&quot;),
##   c_jail_out = col_datetime(format = &quot;&quot;),
##   c_case_number = col_character(),
##   c_offense_date = col_date(format = &quot;&quot;),
##   c_arrest_date = col_date(format = &quot;&quot;),
##   c_charge_degree = col_character(),
##   c_charge_desc = col_character(),
##   r_case_number = col_character(),
##   r_charge_degree = col_character(),
##   r_offense_date = col_date(format = &quot;&quot;),
##   r_charge_desc = col_character(),
##   r_jail_in = col_date(format = &quot;&quot;)
##   # ... with 14 more columns
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<div class="sourceCode" id="cb1212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1212-1"><a href="machine-learning.html#cb1212-1"></a><span class="kw">glue</span>(<span class="st">&quot;N of observations (rows): {nrow(two_years_violent)}</span></span>
<span id="cb1212-2"><a href="machine-learning.html#cb1212-2"></a><span class="st">      N of variables (columns): {ncol(two_years_violent)}&quot;</span>)</span></code></pre></div>
<pre><code>## N of observations (rows): 4743
## N of variables (columns): 54</code></pre>
</div>
<div id="wrangling-1" class="section level4" number="7.8.2.3">
<h4><span class="header-section-number">7.8.2.3</span> Wrangling</h4>
<ul>
<li>Create a function</li>
</ul>
<div class="sourceCode" id="cb1214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1214-1"><a href="machine-learning.html#cb1214-1"></a>wrangle_data &lt;-<span class="st"> </span><span class="cf">function</span>(data){</span>
<span id="cb1214-2"><a href="machine-learning.html#cb1214-2"></a></span>
<span id="cb1214-3"><a href="machine-learning.html#cb1214-3"></a>df &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1214-4"><a href="machine-learning.html#cb1214-4"></a><span class="st">    </span></span>
<span id="cb1214-5"><a href="machine-learning.html#cb1214-5"></a><span class="st">    </span><span class="co"># Select variables </span></span>
<span id="cb1214-6"><a href="machine-learning.html#cb1214-6"></a><span class="st">    </span><span class="kw">select</span>(age, c_charge_degree, race, age_cat, v_score_text, sex, priors_count, </span>
<span id="cb1214-7"><a href="machine-learning.html#cb1214-7"></a>         days_b_screening_arrest, v_decile_score, is_recid, two_year_recid) <span class="op">%&gt;%</span><span class="st">            </span></span>
<span id="cb1214-8"><a href="machine-learning.html#cb1214-8"></a><span class="st">    </span><span class="co"># Filter rows </span></span>
<span id="cb1214-9"><a href="machine-learning.html#cb1214-9"></a><span class="st">    </span><span class="kw">filter</span>(days_b_screening_arrest <span class="op">&lt;=</span><span class="st"> </span><span class="dv">30</span>,</span>
<span id="cb1214-10"><a href="machine-learning.html#cb1214-10"></a>           days_b_screening_arrest <span class="op">&gt;=</span><span class="st"> </span><span class="dv">-30</span>, </span>
<span id="cb1214-11"><a href="machine-learning.html#cb1214-11"></a>           is_recid <span class="op">!=</span><span class="st"> </span><span class="dv">-1</span>,</span>
<span id="cb1214-12"><a href="machine-learning.html#cb1214-12"></a>           c_charge_degree <span class="op">!=</span><span class="st"> &quot;O&quot;</span>,</span>
<span id="cb1214-13"><a href="machine-learning.html#cb1214-13"></a>           v_score_text <span class="op">!=</span><span class="st"> &#39;N/A&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1214-14"><a href="machine-learning.html#cb1214-14"></a><span class="st">    </span><span class="co"># Mutate variables </span></span>
<span id="cb1214-15"><a href="machine-learning.html#cb1214-15"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">c_charge_degree =</span> <span class="kw">factor</span>(c_charge_degree),</span>
<span id="cb1214-16"><a href="machine-learning.html#cb1214-16"></a>           <span class="dt">age_cat =</span> <span class="kw">factor</span>(age_cat),</span>
<span id="cb1214-17"><a href="machine-learning.html#cb1214-17"></a>           <span class="dt">race =</span> <span class="kw">factor</span>(race, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Caucasian&quot;</span>,<span class="st">&quot;African-American&quot;</span>,<span class="st">&quot;Hispanic&quot;</span>,<span class="st">&quot;Other&quot;</span>,<span class="st">&quot;Asian&quot;</span>,<span class="st">&quot;Native American&quot;</span>)),</span>
<span id="cb1214-18"><a href="machine-learning.html#cb1214-18"></a>           <span class="dt">sex =</span> <span class="kw">factor</span>(sex, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>,<span class="st">&quot;Female&quot;</span>)),</span>
<span id="cb1214-19"><a href="machine-learning.html#cb1214-19"></a>           <span class="dt">v_score_text =</span> <span class="kw">factor</span>(v_score_text, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>)),</span>
<span id="cb1214-20"><a href="machine-learning.html#cb1214-20"></a><span class="co"># I added this new variable to test whether measuring the DV as a binary or continuous var makes a difference </span></span>
<span id="cb1214-21"><a href="machine-learning.html#cb1214-21"></a>           <span class="dt">score_num =</span> <span class="kw">as.numeric</span>(v_score_text)) <span class="op">%&gt;%</span></span>
<span id="cb1214-22"><a href="machine-learning.html#cb1214-22"></a><span class="st">    </span><span class="co"># Rename variables </span></span>
<span id="cb1214-23"><a href="machine-learning.html#cb1214-23"></a><span class="st">    </span><span class="kw">rename</span>(<span class="dt">crime =</span> c_charge_degree,</span>
<span id="cb1214-24"><a href="machine-learning.html#cb1214-24"></a>           <span class="dt">gender =</span> sex,</span>
<span id="cb1214-25"><a href="machine-learning.html#cb1214-25"></a>           <span class="dt">score =</span> v_score_text)</span>
<span id="cb1214-26"><a href="machine-learning.html#cb1214-26"></a>        </span>
<span id="cb1214-27"><a href="machine-learning.html#cb1214-27"></a><span class="kw">return</span>(df)}</span></code></pre></div>
<ul>
<li>Apply the function to the data</li>
</ul>
<div class="sourceCode" id="cb1215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1215-1"><a href="machine-learning.html#cb1215-1"></a>df &lt;-<span class="st"> </span><span class="kw">wrangle_data</span>(two_years_violent)</span>
<span id="cb1215-2"><a href="machine-learning.html#cb1215-2"></a></span>
<span id="cb1215-3"><a href="machine-learning.html#cb1215-3"></a><span class="kw">names</span>(df)</span></code></pre></div>
<pre><code>##  [1] &quot;age&quot;                     &quot;crime&quot;                  
##  [3] &quot;race&quot;                    &quot;age_cat&quot;                
##  [5] &quot;score&quot;                   &quot;gender&quot;                 
##  [7] &quot;priors_count&quot;            &quot;days_b_screening_arrest&quot;
##  [9] &quot;v_decile_score&quot;          &quot;is_recid&quot;               
## [11] &quot;two_year_recid&quot;          &quot;score_num&quot;</code></pre>
<div class="sourceCode" id="cb1217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1217-1"><a href="machine-learning.html#cb1217-1"></a><span class="kw">head</span>(df, <span class="dv">5</span>) <span class="co"># Check whether the function works as expected </span></span></code></pre></div>
<pre><code>## # A tibble: 5 x 12
##     age crime race  age_cat score gender priors_count days_b_screenin…
##   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1    69 F     Other Greate… Low   Male              0               -1
## 2    34 F     Afri… 25 - 45 Low   Male              0               -1
## 3    44 M     Other 25 - 45 Low   Male              0                0
## 4    43 F     Other 25 - 45 Low   Male              3               -1
## 5    39 M     Cauc… 25 - 45 Low   Female            0               -1
## # … with 4 more variables: v_decile_score &lt;dbl&gt;, is_recid &lt;dbl&gt;,
## #   two_year_recid &lt;dbl&gt;, score_num &lt;dbl&gt;</code></pre>
</div>
<div id="descriptive-analysis-1" class="section level4" number="7.8.2.4">
<h4><span class="header-section-number">7.8.2.4</span> Descriptive analysis</h4>
<ul>
<li>Score distribution</li>
</ul>
<div class="sourceCode" id="cb1219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1219-1"><a href="machine-learning.html#cb1219-1"></a>df <span class="op">%&gt;%</span></span>
<span id="cb1219-2"><a href="machine-learning.html#cb1219-2"></a><span class="st">  </span><span class="kw">group_by</span>(score) <span class="op">%&gt;%</span></span>
<span id="cb1219-3"><a href="machine-learning.html#cb1219-3"></a><span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span></span>
<span id="cb1219-4"><a href="machine-learning.html#cb1219-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> score, <span class="dt">y =</span> n)) <span class="op">+</span></span>
<span id="cb1219-5"><a href="machine-learning.html#cb1219-5"></a><span class="st">    </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1219-6"><a href="machine-learning.html#cb1219-6"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Score&quot;</span>,</span>
<span id="cb1219-7"><a href="machine-learning.html#cb1219-7"></a>         <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb1219-8"><a href="machine-learning.html#cb1219-8"></a>         <span class="dt">title =</span> <span class="st">&quot;Score distribution&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<ul>
<li>Score distribution by race</li>
</ul>
<div class="sourceCode" id="cb1220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1220-1"><a href="machine-learning.html#cb1220-1"></a>df <span class="op">%&gt;%</span></span>
<span id="cb1220-2"><a href="machine-learning.html#cb1220-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">ordered</span>(v_decile_score))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1220-3"><a href="machine-learning.html#cb1220-3"></a><span class="st">          </span><span class="kw">geom_bar</span>() <span class="op">+</span></span>
<span id="cb1220-4"><a href="machine-learning.html#cb1220-4"></a><span class="st">          </span><span class="kw">facet_wrap</span>(<span class="op">~</span>race, <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1220-5"><a href="machine-learning.html#cb1220-5"></a><span class="st">          </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Decile Score&quot;</span>,</span>
<span id="cb1220-6"><a href="machine-learning.html#cb1220-6"></a>               <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb1220-7"><a href="machine-learning.html#cb1220-7"></a>               <span class="dt">Title =</span> <span class="st">&quot;Defendant&#39;s Decile Score&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
</div>
<div id="modeling-1" class="section level4" number="7.8.2.5">
<h4><span class="header-section-number">7.8.2.5</span> Modeling</h4>
<p>After filtering out bad rows, our first question is whether there is a significant difference in COMPAS scores between races. To do so we need to change some variables into factors, and run a logistic regression, comparing low scores to high scores.</p>
<div class="sourceCode" id="cb1221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1221-1"><a href="machine-learning.html#cb1221-1"></a>model_data &lt;-<span class="st"> </span><span class="cf">function</span>(data){</span>
<span id="cb1221-2"><a href="machine-learning.html#cb1221-2"></a></span>
<span id="cb1221-3"><a href="machine-learning.html#cb1221-3"></a><span class="co"># Logistic regression model</span></span>
<span id="cb1221-4"><a href="machine-learning.html#cb1221-4"></a>lr_model &lt;-<span class="st"> </span><span class="kw">glm</span>(score <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age_cat <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>priors_count <span class="op">+</span><span class="st"> </span>crime <span class="op">+</span><span class="st"> </span>two_year_recid, </span>
<span id="cb1221-5"><a href="machine-learning.html#cb1221-5"></a>             <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> data)</span>
<span id="cb1221-6"><a href="machine-learning.html#cb1221-6"></a></span>
<span id="cb1221-7"><a href="machine-learning.html#cb1221-7"></a><span class="co"># OLS</span></span>
<span id="cb1221-8"><a href="machine-learning.html#cb1221-8"></a>ols_model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(score_num <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age_cat <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>priors_count <span class="op">+</span><span class="st"> </span>crime <span class="op">+</span><span class="st"> </span>two_year_recid, </span>
<span id="cb1221-9"><a href="machine-learning.html#cb1221-9"></a>             <span class="dt">data =</span> data)</span>
<span id="cb1221-10"><a href="machine-learning.html#cb1221-10"></a></span>
<span id="cb1221-11"><a href="machine-learning.html#cb1221-11"></a>ols_model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(v_decile_score <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age_cat <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>priors_count <span class="op">+</span><span class="st"> </span>crime <span class="op">+</span><span class="st"> </span>two_year_recid, </span>
<span id="cb1221-12"><a href="machine-learning.html#cb1221-12"></a>             <span class="dt">data =</span> data)</span>
<span id="cb1221-13"><a href="machine-learning.html#cb1221-13"></a></span>
<span id="cb1221-14"><a href="machine-learning.html#cb1221-14"></a><span class="co"># Extract model outcomes with confidence intervals </span></span>
<span id="cb1221-15"><a href="machine-learning.html#cb1221-15"></a>lr_est &lt;-<span class="st"> </span>lr_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1221-16"><a href="machine-learning.html#cb1221-16"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) </span>
<span id="cb1221-17"><a href="machine-learning.html#cb1221-17"></a></span>
<span id="cb1221-18"><a href="machine-learning.html#cb1221-18"></a>ols_est1 &lt;-<span class="st"> </span>ols_model1 <span class="op">%&gt;%</span></span>
<span id="cb1221-19"><a href="machine-learning.html#cb1221-19"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) </span>
<span id="cb1221-20"><a href="machine-learning.html#cb1221-20"></a></span>
<span id="cb1221-21"><a href="machine-learning.html#cb1221-21"></a>ols_est2 &lt;-<span class="st"> </span>ols_model2 <span class="op">%&gt;%</span></span>
<span id="cb1221-22"><a href="machine-learning.html#cb1221-22"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) </span>
<span id="cb1221-23"><a href="machine-learning.html#cb1221-23"></a></span>
<span id="cb1221-24"><a href="machine-learning.html#cb1221-24"></a><span class="co"># AIC scores </span></span>
<span id="cb1221-25"><a href="machine-learning.html#cb1221-25"></a>lr_AIC &lt;-<span class="st"> </span><span class="kw">AIC</span>(lr_model)</span>
<span id="cb1221-26"><a href="machine-learning.html#cb1221-26"></a>ols_AIC1 &lt;-<span class="st"> </span><span class="kw">AIC</span>(ols_model1)</span>
<span id="cb1221-27"><a href="machine-learning.html#cb1221-27"></a>ols_AIC2 &lt;-<span class="st"> </span><span class="kw">AIC</span>(ols_model2)</span>
<span id="cb1221-28"><a href="machine-learning.html#cb1221-28"></a>    </span>
<span id="cb1221-29"><a href="machine-learning.html#cb1221-29"></a><span class="kw">list</span>(lr_est, ols_est1, ols_est2, lr_AIC, ols_AIC1, ols_AIC2)</span>
<span id="cb1221-30"><a href="machine-learning.html#cb1221-30"></a>}</span></code></pre></div>
<ul>
<li>Model comparisons</li>
</ul>
<div class="sourceCode" id="cb1222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1222-1"><a href="machine-learning.html#cb1222-1"></a><span class="kw">glue</span>(<span class="st">&quot;AIC score of logistic regression: {model_data(df)[4]} </span></span>
<span id="cb1222-2"><a href="machine-learning.html#cb1222-2"></a><span class="st">      AIC score of OLS regression (with categorical DV):  {model_data(df)[5]}</span></span>
<span id="cb1222-3"><a href="machine-learning.html#cb1222-3"></a><span class="st">      AIC score of OLS regression (with continuous DV): {model_data(df)[6]}&quot;</span>)</span></code></pre></div>
<pre><code>## AIC score of logistic regression: 3022.77943765996 
## AIC score of OLS regression (with categorical DV):  5414.49127581608
## AIC score of OLS regression (with continuous DV): 15458.3861723106</code></pre>
<ul>
<li>Logistic regression model</li>
</ul>
<div class="sourceCode" id="cb1224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1224-1"><a href="machine-learning.html#cb1224-1"></a>lr_model &lt;-<span class="st"> </span><span class="kw">model_data</span>(df)[<span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1224-2"><a href="machine-learning.html#cb1224-2"></a><span class="st">  </span><span class="kw">data.frame</span>()</span>
<span id="cb1224-3"><a href="machine-learning.html#cb1224-3"></a></span>
<span id="cb1224-4"><a href="machine-learning.html#cb1224-4"></a>lr_model <span class="op">%&gt;%</span></span>
<span id="cb1224-5"><a href="machine-learning.html#cb1224-5"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1224-6"><a href="machine-learning.html#cb1224-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">gsub</span>(<span class="st">&quot;race|age_cat|gender&quot;</span>,<span class="st">&quot;&quot;</span>, term)) <span class="op">%&gt;%</span></span>
<span id="cb1224-7"><a href="machine-learning.html#cb1224-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(term, estimate), <span class="dt">y =</span> estimate, <span class="dt">ymax =</span> conf.high, <span class="dt">ymin =</span> conf.low)) <span class="op">+</span></span>
<span id="cb1224-8"><a href="machine-learning.html#cb1224-8"></a><span class="st">  </span><span class="kw">geom_pointrange</span>() <span class="op">+</span></span>
<span id="cb1224-9"><a href="machine-learning.html#cb1224-9"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1224-10"><a href="machine-learning.html#cb1224-10"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Estimate&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb1224-11"><a href="machine-learning.html#cb1224-11"></a>      <span class="dt">title =</span> <span class="st">&quot;Logistic regression&quot;</span>) <span class="op">+</span></span>
<span id="cb1224-12"><a href="machine-learning.html#cb1224-12"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-100-1.png" width="672" /></p>
<p>Logistic regression coefficients are log odds ratios. Remember an odd is <span class="math inline">\(\frac{p}{1-p}\)</span>. p could be defined as a success and 1-p could be as a failure. Here, coefficient 1 indicates equal probability for the binary outcomes. Coefficient greater than 1 indicates strong chance for p and weak chance for 1-p. Coefficient smaller than 1 indicates the opposite. Nonetheless, the exact interpretation is not very interpretive as an odd of 2.0 corresponds to the probability of 1/3 (!).</p>
<p>(To refresh your memory, note that probability is bounded between [0, 1]. Odds ranges between 0 and infinity. Log odds ranges from negative to positive infinity. We’re going through this hassle because we used log function to map predictor variables to probability to fit the model to the binary outcomes.)</p>
<p>In this case, we reinterpret coefficients by turning log odds ratios into relative risks. Relative risk = odds ratio / 1 - p0 + (p0 * odds ratio) p-0 is the baseline risk. For more information on relative risks and its value in statistical communication, see <a href="https://www.bmj.com/content/348/bmj.f7450">Grant</a> (2014), <a href="https://www.jstatsoft.org/article/view/v055i05">Wang</a> (2013), and <a href="https://jamanetwork.com/journals/jama/fullarticle/188182">Zhang and Yu</a> (1998).</p>
<div class="sourceCode" id="cb1225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1225-1"><a href="machine-learning.html#cb1225-1"></a>odds_to_risk &lt;-<span class="st"> </span><span class="cf">function</span>(model){</span>
<span id="cb1225-2"><a href="machine-learning.html#cb1225-2"></a>    </span>
<span id="cb1225-3"><a href="machine-learning.html#cb1225-3"></a>    <span class="co"># Calculating p0 (baseline or control group)</span></span>
<span id="cb1225-4"><a href="machine-learning.html#cb1225-4"></a>    intercept &lt;-<span class="st"> </span>model<span class="op">$</span>estimate[model<span class="op">$</span>term <span class="op">==</span><span class="st"> &quot;(Intercept)&quot;</span>]</span>
<span id="cb1225-5"><a href="machine-learning.html#cb1225-5"></a>    control &lt;-<span class="st"> </span><span class="kw">exp</span>(intercept) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(intercept)) </span>
<span id="cb1225-6"><a href="machine-learning.html#cb1225-6"></a>    </span>
<span id="cb1225-7"><a href="machine-learning.html#cb1225-7"></a>    <span class="co"># Calculating relative risk </span></span>
<span id="cb1225-8"><a href="machine-learning.html#cb1225-8"></a>    model &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>)</span>
<span id="cb1225-9"><a href="machine-learning.html#cb1225-9"></a>    model<span class="op">$</span>relative_risk &lt;-<span class="st"> </span>(<span class="kw">exp</span>(model<span class="op">$</span>estimate) <span class="op">/</span><span class="st"> </span></span>
<span id="cb1225-10"><a href="machine-learning.html#cb1225-10"></a><span class="st">                        </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>control <span class="op">+</span><span class="st"> </span>(control <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(model<span class="op">$</span>estimate)))) </span>
<span id="cb1225-11"><a href="machine-learning.html#cb1225-11"></a>    </span>
<span id="cb1225-12"><a href="machine-learning.html#cb1225-12"></a>    <span class="kw">return</span>(model)</span>
<span id="cb1225-13"><a href="machine-learning.html#cb1225-13"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb1226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1226-1"><a href="machine-learning.html#cb1226-1"></a><span class="kw">odds_to_risk</span>(lr_model) <span class="op">%&gt;%</span></span>
<span id="cb1226-2"><a href="machine-learning.html#cb1226-2"></a><span class="st">  </span><span class="kw">relocate</span>(relative_risk) <span class="op">%&gt;%</span></span>
<span id="cb1226-3"><a href="machine-learning.html#cb1226-3"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(relative_risk))</span></code></pre></div>
<pre><code>##    relative_risk                   term    estimate  std.error  statistic
## 1      7.4142320    age_catLess than 25  3.14590906 0.11540998 27.2585528
## 2      2.2169566         two_year_recid  0.93447949 0.11527216  8.1067232
## 3      1.7739274   raceAfrican-American  0.65893450 0.10814991  6.0927885
## 4      1.4845555    raceNative American  0.44792984 1.03546096  0.4325898
## 5      1.1315392           priors_count  0.13764241 0.01161172 11.8537476
## 6      0.9434828           raceHispanic -0.06415947 0.19132794 -0.3353377
## 7      0.8615079                 crimeM -0.16366732 0.09806528 -1.6689631
## 8      0.8290722              raceOther -0.20543235 0.22464062 -0.9144933
## 9      0.5076551           genderFemale -0.72890371 0.12665509 -5.7550290
## 10     0.3972545              raceAsian -0.98520588 0.70537045 -1.3967212
## 11     0.1902151 age_catGreater than 45 -1.74207559 0.18414760 -9.4602135
##          p.value   conf.low   conf.high
## 1  1.315899e-163  2.9224937  3.37506621
## 2   5.200316e-16  0.7084155  1.16039836
## 3   1.109606e-09  0.4480948  0.87222287
## 4   6.653128e-01 -1.9660912  2.24738803
## 5   2.057779e-32  0.1151045  0.16064926
## 6   7.373704e-01 -0.4439074  0.30657314
## 7   9.512470e-02 -0.3563339  0.02822281
## 8   3.604577e-01 -0.6533518  0.22789493
## 9   8.662690e-09 -0.9800266 -0.48330469
## 10  1.624974e-01 -2.4655693  0.33213464
## 11  3.073150e-21 -2.1171742 -1.39384502</code></pre>
<p>Relative risk score 1.45 (African American) indicates that black defendants are 45% more likely than white defendants to receive a higher score.</p>
<p>The plot visualizes this and other results from the table.</p>
<div class="sourceCode" id="cb1228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1228-1"><a href="machine-learning.html#cb1228-1"></a><span class="kw">odds_to_risk</span>(lr_model) <span class="op">%&gt;%</span></span>
<span id="cb1228-2"><a href="machine-learning.html#cb1228-2"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">gsub</span>(<span class="st">&quot;race|age_cat|gender&quot;</span>,<span class="st">&quot;&quot;</span>, term)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1228-3"><a href="machine-learning.html#cb1228-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(term, relative_risk), <span class="dt">y =</span> relative_risk)) <span class="op">+</span></span>
<span id="cb1228-4"><a href="machine-learning.html#cb1228-4"></a><span class="st">        </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb1228-5"><a href="machine-learning.html#cb1228-5"></a><span class="st">        </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1228-6"><a href="machine-learning.html#cb1228-6"></a><span class="st">        </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Likelihood&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb1228-7"><a href="machine-learning.html#cb1228-7"></a>             <span class="dt">title =</span> <span class="st">&quot;Logistic regression&quot;</span>) <span class="op">+</span></span>
<span id="cb1228-8"><a href="machine-learning.html#cb1228-8"></a><span class="st">        </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb1228-9"><a href="machine-learning.html#cb1228-9"></a><span class="st">        </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
</div>
</div>
<div id="bias-in-the-algorithm" class="section level3" number="7.8.3">
<h3><span class="header-section-number">7.8.3</span> Bias in the algorithm</h3>
<ul>
<li><p>In order to test whether COMPAS scores do an accurate job of deciding whether an offender is Low, Medium or High risk, we ran a Cox Proportional Hazards model. Northpointe, the company that created COMPAS and markets it to Law Enforcement, also ran a Cox model in <a href="https://journals.sagepub.com/doi/abs/10.1177/0093854808326545">their validation study</a>.</p></li>
<li><p>We used the counting model and removed people when they were incarcerated. Due to errors in the underlying jail data, we need to filter out 32 rows that have an end date more than the start date. Considering that there are 13,334 total rows in the data, such a small amount of errors will not affect the results.</p></li>
</ul>
<div id="setup-6" class="section level4" number="7.8.3.1">
<h4><span class="header-section-number">7.8.3.1</span> Setup</h4>
<div class="sourceCode" id="cb1229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1229-1"><a href="machine-learning.html#cb1229-1"></a><span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;pacman&quot;</span>)) <span class="kw">install.packages</span>(<span class="st">&quot;pacman&quot;</span>)</span>
<span id="cb1229-2"><a href="machine-learning.html#cb1229-2"></a>pacman<span class="op">::</span><span class="kw">p_load</span>(</span>
<span id="cb1229-3"><a href="machine-learning.html#cb1229-3"></a> tidyverse, <span class="co"># tidyverse packages </span></span>
<span id="cb1229-4"><a href="machine-learning.html#cb1229-4"></a> conflicted, <span class="co"># an alternative conflict resolution strategy </span></span>
<span id="cb1229-5"><a href="machine-learning.html#cb1229-5"></a> ggthemes, <span class="co"># other themes for ggplot2 </span></span>
<span id="cb1229-6"><a href="machine-learning.html#cb1229-6"></a> patchwork, <span class="co"># arranging ggplots</span></span>
<span id="cb1229-7"><a href="machine-learning.html#cb1229-7"></a> scales, <span class="co"># rescaling </span></span>
<span id="cb1229-8"><a href="machine-learning.html#cb1229-8"></a> survival, <span class="co"># survival analysis</span></span>
<span id="cb1229-9"><a href="machine-learning.html#cb1229-9"></a> broom, <span class="co"># for modeling</span></span>
<span id="cb1229-10"><a href="machine-learning.html#cb1229-10"></a> here, <span class="co"># reproducibility </span></span>
<span id="cb1229-11"><a href="machine-learning.html#cb1229-11"></a> glue, <span class="co"># pasting strings and objects </span></span>
<span id="cb1229-12"><a href="machine-learning.html#cb1229-12"></a> reticulate <span class="co"># source python codes</span></span>
<span id="cb1229-13"><a href="machine-learning.html#cb1229-13"></a>)</span>
<span id="cb1229-14"><a href="machine-learning.html#cb1229-14"></a></span>
<span id="cb1229-15"><a href="machine-learning.html#cb1229-15"></a><span class="co"># To avoid conflicts </span></span>
<span id="cb1229-16"><a href="machine-learning.html#cb1229-16"></a><span class="kw">conflict_prefer</span>(<span class="st">&quot;filter&quot;</span>, <span class="st">&quot;dplyr&quot;</span>) </span></code></pre></div>
<pre><code>## [conflicted] Removing existing preference</code></pre>
<pre><code>## [conflicted] Will prefer dplyr::filter over any other package</code></pre>
<div class="sourceCode" id="cb1232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1232-1"><a href="machine-learning.html#cb1232-1"></a><span class="kw">conflict_prefer</span>(<span class="st">&quot;select&quot;</span>, <span class="st">&quot;dplyr&quot;</span>) </span></code></pre></div>
<pre><code>## [conflicted] Removing existing preference</code></pre>
<pre><code>## [conflicted] Will prefer dplyr::select over any other package</code></pre>
<div class="sourceCode" id="cb1235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1235-1"><a href="machine-learning.html#cb1235-1"></a><span class="co"># Set themes </span></span>
<span id="cb1235-2"><a href="machine-learning.html#cb1235-2"></a><span class="kw">theme_set</span>(ggthemes<span class="op">::</span><span class="kw">theme_fivethirtyeight</span>())</span></code></pre></div>
</div>
<div id="load-data-2" class="section level4" number="7.8.3.2">
<h4><span class="header-section-number">7.8.3.2</span> Load data</h4>
<div class="sourceCode" id="cb1236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1236-1"><a href="machine-learning.html#cb1236-1"></a>cox_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span> ,<span class="st">&quot;cox-parsed.csv&quot;</span>))</span></code></pre></div>
<pre><code>## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt;
## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49]</code></pre>
<pre><code>## 
## ── Column specification ───────────────────────────────────────────────────────────────
## cols(
##   .default = col_character(),
##   id = col_double(),
##   compas_screening_date = col_date(format = &quot;&quot;),
##   dob = col_date(format = &quot;&quot;),
##   age = col_double(),
##   juv_fel_count = col_double(),
##   decile_score = col_double(),
##   juv_misd_count = col_double(),
##   juv_other_count = col_double(),
##   priors_count = col_double(),
##   days_b_screening_arrest = col_double(),
##   c_jail_in = col_datetime(format = &quot;&quot;),
##   c_jail_out = col_datetime(format = &quot;&quot;),
##   c_offense_date = col_date(format = &quot;&quot;),
##   c_arrest_date = col_date(format = &quot;&quot;),
##   c_days_from_compas = col_double(),
##   is_recid = col_double(),
##   r_days_from_arrest = col_double(),
##   r_offense_date = col_date(format = &quot;&quot;),
##   r_jail_in = col_date(format = &quot;&quot;),
##   r_jail_out = col_date(format = &quot;&quot;)
##   # ... with 13 more columns
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<div class="sourceCode" id="cb1239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1239-1"><a href="machine-learning.html#cb1239-1"></a><span class="kw">glue</span>(<span class="st">&quot;N of observations (rows): {nrow(cox_data)}</span></span>
<span id="cb1239-2"><a href="machine-learning.html#cb1239-2"></a><span class="st">      N of variables (columns): {ncol(cox_data)}&quot;</span>)</span></code></pre></div>
<pre><code>## N of observations (rows): 13419
## N of variables (columns): 52</code></pre>
</div>
<div id="wrangling-2" class="section level4" number="7.8.3.3">
<h4><span class="header-section-number">7.8.3.3</span> Wrangling</h4>
<div class="sourceCode" id="cb1241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1241-1"><a href="machine-learning.html#cb1241-1"></a>df &lt;-<span class="st"> </span>cox_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1241-2"><a href="machine-learning.html#cb1241-2"></a><span class="st">    </span><span class="kw">filter</span>(score_text <span class="op">!=</span><span class="st"> &quot;N/A&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1241-3"><a href="machine-learning.html#cb1241-3"></a><span class="st">    </span><span class="kw">filter</span>(end <span class="op">&gt;</span><span class="st"> </span>start) <span class="op">%&gt;%</span></span>
<span id="cb1241-4"><a href="machine-learning.html#cb1241-4"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">c_charge_degree =</span> <span class="kw">factor</span>(c_charge_degree),</span>
<span id="cb1241-5"><a href="machine-learning.html#cb1241-5"></a>           <span class="dt">age_cat =</span> <span class="kw">factor</span>(age_cat),</span>
<span id="cb1241-6"><a href="machine-learning.html#cb1241-6"></a>           <span class="dt">race =</span> <span class="kw">factor</span>(race, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Caucasian&quot;</span>,<span class="st">&quot;African-American&quot;</span>,<span class="st">&quot;Hispanic&quot;</span>,<span class="st">&quot;Other&quot;</span>,<span class="st">&quot;Asian&quot;</span>,<span class="st">&quot;Native American&quot;</span>)),</span>
<span id="cb1241-7"><a href="machine-learning.html#cb1241-7"></a>           <span class="dt">sex =</span> <span class="kw">factor</span>(sex, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>,<span class="st">&quot;Female&quot;</span>)),</span>
<span id="cb1241-8"><a href="machine-learning.html#cb1241-8"></a>           <span class="dt">score_factor =</span> <span class="kw">factor</span>(score_text, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>)))</span>
<span id="cb1241-9"><a href="machine-learning.html#cb1241-9"></a></span>
<span id="cb1241-10"><a href="machine-learning.html#cb1241-10"></a>grp &lt;-<span class="st"> </span>df[<span class="op">!</span><span class="kw">duplicated</span>(df<span class="op">$</span>id),]</span></code></pre></div>
</div>
<div id="descriptive-analysis-2" class="section level4" number="7.8.3.4">
<h4><span class="header-section-number">7.8.3.4</span> Descriptive analysis</h4>
<ul>
<li>Score distribution</li>
</ul>
<div class="sourceCode" id="cb1242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1242-1"><a href="machine-learning.html#cb1242-1"></a>grp <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1242-2"><a href="machine-learning.html#cb1242-2"></a><span class="st">    </span><span class="kw">group_by</span>(score_factor) <span class="op">%&gt;%</span></span>
<span id="cb1242-3"><a href="machine-learning.html#cb1242-3"></a><span class="st">      </span><span class="kw">count</span>() <span class="op">%&gt;%</span></span>
<span id="cb1242-4"><a href="machine-learning.html#cb1242-4"></a><span class="st">      </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> score_factor, <span class="dt">y =</span> n)) <span class="op">+</span></span>
<span id="cb1242-5"><a href="machine-learning.html#cb1242-5"></a><span class="st">        </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1242-6"><a href="machine-learning.html#cb1242-6"></a><span class="st">        </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Score&quot;</span>,</span>
<span id="cb1242-7"><a href="machine-learning.html#cb1242-7"></a>             <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb1242-8"><a href="machine-learning.html#cb1242-8"></a>             <span class="dt">title =</span> <span class="st">&quot;Score distribution&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-107-1.png" width="672" /></p>
<ul>
<li>Score distribution by race</li>
</ul>
<div class="sourceCode" id="cb1243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1243-1"><a href="machine-learning.html#cb1243-1"></a>df <span class="op">%&gt;%</span></span>
<span id="cb1243-2"><a href="machine-learning.html#cb1243-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">ordered</span>(score_factor))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1243-3"><a href="machine-learning.html#cb1243-3"></a><span class="st">          </span><span class="kw">geom_bar</span>() <span class="op">+</span></span>
<span id="cb1243-4"><a href="machine-learning.html#cb1243-4"></a><span class="st">          </span><span class="kw">facet_wrap</span>(<span class="op">~</span>race, <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb1243-5"><a href="machine-learning.html#cb1243-5"></a><span class="st">          </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Decile Score&quot;</span>,</span>
<span id="cb1243-6"><a href="machine-learning.html#cb1243-6"></a>               <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb1243-7"><a href="machine-learning.html#cb1243-7"></a>               <span class="dt">Title =</span> <span class="st">&quot;Defendant&#39;s Decile Score&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
</div>
<div id="modeling-2" class="section level4" number="7.8.3.5">
<h4><span class="header-section-number">7.8.3.5</span> Modeling</h4>
<div class="sourceCode" id="cb1244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1244-1"><a href="machine-learning.html#cb1244-1"></a>f2 &lt;-<span class="st"> </span><span class="kw">Surv</span>(start, end, event, <span class="dt">type=</span><span class="st">&quot;counting&quot;</span>) <span class="op">~</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race <span class="op">*</span><span class="st"> </span>score_factor</span>
<span id="cb1244-2"><a href="machine-learning.html#cb1244-2"></a></span>
<span id="cb1244-3"><a href="machine-learning.html#cb1244-3"></a>model &lt;-<span class="st"> </span><span class="kw">coxph</span>(f2, <span class="dt">data =</span> df)</span>
<span id="cb1244-4"><a href="machine-learning.html#cb1244-4"></a></span>
<span id="cb1244-5"><a href="machine-learning.html#cb1244-5"></a>model <span class="op">%&gt;%</span></span>
<span id="cb1244-6"><a href="machine-learning.html#cb1244-6"></a><span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb1244-7"><a href="machine-learning.html#cb1244-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">gsub</span>(<span class="st">&quot;race|score_factor&quot;</span>,<span class="st">&quot;&quot;</span>, term)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1244-8"><a href="machine-learning.html#cb1244-8"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;&lt;chr&gt;&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1244-9"><a href="machine-learning.html#cb1244-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(term, estimate), <span class="dt">y =</span> estimate, <span class="dt">ymax =</span> conf.high, <span class="dt">ymin =</span> conf.low)) <span class="op">+</span></span>
<span id="cb1244-10"><a href="machine-learning.html#cb1244-10"></a><span class="st">  </span><span class="kw">geom_pointrange</span>() <span class="op">+</span></span>
<span id="cb1244-11"><a href="machine-learning.html#cb1244-11"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1244-12"><a href="machine-learning.html#cb1244-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Estimate&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-109-1.png" width="672" /></p>
<p>The interaction term shows a similar disparity as the logistic regression above.</p>
<p>High risk white defendants are 3.61 more likely than low risk white defendants, while High risk black defendants are 2.99 more likely than low.</p>
<div class="sourceCode" id="cb1245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1245-1"><a href="machine-learning.html#cb1245-1"></a>visualize_surv &lt;-<span class="st"> </span><span class="cf">function</span>(input){</span>
<span id="cb1245-2"><a href="machine-learning.html#cb1245-2"></a>  </span>
<span id="cb1245-3"><a href="machine-learning.html#cb1245-3"></a>f &lt;-<span class="st"> </span><span class="kw">Surv</span>(start, end, event, <span class="dt">type=</span><span class="st">&quot;counting&quot;</span>) <span class="op">~</span><span class="st"> </span>score_factor</span>
<span id="cb1245-4"><a href="machine-learning.html#cb1245-4"></a></span>
<span id="cb1245-5"><a href="machine-learning.html#cb1245-5"></a>fit &lt;-<span class="st"> </span><span class="kw">survfit</span>(f, <span class="dt">data =</span> input)</span>
<span id="cb1245-6"><a href="machine-learning.html#cb1245-6"></a></span>
<span id="cb1245-7"><a href="machine-learning.html#cb1245-7"></a>fit <span class="op">%&gt;%</span></span>
<span id="cb1245-8"><a href="machine-learning.html#cb1245-8"></a><span class="st">    </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb1245-9"><a href="machine-learning.html#cb1245-9"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">strata =</span> <span class="kw">gsub</span>(<span class="st">&quot;score_factor=&quot;</span>,<span class="st">&quot;&quot;</span>, strata)) <span class="op">%&gt;%</span></span>
<span id="cb1245-10"><a href="machine-learning.html#cb1245-10"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">strata =</span> <span class="kw">factor</span>(strata, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;High&quot;</span>,<span class="st">&quot;Medium&quot;</span>,<span class="st">&quot;Low&quot;</span>))) <span class="op">%&gt;%</span></span>
<span id="cb1245-11"><a href="machine-learning.html#cb1245-11"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> time, <span class="dt">y =</span> estimate, <span class="dt">ymax =</span> conf.high, <span class="dt">ymin =</span> conf.low, <span class="dt">group =</span> strata, <span class="dt">col =</span> strata)) <span class="op">+</span></span>
<span id="cb1245-12"><a href="machine-learning.html#cb1245-12"></a><span class="st">    </span><span class="kw">geom_pointrange</span>(<span class="dt">alpha =</span> <span class="fl">0.1</span>) <span class="op">+</span></span>
<span id="cb1245-13"><a href="machine-learning.html#cb1245-13"></a><span class="st">    </span><span class="kw">guides</span>(<span class="dt">colour =</span> <span class="kw">guide_legend</span>(<span class="dt">override.aes =</span> <span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>))) <span class="op">+</span></span>
<span id="cb1245-14"><a href="machine-learning.html#cb1245-14"></a><span class="st">    </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb1245-15"><a href="machine-learning.html#cb1245-15"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Estimated survival rate&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;Strata&quot;</span>)}</span></code></pre></div>
<div class="sourceCode" id="cb1246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1246-1"><a href="machine-learning.html#cb1246-1"></a><span class="kw">visualize_surv</span>(df) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Overall&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<p>Black defendants do recidivate at higher rates according to race specific Kaplan Meier plots.</p>
<div class="sourceCode" id="cb1247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1247-1"><a href="machine-learning.html#cb1247-1"></a>(df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(race <span class="op">==</span><span class="st"> &quot;Caucasian&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">visualize_surv</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Caucasian&quot;</span>)) <span class="op">/</span></span>
<span id="cb1247-2"><a href="machine-learning.html#cb1247-2"></a>(df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(race <span class="op">==</span><span class="st"> &quot;African-American&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">visualize_surv</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;African-American&quot;</span>)) </span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
<p>In terms of underlying recidivism rates, we can look at gender specific Kaplan Meier estimates. There is a striking difference between women and men.</p>
<div class="sourceCode" id="cb1248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1248-1"><a href="machine-learning.html#cb1248-1"></a>(df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(sex <span class="op">==</span><span class="st"> &quot;Female&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">visualize_surv</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Female&quot;</span>)) <span class="op">/</span></span>
<span id="cb1248-2"><a href="machine-learning.html#cb1248-2"></a></span>
<span id="cb1248-3"><a href="machine-learning.html#cb1248-3"></a>(df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(sex <span class="op">==</span><span class="st"> &quot;Male&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">visualize_surv</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Male&quot;</span>))</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-113-1.png" width="672" /></p>
<p>As these plots show, the COMPAS score treats a High risk women the same as a Medium risk man.</p>
</div>
<div id="risk-of-recidivism-accuracy" class="section level4" number="7.8.3.6">
<h4><span class="header-section-number">7.8.3.6</span> Risk of Recidivism accuracy</h4>
<p>The above analysis shows that the COMPAS algorithm does overpredict African-American defendant’s future recidivism, but we haven’t yet explored the direction of the bias. We can discover fine differences in overprediction and underprediction by comparing COMPAS scores across racial lines.</p>
<div class="sourceCode" id="cb1249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1249-1"><a href="machine-learning.html#cb1249-1"></a><span class="co"># create a new environment </span></span>
<span id="cb1249-2"><a href="machine-learning.html#cb1249-2"></a><span class="kw">conda_create</span>(<span class="st">&quot;r-reticulate&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;/home/jae/.local/share/r-miniconda/envs/r-reticulate/bin/python&quot;</code></pre>
<div class="sourceCode" id="cb1251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1251-1"><a href="machine-learning.html#cb1251-1"></a><span class="co"># install libs </span></span>
<span id="cb1251-2"><a href="machine-learning.html#cb1251-2"></a><span class="kw">conda_install</span>(<span class="st">&quot;r-reticulate&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;pandas&quot;</span>))</span>
<span id="cb1251-3"><a href="machine-learning.html#cb1251-3"></a></span>
<span id="cb1251-4"><a href="machine-learning.html#cb1251-4"></a><span class="co"># indicate that we want to use a specific condaenv</span></span>
<span id="cb1251-5"><a href="machine-learning.html#cb1251-5"></a><span class="kw">use_condaenv</span>(<span class="st">&quot;r-reticulate&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1252"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1252-1"><a href="machine-learning.html#cb1252-1"></a></span>
<span id="cb1252-2"><a href="machine-learning.html#cb1252-2"></a><span class="im">from</span> truth_tables <span class="im">import</span> PeekyReader, Person, table, is_race, count, vtable, hightable, vhightable</span>
<span id="cb1252-3"><a href="machine-learning.html#cb1252-3"></a><span class="im">from</span> csv <span class="im">import</span> DictReader</span>
<span id="cb1252-4"><a href="machine-learning.html#cb1252-4"></a></span>
<span id="cb1252-5"><a href="machine-learning.html#cb1252-5"></a>people <span class="op">=</span> []</span></code></pre></div>
<div class="sourceCode" id="cb1253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1253-1"><a href="machine-learning.html#cb1253-1"></a></span>
<span id="cb1253-2"><a href="machine-learning.html#cb1253-2"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;./data/cox-parsed.csv&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb1253-3"><a href="machine-learning.html#cb1253-3"></a>    reader <span class="op">=</span> PeekyReader(DictReader(f))</span>
<span id="cb1253-4"><a href="machine-learning.html#cb1253-4"></a>    <span class="cf">try</span>:</span>
<span id="cb1253-5"><a href="machine-learning.html#cb1253-5"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb1253-6"><a href="machine-learning.html#cb1253-6"></a>            p <span class="op">=</span> Person(reader)</span>
<span id="cb1253-7"><a href="machine-learning.html#cb1253-7"></a>            <span class="cf">if</span> p.valid:</span>
<span id="cb1253-8"><a href="machine-learning.html#cb1253-8"></a>                people.append(p)</span>
<span id="cb1253-9"><a href="machine-learning.html#cb1253-9"></a>    <span class="cf">except</span> <span class="pp">StopIteration</span>:</span>
<span id="cb1253-10"><a href="machine-learning.html#cb1253-10"></a>        <span class="cf">pass</span></span></code></pre></div>
<div class="sourceCode" id="cb1254"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1254-1"><a href="machine-learning.html#cb1254-1"></a></span>
<span id="cb1254-2"><a href="machine-learning.html#cb1254-2"></a>pop <span class="op">=</span> <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> i: ((i.recidivist <span class="op">==</span> <span class="va">True</span> <span class="kw">and</span> i.lifetime <span class="op">&lt;=</span> <span class="dv">730</span>) <span class="kw">or</span></span>
<span id="cb1254-3"><a href="machine-learning.html#cb1254-3"></a>                              i.lifetime <span class="op">&gt;</span> <span class="dv">730</span>), <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> x: x.score_valid, people))))</span>
<span id="cb1254-4"><a href="machine-learning.html#cb1254-4"></a></span>
<span id="cb1254-5"><a href="machine-learning.html#cb1254-5"></a>recid <span class="op">=</span> <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> i: i.recidivist <span class="op">==</span> <span class="va">True</span> <span class="kw">and</span> i.lifetime <span class="op">&lt;=</span> <span class="dv">730</span>, pop))</span>
<span id="cb1254-6"><a href="machine-learning.html#cb1254-6"></a></span>
<span id="cb1254-7"><a href="machine-learning.html#cb1254-7"></a>rset <span class="op">=</span> <span class="bu">set</span>(recid)</span>
<span id="cb1254-8"><a href="machine-learning.html#cb1254-8"></a></span>
<span id="cb1254-9"><a href="machine-learning.html#cb1254-9"></a>surv <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> pop <span class="cf">if</span> i <span class="kw">not</span> <span class="kw">in</span> rset]</span></code></pre></div>
<ul>
<li>Define a function for a table.</li>
</ul>
<div class="sourceCode" id="cb1255"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1255-1"><a href="machine-learning.html#cb1255-1"></a></span>
<span id="cb1255-2"><a href="machine-learning.html#cb1255-2"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1255-3"><a href="machine-learning.html#cb1255-3"></a></span>
<span id="cb1255-4"><a href="machine-learning.html#cb1255-4"></a><span class="kw">def</span> create_table(x, y):</span>
<span id="cb1255-5"><a href="machine-learning.html#cb1255-5"></a></span>
<span id="cb1255-6"><a href="machine-learning.html#cb1255-6"></a>  t <span class="op">=</span> table(<span class="bu">list</span>(x), <span class="bu">list</span>(y))</span>
<span id="cb1255-7"><a href="machine-learning.html#cb1255-7"></a>  </span>
<span id="cb1255-8"><a href="machine-learning.html#cb1255-8"></a>  df <span class="op">=</span> pd.DataFrame(t.items(), </span>
<span id="cb1255-9"><a href="machine-learning.html#cb1255-9"></a>             columns <span class="op">=</span> [<span class="st">&#39;Metrics&#39;</span>, <span class="st">&#39;Scores&#39;</span>])</span>
<span id="cb1255-10"><a href="machine-learning.html#cb1255-10"></a>             </span>
<span id="cb1255-11"><a href="machine-learning.html#cb1255-11"></a>  <span class="cf">return</span>(df)</span>
<span id="cb1255-12"><a href="machine-learning.html#cb1255-12"></a>             </span></code></pre></div>
<ul>
<li>All defenders</li>
</ul>
<div class="sourceCode" id="cb1256"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1256-1"><a href="machine-learning.html#cb1256-1"></a></span>
<span id="cb1256-2"><a href="machine-learning.html#cb1256-2"></a>create_table(<span class="bu">list</span>(recid), <span class="bu">list</span>(surv)).to_csv(<span class="st">&quot;data/table_recid.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1257-1"><a href="machine-learning.html#cb1257-1"></a><span class="kw">read.csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;table_recid.csv&quot;</span>))[,<span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span></span>
<span id="cb1257-2"><a href="machine-learning.html#cb1257-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Metrics, <span class="dt">y =</span> Scores)) <span class="op">+</span></span>
<span id="cb1257-3"><a href="machine-learning.html#cb1257-3"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1257-4"><a href="machine-learning.html#cb1257-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Recidivism&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-120-1.png" width="672" /></p>
<p>That number is higher for African Americans at 44.85% and lower for whites at 23.45%.</p>
<div class="sourceCode" id="cb1258"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1258-1"><a href="machine-learning.html#cb1258-1"></a></span>
<span id="cb1258-2"><a href="machine-learning.html#cb1258-2"></a><span class="kw">def</span> create_comp_tables(recid_data, surv_data):</span>
<span id="cb1258-3"><a href="machine-learning.html#cb1258-3"></a>  </span>
<span id="cb1258-4"><a href="machine-learning.html#cb1258-4"></a>    <span class="co"># filtering variables </span></span>
<span id="cb1258-5"><a href="machine-learning.html#cb1258-5"></a>    is_afam <span class="op">=</span> is_race(<span class="st">&quot;African-American&quot;</span>)</span>
<span id="cb1258-6"><a href="machine-learning.html#cb1258-6"></a>    is_white <span class="op">=</span> is_race(<span class="st">&quot;Caucasian&quot;</span>)</span>
<span id="cb1258-7"><a href="machine-learning.html#cb1258-7"></a>  </span>
<span id="cb1258-8"><a href="machine-learning.html#cb1258-8"></a>    <span class="co"># dfs </span></span>
<span id="cb1258-9"><a href="machine-learning.html#cb1258-9"></a>    df1 <span class="op">=</span> create_table(<span class="bu">filter</span>(is_afam, recid_data),</span>
<span id="cb1258-10"><a href="machine-learning.html#cb1258-10"></a>                       <span class="bu">filter</span>(is_afam, surv_data))</span>
<span id="cb1258-11"><a href="machine-learning.html#cb1258-11"></a>  </span>
<span id="cb1258-12"><a href="machine-learning.html#cb1258-12"></a>    df2 <span class="op">=</span> create_table(<span class="bu">filter</span>(is_white, recid_data), </span>
<span id="cb1258-13"><a href="machine-learning.html#cb1258-13"></a>                       <span class="bu">filter</span>(is_white, surv_data))</span>
<span id="cb1258-14"><a href="machine-learning.html#cb1258-14"></a>  </span>
<span id="cb1258-15"><a href="machine-learning.html#cb1258-15"></a>    <span class="co"># concat </span></span>
<span id="cb1258-16"><a href="machine-learning.html#cb1258-16"></a>    dfs <span class="op">=</span> pd.concat([df1, df2])</span>
<span id="cb1258-17"><a href="machine-learning.html#cb1258-17"></a>    </span>
<span id="cb1258-18"><a href="machine-learning.html#cb1258-18"></a>    dfs[<span class="st">&#39;Group&#39;</span>] <span class="op">=</span> [<span class="st">&#39;African Americans&#39;</span>,<span class="st">&#39;African Americans&#39;</span>,<span class="st">&#39;Whites&#39;</span>,<span class="st">&#39;Whites&#39;</span>]</span>
<span id="cb1258-19"><a href="machine-learning.html#cb1258-19"></a>    </span>
<span id="cb1258-20"><a href="machine-learning.html#cb1258-20"></a>    <span class="cf">return</span>(dfs)</span>
<span id="cb1258-21"><a href="machine-learning.html#cb1258-21"></a>    </span></code></pre></div>
<div class="sourceCode" id="cb1259"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1259-1"><a href="machine-learning.html#cb1259-1"></a></span>
<span id="cb1259-2"><a href="machine-learning.html#cb1259-2"></a>create_comp_tables(recid, surv).to_csv(<span class="st">&quot;data/comp_tables_recid.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1260-1"><a href="machine-learning.html#cb1260-1"></a><span class="kw">read.csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;comp_tables_recid.csv&quot;</span>))[,<span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span></span>
<span id="cb1260-2"><a href="machine-learning.html#cb1260-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Metrics, <span class="dt">y =</span> Scores, <span class="dt">fill =</span> Group)) <span class="op">+</span></span>
<span id="cb1260-3"><a href="machine-learning.html#cb1260-3"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span></span>
<span id="cb1260-4"><a href="machine-learning.html#cb1260-4"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1260-5"><a href="machine-learning.html#cb1260-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Recidivism&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-123-1.png" width="672" /></p>
</div>
<div id="risk-of-violent-recidivism-accuracy" class="section level4" number="7.8.3.7">
<h4><span class="header-section-number">7.8.3.7</span> Risk of Violent Recidivism accuracy</h4>
<p>COMPAS also offers a score that aims to measure a persons risk of violent recidivism, which has a similar overall accuracy to the Recidivism score.</p>
<div class="sourceCode" id="cb1261"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1261-1"><a href="machine-learning.html#cb1261-1"></a></span>
<span id="cb1261-2"><a href="machine-learning.html#cb1261-2"></a>vpeople <span class="op">=</span> []</span>
<span id="cb1261-3"><a href="machine-learning.html#cb1261-3"></a></span>
<span id="cb1261-4"><a href="machine-learning.html#cb1261-4"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;./data/cox-violent-parsed.csv&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb1261-5"><a href="machine-learning.html#cb1261-5"></a>    reader <span class="op">=</span> PeekyReader(DictReader(f))</span>
<span id="cb1261-6"><a href="machine-learning.html#cb1261-6"></a>    <span class="cf">try</span>:</span>
<span id="cb1261-7"><a href="machine-learning.html#cb1261-7"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb1261-8"><a href="machine-learning.html#cb1261-8"></a>            p <span class="op">=</span> Person(reader)</span>
<span id="cb1261-9"><a href="machine-learning.html#cb1261-9"></a>            <span class="cf">if</span> p.valid:</span>
<span id="cb1261-10"><a href="machine-learning.html#cb1261-10"></a>                vpeople.append(p)</span>
<span id="cb1261-11"><a href="machine-learning.html#cb1261-11"></a>    <span class="cf">except</span> <span class="pp">StopIteration</span>:</span>
<span id="cb1261-12"><a href="machine-learning.html#cb1261-12"></a>        <span class="cf">pass</span></span>
<span id="cb1261-13"><a href="machine-learning.html#cb1261-13"></a></span>
<span id="cb1261-14"><a href="machine-learning.html#cb1261-14"></a>vpop <span class="op">=</span> <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> i: ((i.violent_recidivist <span class="op">==</span> <span class="va">True</span> <span class="kw">and</span> i.lifetime <span class="op">&lt;=</span> <span class="dv">730</span>) <span class="kw">or</span></span>
<span id="cb1261-15"><a href="machine-learning.html#cb1261-15"></a>                              i.lifetime <span class="op">&gt;</span> <span class="dv">730</span>), <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> x: x.vscore_valid, vpeople))))</span>
<span id="cb1261-16"><a href="machine-learning.html#cb1261-16"></a></span>
<span id="cb1261-17"><a href="machine-learning.html#cb1261-17"></a>vrecid <span class="op">=</span> <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> i: i.violent_recidivist <span class="op">==</span> <span class="va">True</span> <span class="kw">and</span> i.lifetime <span class="op">&lt;=</span> <span class="dv">730</span>, vpeople))</span>
<span id="cb1261-18"><a href="machine-learning.html#cb1261-18"></a></span>
<span id="cb1261-19"><a href="machine-learning.html#cb1261-19"></a>vrset <span class="op">=</span> <span class="bu">set</span>(vrecid)</span>
<span id="cb1261-20"><a href="machine-learning.html#cb1261-20"></a></span>
<span id="cb1261-21"><a href="machine-learning.html#cb1261-21"></a>vsurv <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> vpop <span class="cf">if</span> i <span class="kw">not</span> <span class="kw">in</span> vrset]</span></code></pre></div>
<div class="sourceCode" id="cb1262"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1262-1"><a href="machine-learning.html#cb1262-1"></a></span>
<span id="cb1262-2"><a href="machine-learning.html#cb1262-2"></a>create_table(vrecid, vsurv).to_csv(<span class="st">&quot;data/table_vrecid.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1263-1"><a href="machine-learning.html#cb1263-1"></a><span class="kw">read.csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;table_vrecid.csv&quot;</span>))[,<span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span></span>
<span id="cb1263-2"><a href="machine-learning.html#cb1263-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Metrics, <span class="dt">y =</span> Scores)) <span class="op">+</span></span>
<span id="cb1263-3"><a href="machine-learning.html#cb1263-3"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb1263-4"><a href="machine-learning.html#cb1263-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Violent recidivism&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-126-1.png" width="672" /></p>
<p>Even more so for Black defendants.</p>
<div class="sourceCode" id="cb1264"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1264-1"><a href="machine-learning.html#cb1264-1"></a></span>
<span id="cb1264-2"><a href="machine-learning.html#cb1264-2"></a>create_comp_tables(vrecid, vsurv).to_csv(<span class="st">&quot;data/comp_tables_vrecid.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1265-1"><a href="machine-learning.html#cb1265-1"></a><span class="kw">read.csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;comp_tables_vrecid.csv&quot;</span>))[,<span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span></span>
<span id="cb1265-2"><a href="machine-learning.html#cb1265-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Metrics, <span class="dt">y =</span> Scores, <span class="dt">fill =</span> Group)) <span class="op">+</span></span>
<span id="cb1265-3"><a href="machine-learning.html#cb1265-3"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span></span>
<span id="cb1265-4"><a href="machine-learning.html#cb1265-4"></a><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb1265-5"><a href="machine-learning.html#cb1265-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Violent recidivism&quot;</span>)</span></code></pre></div>
<p><img src="06_high_dimensional_data_files/figure-html/unnamed-chunk-128-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="references-2" class="section level2" number="7.9">
<h2><span class="header-section-number">7.9</span> References</h2>
<div id="books" class="section level3" number="7.9.1">
<h3><span class="header-section-number">7.9.1</span> Books</h3>
<ul>
<li><p><em>An Introduction to Statistical Learning - with Applications in R (2013)</em> by Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. Springer: New York. <a href="https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370">Amazon</a> or <a href="http://www-bcf.usc.edu/~gareth/ISL/">free PDF</a>.</p></li>
<li><p><em>Hands-On Machine Learning with R (2020)</em> by Bradley Boehmke &amp; Brandon Greenwell. <a href="https://www.routledge.com/Hands-On-Machine-Learning-with-R/Boehmke-Greenwell/p/book/9781138495685">CRC Press</a> or <a href="https://www.amazon.com/gp/product/1138495689?pf_rd_p=ab873d20-a0ca-439b-ac45-cd78f07a84d8&amp;pf_rd_r=JBRX0ZJ1WFSR9T3JPTQE">Amazon</a></p></li>
<li><p><em>Applied Predictive Modeling (2013)</em> by Max Kuhn and Kjell Johnson. Springer: New York. <a href="https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485?SubscriptionId=0ENGV10E9K9QDNSJ5C82&amp;tag=apm0a-20&amp;linkCode=xm2&amp;camp=2025&amp;creative=165953&amp;creativeASIN=1461468485">Amazon</a></p></li>
<li><p><em>Feature Engineering and Selection: A Practical Approach for Predictive Models (2019)</em> by Kjell Johnson and Max Kuhn. Taylor &amp; Francis. <a href="http://www.feat.engineering/">Amazon</a> or <a href="http://www.feat.engineering/">free HTML</a>.</p></li>
<li><p><em><a href="https://www.tmwr.org/">Tidy Modeling with R</a> (2020)</em> by Max Kuhn and Julia Silge (work-in-progress)</p></li>
</ul>
</div>
<div id="lecture-slides" class="section level3" number="7.9.2">
<h3><span class="header-section-number">7.9.2</span> Lecture slides</h3>
<ul>
<li><p><a href="https://www.nber.org/econometrics_minicourse_2015/nber_slides11.pdf">An introduction to supervised and unsupervised learning (2015)</a> by Susan Athey and Guido Imbens</p></li>
<li><p><a href="https://education.rstudio.com/blog/2020/02/conf20-intro-ml/">Introduction Machine Learning with the Tidyverse</a> by Alison Hill</p></li>
</ul>
</div>
<div id="blog-posts" class="section level3" number="7.9.3">
<h3><span class="header-section-number">7.9.3</span> Blog posts</h3>
<ul>
<li><a href="http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/">“Using the recipes package for easy pre-processing”</a> by Rebecca Barter</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="semi-structured-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="big-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
